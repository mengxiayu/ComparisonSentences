{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# path_inference_data = Path(\"/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pair_scoring/Q11424/data_2k_hn.csv\")\n",
    "# dataset_inference = pd.read_csv(path_inference_data)\n",
    "# X_infer = dataset_inference.iloc[:, 1:-1]\n",
    "# Y_infer = dataset_inference.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57821 2000\n",
      "train_r2 0.9446612422236144\n",
      "test_r2 0.4202670872043277\n",
      "test_mae 0.31109432109380897\n",
      "test_mse 0.3993648216628805\n",
      "ndcg 0.8790434271040206\n",
      "kendalltau 0.6136835528119015\n",
      "acc 0.9075\n",
      "p 0.9022265246853823\n",
      "r 0.9173228346456693\n",
      "f1 0.9097120546608102\n",
      "Importance of 35 features:\n",
      "degree_e1 0.028321274491580204\n",
      "degree_e2 0.031751543154737626\n",
      "indegree_e1 0.030286899831846962\n",
      "indegree_e2 0.03049909096455405\n",
      "avg_rel_coverage 0.01448762160953726\n",
      "min_rel_coverage 0.012695590433014638\n",
      "max_rel_coverage 0.010852177304887555\n",
      "diff_rel_coverage 0.012407358662921985\n",
      "num_common_prop 0.010823876537201127\n",
      "common_prop_rate 0.024152302781180867\n",
      "num_common_feature 0.008471039408618633\n",
      "common_feat_rate 0.03189010377062825\n",
      "avg_common_prop_freq 0.03404318094228013\n",
      "max_common_prop_freq 0.0\n",
      "min_common_prop_freq 0.019997887690570527\n",
      "avg_common_value_freq 0.021460435648831714\n",
      "max_common_value_freq 0.008585177758027923\n",
      "min_common_value_freq 0.0208074142582877\n",
      "min_common_v_indegree 0.08674218245651077\n",
      "max_common_v_indegree 0.01097355674468583\n",
      "second_common_v_indegree 0.013445915489703674\n",
      "property_freq 0.11536575731589653\n",
      "property_diversity 0.0603471325922439\n",
      "freq_v1 0.024408468579088346\n",
      "freq_v2 0.023073742835214878\n",
      "avg_value_freq 0.033870006112112286\n",
      "diff_value_freq 0.050537016697637785\n",
      "degree_v1 0.03467375444693421\n",
      "degree_v2 0.033392708393064886\n",
      "indegree_v1 0.06650317830145362\n",
      "indegree_v2 0.039646923285682076\n",
      "second_common_prop_freq 0.022401525884958223\n",
      "min_common_v_degree 0.014041401397654304\n",
      "max_common_v_degree 0.009857360620802348\n",
      "second_common_v_degree 0.009186393597649152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, explained_variance_score, max_error, mean_absolute_error, mean_squared_error, mean_poisson_deviance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# as classification / ranking\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, ndcg_score, f1_score\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# train\n",
    "path_data = Path(\"/Users/mengxiayu/Documents/Research/ComparisonSentences/experiments/pair_scoring/global/data.tsv\")\n",
    "dataset = pd.read_csv(path_data)\n",
    "dataset.drop_duplicates()\n",
    "dataset = dataset.sample(frac = 1).reset_index(drop=True) # shuffle\n",
    "\n",
    "X = dataset.iloc[:, :-1]\n",
    "Y = dataset.iloc[:, -1]\n",
    "\n",
    "# split dataset method 1: avoid overlap entities\n",
    "def split_dataset(X, Y, method):\n",
    "    if method == \"no_overlap\":\n",
    "        existing_entities = set()\n",
    "        for x in X.iloc[:2000, 0]:\n",
    "            e1, e2, p, v1, v2 = eval(x)\n",
    "            existing_entities.add(e1)\n",
    "            existing_entities.add(e2)\n",
    "        indices = []\n",
    "        for ind in X.index:\n",
    "            pair = X['pair'][ind]\n",
    "            e1, e2, p, v1, v2 = eval(pair)\n",
    "            if e1 not in existing_entities and e2 not in existing_entities:\n",
    "                indices.append(ind)\n",
    "        X_train = X.iloc[indices, :]\n",
    "        Y_train = Y.iloc[indices]\n",
    "        X_dev = X.iloc[:2000, :]\n",
    "        Y_dev = Y.iloc[:2000]\n",
    "        return X_train, Y_train, X_dev, Y_dev\n",
    "    elif method == \"random\":\n",
    "        X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.05, random_state=0)\n",
    "        return X_train, Y_train, X_dev, Y_dev\n",
    "    else:\n",
    "        print(\"splitting method errir\")\n",
    "        return None\n",
    "X_train, Y_train, X_dev, Y_dev = split_dataset(X, Y, \"no_overlap\")\n",
    "\n",
    "X_train = X_train.iloc[:, 1:]\n",
    "X_dev = X_dev.iloc[:, 1:]\n",
    "print(len(X_train), len(X_dev))\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=130, random_state=0)\n",
    "regressor.fit(X_train, Y_train)\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "print(\"train_r2\", r2_score(Y_train, y_pred_train))\n",
    "y_pred = regressor.predict(X_dev)\n",
    "\n",
    "def print_evaluation(truths, preds):\n",
    "    print(\"test_r2\", r2_score(truths, preds))\n",
    "    print(\"test_mae\", mean_absolute_error(truths, preds))\n",
    "    print(\"test_mse\", mean_squared_error(truths, preds))\n",
    "    print(\"ndcg\", ndcg_score(np.array([truths]), [preds]))\n",
    "    print(\"kendalltau\", stats.kendalltau(truths, preds)[0])\n",
    "    y_pred = [1 if x > math.log(1.5) else 0 for x in preds]\n",
    "    y_label = [1 if x > math.log(1.5) else 0 for x in truths]\n",
    "    print(\"acc\",accuracy_score(y_label, y_pred))\n",
    "    print(\"p\",precision_score(y_label, y_pred))\n",
    "    print(\"r\", recall_score(y_label, y_pred))\n",
    "    print(\"f1\", f1_score(y_label, y_pred))\n",
    "\n",
    "print_evaluation(Y_dev, y_pred)\n",
    "print(f\"Importance of {len(regressor.feature_importances_)} features:\")\n",
    "for k,v in zip(regressor.feature_names_in_, regressor.feature_importances_):\n",
    "    print(k,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"/Users/mengxiayu/Documents/Research/ComparisonSentences/experiments/pair_scoring/global/data.tsv\")\n",
    "dataset = pd.read_csv(path_data)\n",
    "\n",
    "\n",
    "X = dataset.iloc[:, :-1]\n",
    "Y = dataset.iloc[:, -1]\n",
    "X.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "path_test_data = Path(\"/Users/mengxiayu/Documents/Research/ComparisonSentences/experiments/pair_scoring/Q5/test_data.tsv\")\n",
    "test_dataset = pd.read_csv(path_test_data)\n",
    "X_test = test_dataset.iloc[:, 1:-1]\n",
    "Y_test = test_dataset.iloc[:, -1]\n",
    "\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "print_evaluation(Y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in y_pred_test:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([ 9.15480129, 11.13308446, 13.51055559, 15.36217539, 17.57106074,\n",
       "         45.27998074, 22.03085303]),\n",
       "  'std_fit_time': array([ 0.2602258 ,  0.23924122,  0.49525624,  0.49913398,  0.48800812,\n",
       "         35.46893728,  1.09137444]),\n",
       "  'mean_score_time': array([0.05588659, 0.08275557, 0.08194153, 0.1052746 , 0.10428667,\n",
       "         0.13601661, 0.12406127]),\n",
       "  'std_score_time': array([0.00084515, 0.02146036, 0.00506859, 0.01847758, 0.00123396,\n",
       "         0.03098605, 0.00109461]),\n",
       "  'param_n_estimators': masked_array(data=[80, 100, 120, 140, 160, 180, 200],\n",
       "               mask=[False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'n_estimators': 80},\n",
       "   {'n_estimators': 100},\n",
       "   {'n_estimators': 120},\n",
       "   {'n_estimators': 140},\n",
       "   {'n_estimators': 160},\n",
       "   {'n_estimators': 180},\n",
       "   {'n_estimators': 200}],\n",
       "  'split0_test_score': array([0.48673496, 0.4884008 , 0.48781553, 0.48837213, 0.48864157,\n",
       "         0.48768728, 0.48558667]),\n",
       "  'split1_test_score': array([0.47158045, 0.47262486, 0.47798841, 0.47976445, 0.48231657,\n",
       "         0.48290555, 0.48424436]),\n",
       "  'split2_test_score': array([0.41239813, 0.41723698, 0.41802333, 0.4210853 , 0.42500722,\n",
       "         0.42600783, 0.42644012]),\n",
       "  'mean_test_score': array([0.45690451, 0.45942088, 0.46127576, 0.46307396, 0.46532178,\n",
       "         0.46553355, 0.46542372]),\n",
       "  'std_test_score': array([0.03207313, 0.03051591, 0.0308461 , 0.0298977 , 0.02862341,\n",
       "         0.028017  , 0.02757101]),\n",
       "  'rank_test_score': array([7, 6, 5, 4, 3, 1, 2], dtype=int32)},\n",
       " {'n_estimators': 180},\n",
       " 0.46553355085079645)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_search = {'n_estimators': range(80, 201, 20)}\n",
    "gsearch = GridSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "                       param_grid=param_search,\n",
    "                       scoring=\"r2\", \n",
    "                       cv=3 )\n",
    "gsearch.fit(X_train.iloc[:10000, :], Y_train.iloc[:10000])\n",
    "gsearch.cv_results_, gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {'max_depth':range(3,20,4), 'min_samples_split':range(10,201,30)}\n",
    "\n",
    "gsearch = GridSearchCV(estimator=RandomForestRegressor(n_estimators=130, random_state=10),\n",
    "                       param_grid=param_test2,\n",
    "                       scoring=\"r2\", \n",
    "                       cv=3 )\n",
    "gsearch.fit(X_train, Y_train)\n",
    "gsearch.cv_results_, gsearch.best_params_, gsearch.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test in another domain\n",
    "regressor = RandomForestRegressor(n_estimators=130, random_state=0)\n",
    "regressor.fit(X_train, Y_train)\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "print(\"train_r2\", r2_score(Y_train, y_pred_train))\n",
    "Y_pred = regressor.predict(X_test)\n",
    "\n",
    "# as classification\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, ndcg_score\n",
    "print(\"ndcg\", ndcg_score(np.array([Y_test]), [Y_pred]))\n",
    "y_pred = [1 if x > math.log(1.5) else 0 for x in Y_pred]\n",
    "y_label = [1 if x > math.log(1.5) else 0 for x in Y_test]\n",
    "print(\"acc\",accuracy_score(y_label, y_pred))\n",
    "print(\"p\",precision_score(y_label, y_pred))\n",
    "print(\"r\", recall_score(y_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "for i in range(10):\n",
    "    k = 0.1*i\n",
    "    pred = [1 if x > math.log(1 + k) else 0 for x in y_pred]\n",
    "    label = [1 if x > math.log(1.5) else 0 for x in Y_test]\n",
    "    precisions.append(precision_score(label, pred))\n",
    "    recalls.append(recall_score(label, pred))\n",
    "print(precisions)\n",
    "print(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1]\n",
    "Y = dataset.iloc[:, -1]\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "n = 10\n",
    "num_train_example = int(len(X_train) / n) \n",
    "for i in range(n):\n",
    "    start = i*num_train_example\n",
    "    end = (i+1)*num_train_example\n",
    "    regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    regressor.fit(X_train[:end], Y_train[:end])\n",
    "    y_train_pred = regressor.predict(X_train[:end])\n",
    "    train_score.append(r2_score(Y_train[:end], y_train_pred))\n",
    "\n",
    "    y_test_pred = regressor.predict(X_test)\n",
    "    test_score.append(r2_score(Y_test, y_test_pred))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(n)], train_score, label=\"train\")\n",
    "plt.plot([i for i in range(n)], test_score, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9e61f8d546329b383339a5a7c490bb93f3c20f31eab98313765141e23006966"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
