{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/m/myu2/anaconda2/envs/bert/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.load(\"/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/multinews_extractive/bert1213/checkpoint-50000/pred/predictions.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5622, 100, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6590,  2.2262],\n",
       "        [ 0.8407, -0.7048],\n",
       "        [-1.9699,  1.8817],\n",
       "        [-3.9118,  3.7355],\n",
       "        [-0.5102,  0.1573],\n",
       "        [-1.0450,  0.8167],\n",
       "        [-0.7691,  0.4873],\n",
       "        [-1.0002,  0.5313],\n",
       "        [ 4.9005, -4.2765],\n",
       "        [ 4.6939, -4.0267],\n",
       "        [ 5.0705, -4.5717],\n",
       "        [ 4.7987, -4.2977],\n",
       "        [ 5.2911, -4.8533],\n",
       "        [ 5.0977, -4.5027],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "b = softmax(a, axis=-1)\n",
    "c = b[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9250e-01, 1.7573e-01, 9.7920e-01, 9.9952e-01, 6.6095e-01, 8.6550e-01,\n",
       "        7.7841e-01, 8.2224e-01, 1.0338e-04, 1.6317e-04, 6.4928e-05, 1.1206e-04,\n",
       "        3.9294e-05, 6.7696e-05, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01,\n",
       "        5.0000e-01, 5.0000e-01, 5.0000e-01, 5.0000e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 10, 13,  ...,  2,  0,  3],\n",
       "        [ 3,  0,  5,  ..., 11, 10, 12],\n",
       "        [ 4,  5,  7,  ...,  9,  1,  2],\n",
       "        ...,\n",
       "        [11,  5,  4,  ...,  6,  1,  8],\n",
       "        [ 8, 14,  4,  ..., 44,  2,  0],\n",
       "        [ 1, 17, 13,  ..., 11,  8,  5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import argsort\n",
    "argsort(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9250e-01, 1.7573e-01, 9.7920e-01, 9.9952e-01, 6.6095e-01, 8.6550e-01,\n",
      "        7.7841e-01, 8.2224e-01, 1.0338e-04, 1.6317e-04, 6.4928e-05, 1.1206e-04,\n",
      "        3.9294e-05, 6.7696e-05, 5.0000e-01])\n",
      "tensor([5.2710e-04, 3.1383e-03, 2.1789e-01, 2.9400e-04, 1.1851e-02, 2.4038e-03,\n",
      "        1.1641e-01, 1.1066e-01, 1.8770e-01, 1.8584e-01, 9.3332e-01, 8.8772e-01,\n",
      "        9.9658e-01, 5.0000e-01, 5.0000e-01])\n",
      "tensor([1.1363e-03, 9.2424e-01, 9.8880e-01, 7.8834e-03, 7.3673e-05, 1.1117e-04,\n",
      "        1.2644e-02, 7.6979e-04, 2.8396e-03, 9.1921e-01, 3.5944e-01, 8.9281e-01,\n",
      "        7.2866e-01, 8.5345e-01, 8.3935e-02, 5.0000e-01])\n",
      "tensor([4.2838e-03, 8.3443e-01, 7.1176e-01, 3.5169e-01, 2.5701e-01, 9.4964e-03,\n",
      "        6.0890e-01, 7.1853e-04, 1.8999e-01, 2.5678e-01, 6.2233e-02, 4.8553e-04,\n",
      "        4.7325e-01, 9.9929e-01, 9.6767e-02, 1.7511e-02, 5.0000e-01, 5.0000e-01,\n",
      "        5.0000e-01])\n",
      "tensor([4.5288e-02, 9.9388e-01, 8.7500e-02, 1.9862e-02, 1.6219e-01, 8.1040e-01,\n",
      "        3.2069e-04, 1.9747e-01, 5.8646e-03, 7.2863e-01, 7.7311e-01, 5.0000e-01])\n",
      "tensor([9.1886e-01, 8.5585e-01, 7.7206e-02, 9.6056e-01, 7.3745e-01, 6.9880e-05,\n",
      "        9.3760e-01, 3.4380e-01, 1.4629e-04, 8.7757e-01, 3.2011e-02, 1.4414e-03,\n",
      "        9.9760e-01, 5.0000e-01])\n",
      "tensor([9.7733e-01, 9.0017e-02, 5.4293e-02, 1.0470e-01, 1.6153e-01, 5.7446e-03,\n",
      "        7.7755e-01, 9.8738e-01, 2.1901e-01, 1.1008e-04, 2.8382e-01, 2.0367e-03,\n",
      "        5.0000e-01, 5.0000e-01])\n",
      "tensor([1.4556e-03, 2.2987e-02, 7.4921e-01, 2.8030e-01, 2.6302e-02, 8.8128e-02,\n",
      "        7.9432e-01, 7.7470e-01, 9.6372e-01, 9.0303e-01, 6.4297e-04, 8.4001e-05,\n",
      "        1.0651e-02, 2.7334e-01, 2.3967e-03])\n",
      "tensor([3.4785e-01, 1.7532e-01, 7.3612e-02, 8.0604e-03, 1.2549e-02, 9.9933e-01,\n",
      "        6.9175e-04, 9.9889e-01, 5.2422e-05, 9.8595e-01, 3.9810e-01])\n",
      "tensor([1.2146e-01, 9.9588e-03, 2.8476e-02, 6.0271e-01, 4.2744e-01, 4.5893e-04,\n",
      "        3.0473e-04, 8.6496e-04, 2.4683e-03, 9.5845e-01, 2.2250e-02, 7.2039e-04,\n",
      "        3.7131e-02, 3.9351e-01, 4.9886e-01, 6.4061e-03, 8.3135e-02, 1.5345e-01,\n",
      "        5.0000e-01])\n",
      "10 10\n",
      "0.36836040056110503 0.08967630642610339 0.16008662071389096\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from numpy import argsort\n",
    "predictions = [] \n",
    "references = []\n",
    "with open(\"/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/downloaded/multi_doc_summ/matchsum_multi-news/test_multinews_brief.json\") as f:\n",
    "    topk = 6\n",
    "    for idx,line in enumerate(f):\n",
    "        if idx == 10:\n",
    "            break\n",
    "        obj = json.loads(line)\n",
    "        labels = obj[\"label\"]\n",
    "        sent_ids = np.arange(0, len(labels), 1)\n",
    "        scores = c[idx][sent_ids]\n",
    "        print(scores)\n",
    "        rank_ids = argsort(scores)[:topk] if len(labels) > topk else argsort(scores)\n",
    "        # print(rank_ids)\n",
    "        selected_sentences = [obj[\"text\"][x] for x in rank_ids]\n",
    "        predictions.append(' '.join(selected_sentences))\n",
    "        references.append(' '.join(obj['summary']))\n",
    "\n",
    "print(len(predictions), len(references))\n",
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge1_all = []\n",
    "rouge2_all = []\n",
    "rougeL_all = []\n",
    "cnt_empty = 0\n",
    "for idx, gold in enumerate(references):\n",
    "\n",
    "    scores = scorer.score(predictions[idx] , gold)\n",
    "    rouge1_all.append(scores[\"rouge1\"][2])\n",
    "    rouge2_all.append(scores[\"rouge2\"][2])\n",
    "    rougeL_all.append(scores[\"rougeL\"][2])\n",
    "print(sum(rouge1_all)/len(rouge1_all), sum(rouge2_all)/len(rouge2_all), sum(rougeL_all)/len(rougeL_all),)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "text = \"los angeles ( ap ) \\u2014 in her first interview since the nba banned her estranged husband , shelly sterling says she will fight to keep her share of the los angeles clippers and plans one day to divorce donald sterling .\"\n",
    "print(len(tokenizer.encode(text)))\n",
    "print(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 14:32:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d8688f04fd1fa4aff304b56e81ea5350d477cdeeb5db0fd8b4cec18bd13a8cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
