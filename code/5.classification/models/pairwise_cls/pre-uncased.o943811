12/20/2022 02:42:50 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
12/20/2022 02:42:50 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/runs/Dec20_02-42-50_ta-a6k-001.crc.nd.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
no_cuda=False,
num_train_epochs=4.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=384,
per_device_train_batch_size=384,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=2,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
12/20/2022 02:42:50 - WARNING - datasets.builder - Using custom data configuration default-ff61733b66cf47a8
12/20/2022 02:42:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.
12/20/2022 02:42:50 - INFO - datasets.info - Loading Dataset info from /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-ff61733b66cf47a8/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253
12/20/2022 02:42:50 - WARNING - datasets.builder - Reusing dataset json (/afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-ff61733b66cf47a8/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)
12/20/2022 02:42:50 - INFO - datasets.info - Loading Dataset info from /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-ff61733b66cf47a8/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253
12/20/2022 02:42:50 - WARNING - datasets.builder - Using custom data configuration default-5854ef2d5edd07c2
12/20/2022 02:42:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.
12/20/2022 02:42:50 - INFO - datasets.info - Loading Dataset info from /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-5854ef2d5edd07c2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253
12/20/2022 02:42:50 - WARNING - datasets.builder - Reusing dataset json (/afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-5854ef2d5edd07c2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)
12/20/2022 02:42:50 - INFO - datasets.info - Loading Dataset info from /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-5854ef2d5edd07c2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253
12/20/2022 02:42:51 - WARNING - datasets.builder - Using custom data configuration default-084e609c7164ba5a
12/20/2022 02:42:51 - INFO - datasets.builder - Overwrite dataset info from restored data version.
12/20/2022 02:42:51 - INFO - datasets.info - Loading Dataset info from /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-084e609c7164ba5a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253
12/20/2022 02:42:51 - WARNING - datasets.builder - Reusing dataset json (/afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-084e609c7164ba5a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)
12/20/2022 02:42:51 - INFO - datasets.info - Loading Dataset info from /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-084e609c7164ba5a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253
[INFO|configuration_utils.py:648] 2022-12-20 02:42:51,224 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2022-12-20 02:42:51,225 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "xnli",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|configuration_utils.py:648] 2022-12-20 02:42:51,471 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2022-12-20 02:42:51,472 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|tokenization_utils_base.py:1786] 2022-12-20 02:42:52,250 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1786] 2022-12-20 02:42:52,251 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|tokenization_utils_base.py:1786] 2022-12-20 02:42:52,251 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1786] 2022-12-20 02:42:52,251 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1786] 2022-12-20 02:42:52,251 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
[INFO|configuration_utils.py:648] 2022-12-20 02:42:52,381 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2022-12-20 02:42:52,382 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1431] 2022-12-20 02:42:52,628 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
[WARNING|modeling_utils.py:1694] 2022-12-20 02:42:53,825 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1705] 2022-12-20 02:42:53,826 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/20/2022 02:42:53 - WARNING - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-ff61733b66cf47a8/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-c764a1ae05a97afe.arrow
Running tokenizer on train dataset #0:   0%|          | 0/13 [00:00<?, ?ba/s]
Running tokenizer on train dataset #1:   0%|          | 0/13 [00:00<?, ?ba/s][A

Running tokenizer on train dataset #2:   0%|          | 0/13 [00:00<?, ?ba/s][A[A


Running tokenizer on train dataset #3:   0%|          | 0/13 [00:00<?, ?ba/s][A[A[A



Running tokenizer on train dataset #4:   0%|          | 0/13 [00:00<?, ?ba/s][A[A[A[A




Running tokenizer on train dataset #5:   0%|          | 0/13 [00:00<?, ?ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:   0%|          | 0/13 [00:00<?, ?ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:   0%|          | 0/13 [00:00<?, ?ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:   0%|          | 0/13 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A








Running tokenizer on train dataset #9:   0%|          | 0/13 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:   8%|▊         | 1/13 [00:00<00:02,  4.11ba/s]
Running tokenizer on train dataset #1:   8%|▊         | 1/13 [00:00<00:03,  3.86ba/s][A

Running tokenizer on train dataset #2:   8%|▊         | 1/13 [00:00<00:03,  3.88ba/s][A[A


Running tokenizer on train dataset #3:   8%|▊         | 1/13 [00:00<00:03,  3.80ba/s][A[A[A



Running tokenizer on train dataset #4:   8%|▊         | 1/13 [00:00<00:03,  3.84ba/s][A[A[A[A




Running tokenizer on train dataset #5:   8%|▊         | 1/13 [00:00<00:03,  3.83ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:   8%|▊         | 1/13 [00:00<00:03,  3.82ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:   8%|▊         | 1/13 [00:00<00:03,  3.85ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:   8%|▊         | 1/13 [00:00<00:03,  3.84ba/s][A[A[A[A[A[A[A[A








Running tokenizer on train dataset #9:   8%|▊         | 1/13 [00:00<00:03,  3.92ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  15%|█▌        | 2/13 [00:00<00:02,  4.12ba/s]
Running tokenizer on train dataset #1:  15%|█▌        | 2/13 [00:00<00:02,  3.99ba/s][A

Running tokenizer on train dataset #2:  15%|█▌        | 2/13 [00:00<00:02,  3.98ba/s][A[A


Running tokenizer on train dataset #3:  15%|█▌        | 2/13 [00:00<00:02,  3.98ba/s][A[A[A



Running tokenizer on train dataset #4:  15%|█▌        | 2/13 [00:00<00:02,  3.99ba/s][A[A[A[A




Running tokenizer on train dataset #5:  15%|█▌        | 2/13 [00:00<00:02,  3.95ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  15%|█▌        | 2/13 [00:00<00:02,  3.97ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:  15%|█▌        | 2/13 [00:00<00:02,  3.96ba/s][A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  15%|█▌        | 2/13 [00:00<00:02,  3.84ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  15%|█▌        | 2/13 [00:00<00:02,  3.74ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  23%|██▎       | 3/13 [00:00<00:02,  4.11ba/s]

Running tokenizer on train dataset #2:  23%|██▎       | 3/13 [00:00<00:02,  4.05ba/s][A[A
Running tokenizer on train dataset #1:  23%|██▎       | 3/13 [00:00<00:02,  3.89ba/s][A



Running tokenizer on train dataset #4:  23%|██▎       | 3/13 [00:00<00:02,  4.06ba/s][A[A[A[A


Running tokenizer on train dataset #3:  23%|██▎       | 3/13 [00:00<00:02,  3.97ba/s][A[A[A




Running tokenizer on train dataset #5:  23%|██▎       | 3/13 [00:00<00:02,  4.02ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  23%|██▎       | 3/13 [00:00<00:02,  3.99ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:  23%|██▎       | 3/13 [00:00<00:02,  4.02ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  23%|██▎       | 3/13 [00:00<00:02,  3.90ba/s][A[A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  23%|██▎       | 3/13 [00:00<00:02,  3.94ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  31%|███       | 4/13 [00:00<00:02,  4.06ba/s]

Running tokenizer on train dataset #2:  31%|███       | 4/13 [00:00<00:02,  4.02ba/s][A[A
Running tokenizer on train dataset #1:  31%|███       | 4/13 [00:01<00:02,  3.94ba/s][A



Running tokenizer on train dataset #4:  31%|███       | 4/13 [00:00<00:02,  4.02ba/s][A[A[A[A


Running tokenizer on train dataset #3:  31%|███       | 4/13 [00:01<00:02,  3.97ba/s][A[A[A




Running tokenizer on train dataset #5:  31%|███       | 4/13 [00:01<00:02,  4.02ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  31%|███       | 4/13 [00:01<00:02,  3.99ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:  31%|███       | 4/13 [00:01<00:02,  3.88ba/s][A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  31%|███       | 4/13 [00:01<00:02,  4.03ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  31%|███       | 4/13 [00:01<00:02,  3.99ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  38%|███▊      | 5/13 [00:01<00:01,  4.06ba/s]

Running tokenizer on train dataset #2:  38%|███▊      | 5/13 [00:01<00:01,  4.05ba/s][A[A
Running tokenizer on train dataset #1:  38%|███▊      | 5/13 [00:01<00:01,  4.00ba/s][A



Running tokenizer on train dataset #4:  38%|███▊      | 5/13 [00:01<00:01,  4.04ba/s][A[A[A[A


Running tokenizer on train dataset #3:  38%|███▊      | 5/13 [00:01<00:02,  3.96ba/s][A[A[A




Running tokenizer on train dataset #5:  38%|███▊      | 5/13 [00:01<00:01,  4.02ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  38%|███▊      | 5/13 [00:01<00:01,  4.04ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:  38%|███▊      | 5/13 [00:01<00:02,  3.92ba/s][A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  38%|███▊      | 5/13 [00:01<00:01,  4.01ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  38%|███▊      | 5/13 [00:01<00:02,  3.94ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  46%|████▌     | 6/13 [00:01<00:01,  4.09ba/s]

Running tokenizer on train dataset #2:  46%|████▌     | 6/13 [00:01<00:01,  4.05ba/s][A[A
Running tokenizer on train dataset #1:  46%|████▌     | 6/13 [00:01<00:01,  4.00ba/s][A



Running tokenizer on train dataset #4:  46%|████▌     | 6/13 [00:01<00:01,  4.00ba/s][A[A[A[A


Running tokenizer on train dataset #3:  46%|████▌     | 6/13 [00:01<00:01,  4.00ba/s][A[A[A




Running tokenizer on train dataset #5:  46%|████▌     | 6/13 [00:01<00:01,  4.03ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  46%|████▌     | 6/13 [00:01<00:01,  4.06ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:  46%|████▌     | 6/13 [00:01<00:01,  3.97ba/s][A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  46%|████▌     | 6/13 [00:01<00:01,  4.05ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  46%|████▌     | 6/13 [00:01<00:01,  3.98ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  54%|█████▍    | 7/13 [00:01<00:01,  4.04ba/s]

Running tokenizer on train dataset #2:  54%|█████▍    | 7/13 [00:01<00:01,  4.06ba/s][A[A
Running tokenizer on train dataset #1:  54%|█████▍    | 7/13 [00:01<00:01,  4.02ba/s][A



Running tokenizer on train dataset #4:  54%|█████▍    | 7/13 [00:01<00:01,  4.02ba/s][A[A[A[A


Running tokenizer on train dataset #3:  54%|█████▍    | 7/13 [00:01<00:01,  4.01ba/s][A[A[A




Running tokenizer on train dataset #5:  54%|█████▍    | 7/13 [00:01<00:01,  4.03ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  54%|█████▍    | 7/13 [00:01<00:01,  4.05ba/s][A[A[A[A[A[A








Running tokenizer on train dataset #9:  54%|█████▍    | 7/13 [00:01<00:01,  4.07ba/s][A[A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  54%|█████▍    | 7/13 [00:01<00:01,  3.99ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  54%|█████▍    | 7/13 [00:01<00:01,  3.96ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  62%|██████▏   | 8/13 [00:01<00:01,  4.05ba/s]

Running tokenizer on train dataset #2:  62%|██████▏   | 8/13 [00:01<00:01,  4.07ba/s][A[A
Running tokenizer on train dataset #1:  62%|██████▏   | 8/13 [00:01<00:01,  4.06ba/s][A



Running tokenizer on train dataset #4:  62%|██████▏   | 8/13 [00:01<00:01,  4.02ba/s][A[A[A[A


Running tokenizer on train dataset #3:  62%|██████▏   | 8/13 [00:02<00:01,  4.01ba/s][A[A[A




Running tokenizer on train dataset #5:  62%|██████▏   | 8/13 [00:01<00:01,  4.05ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  62%|██████▏   | 8/13 [00:01<00:01,  4.09ba/s][A[A[A[A[A[A








Running tokenizer on train dataset #9:  62%|██████▏   | 8/13 [00:01<00:01,  4.08ba/s][A[A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  62%|██████▏   | 8/13 [00:02<00:01,  4.01ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  62%|██████▏   | 8/13 [00:02<00:01,  3.99ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  69%|██████▉   | 9/13 [00:02<00:00,  4.08ba/s]

Running tokenizer on train dataset #2:  69%|██████▉   | 9/13 [00:02<00:00,  4.07ba/s][A[A
Running tokenizer on train dataset #1:  69%|██████▉   | 9/13 [00:02<00:00,  4.06ba/s][A



Running tokenizer on train dataset #4:  69%|██████▉   | 9/13 [00:02<00:00,  4.04ba/s][A[A[A[A


Running tokenizer on train dataset #3:  69%|██████▉   | 9/13 [00:02<00:00,  4.03ba/s][A[A[A




Running tokenizer on train dataset #5:  69%|██████▉   | 9/13 [00:02<00:00,  4.04ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  69%|██████▉   | 9/13 [00:02<00:00,  4.08ba/s][A[A[A[A[A[A








Running tokenizer on train dataset #9:  69%|██████▉   | 9/13 [00:02<00:00,  4.06ba/s][A[A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  69%|██████▉   | 9/13 [00:02<00:00,  4.01ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  69%|██████▉   | 9/13 [00:02<00:00,  4.04ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  77%|███████▋  | 10/13 [00:02<00:00,  4.07ba/s]

Running tokenizer on train dataset #2:  77%|███████▋  | 10/13 [00:02<00:00,  4.07ba/s][A[A
Running tokenizer on train dataset #1:  77%|███████▋  | 10/13 [00:02<00:00,  4.05ba/s][A



Running tokenizer on train dataset #4:  77%|███████▋  | 10/13 [00:02<00:00,  4.05ba/s][A[A[A[A


Running tokenizer on train dataset #3:  77%|███████▋  | 10/13 [00:02<00:00,  4.00ba/s][A[A[A





Running tokenizer on train dataset #6:  77%|███████▋  | 10/13 [00:02<00:00,  4.08ba/s][A[A[A[A[A[A




Running tokenizer on train dataset #5:  77%|███████▋  | 10/13 [00:02<00:00,  4.04ba/s][A[A[A[A[A








Running tokenizer on train dataset #9:  77%|███████▋  | 10/13 [00:02<00:00,  4.07ba/s][A[A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  77%|███████▋  | 10/13 [00:02<00:00,  4.02ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  77%|███████▋  | 10/13 [00:02<00:00,  4.06ba/s][A[A[A[A[A[A[A[A

Running tokenizer on train dataset #2:  85%|████████▍ | 11/13 [00:02<00:00,  3.52ba/s][A[ARunning tokenizer on train dataset #0:  85%|████████▍ | 11/13 [00:02<00:00,  3.38ba/s]
Running tokenizer on train dataset #1:  85%|████████▍ | 11/13 [00:02<00:00,  3.50ba/s][A



Running tokenizer on train dataset #4:  85%|████████▍ | 11/13 [00:02<00:00,  3.53ba/s][A[A[A[A




Running tokenizer on train dataset #5:  85%|████████▍ | 11/13 [00:02<00:00,  3.55ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  85%|████████▍ | 11/13 [00:02<00:00,  3.56ba/s][A[A[A[A[A[A


Running tokenizer on train dataset #3:  85%|████████▍ | 11/13 [00:02<00:00,  3.51ba/s][A[A[A








Running tokenizer on train dataset #9:  85%|████████▍ | 11/13 [00:02<00:00,  3.54ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  85%|████████▍ | 11/13 [00:02<00:00,  3.57ba/s][A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  85%|████████▍ | 11/13 [00:02<00:00,  3.49ba/s][A[A[A[A[A[A[A

Running tokenizer on train dataset #2:  92%|█████████▏| 12/13 [00:03<00:00,  3.65ba/s][A[ARunning tokenizer on train dataset #0:  92%|█████████▏| 12/13 [00:03<00:00,  3.55ba/s]
Running tokenizer on train dataset #1:  92%|█████████▏| 12/13 [00:03<00:00,  3.64ba/s][A



Running tokenizer on train dataset #4:  92%|█████████▏| 12/13 [00:03<00:00,  3.69ba/s][A[A[A[A





Running tokenizer on train dataset #6:  92%|█████████▏| 12/13 [00:03<00:00,  3.70ba/s][A[A[A[A[A[A


Running tokenizer on train dataset #3:  92%|█████████▏| 12/13 [00:03<00:00,  3.67ba/s][A[A[A




Running tokenizer on train dataset #5:  92%|█████████▏| 12/13 [00:03<00:00,  3.69ba/s][A[A[A[A[A








Running tokenizer on train dataset #9:  92%|█████████▏| 12/13 [00:03<00:00,  3.70ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  92%|█████████▏| 12/13 [00:03<00:00,  3.72ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0: 100%|██████████| 13/13 [00:03<00:00,  4.05ba/s]Running tokenizer on train dataset #2: 100%|██████████| 13/13 [00:03<00:00,  4.08ba/s]






Running tokenizer on train dataset #7:  92%|█████████▏| 12/13 [00:03<00:00,  3.65ba/s][A[A[A[A[A[A[ARunning tokenizer on train dataset #1: 100%|██████████| 13/13 [00:03<00:00,  4.04ba/s]Running tokenizer on train dataset #4: 100%|██████████| 13/13 [00:03<00:00,  4.08ba/s]Running tokenizer on train dataset #6: 100%|██████████| 13/13 [00:03<00:00,  4.10ba/s]Running tokenizer on train dataset #3: 100%|██████████| 13/13 [00:03<00:00,  4.05ba/s]Running tokenizer on train dataset #5: 100%|██████████| 13/13 [00:03<00:00,  4.08ba/s]Running tokenizer on train dataset #9: 100%|██████████| 13/13 [00:03<00:00,  4.09ba/s]Running tokenizer on train dataset #8: 100%|██████████| 13/13 [00:03<00:00,  4.06ba/s]Running tokenizer on train dataset #7: 100%|██████████| 13/13 [00:03<00:00,  4.04ba/s]







12/20/2022 02:42:58 - INFO - __main__ - Sample 83810 of the training set: {'id': 'neg_52212_0_78', 'text_e1': 'Chiang Chung-ling (; 21 September 1922 – 18 March 2015) was a Taiwanese army general, former Minister of Defense and Vice Chairman of the Kuomintang (Chinese Nationalist Party).', 'text_e2': 'After the 2004 Presidential election, Soong actively sought the merger of the KMT and People First Party.', 'label': 0, 'input_ids': [101, 100, 100, 1011, 17002, 1006, 1025, 2538, 100, 4798, 1516, 2324, 100, 2325, 1007, 2001, 1037, 100, 2390, 2236, 1010, 2280, 100, 1997, 100, 1998, 100, 100, 1997, 1996, 100, 1006, 100, 100, 100, 1007, 1012, 102, 100, 1996, 2432, 100, 2602, 1010, 100, 8851, 4912, 1996, 7660, 1997, 1996, 100, 1998, 100, 100, 100, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
12/20/2022 02:42:58 - INFO - __main__ - Sample 14592 of the training set: {'id': 'pos_61239_61_89', 'text_e1': 'He then made his managerial debut with the Yankees Double A affiliate Norwich Navigators, and led the team to its first Eastern League Championship.', 'text_e2': "On February 19, 2009, Williams worked out with the Yankees at the team's spring training complex.", 'label': 1, 'input_ids': [101, 100, 2059, 2081, 2010, 24465, 2834, 2007, 1996, 100, 100, 100, 8727, 100, 100, 1010, 1998, 2419, 1996, 2136, 2000, 2049, 2034, 100, 100, 100, 1012, 102, 100, 100, 2539, 1010, 2268, 1010, 100, 2499, 2041, 2007, 1996, 100, 2012, 1996, 2136, 1005, 1055, 3500, 2731, 3375, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
12/20/2022 02:42:58 - INFO - __main__ - Sample 3278 of the training set: {'id': 'pos_64715_25_60', 'text_e1': 'In the early 1950s, Senator Herman Welker of Idaho told Washington Senators owner Clark Griffith about Killebrew, who was hitting for an .847 batting average for a semi-professional baseball team at the time.', 'text_e2': "He was named to the Twins' 40th anniversary team in 2000.", 'label': 1, 'input_ids': [101, 100, 1996, 2220, 4856, 1010, 100, 100, 100, 1997, 100, 2409, 100, 100, 3954, 100, 100, 2055, 100, 1010, 2040, 2001, 7294, 2005, 2019, 1012, 6391, 2581, 9640, 2779, 2005, 1037, 4100, 1011, 2658, 3598, 2136, 2012, 1996, 2051, 1012, 102, 100, 2001, 2315, 2000, 1996, 100, 1005, 16541, 5315, 2136, 1999, 2456, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
Running tokenizer on validation dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]
Running tokenizer on validation dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s][A

Running tokenizer on validation dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s][A[A


Running tokenizer on validation dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A



Running tokenizer on validation dataset #4:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A




Running tokenizer on validation dataset #5:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A





Running tokenizer on validation dataset #6:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A






Running tokenizer on validation dataset #7:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A[A







Running tokenizer on validation dataset #8:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A








Running tokenizer on validation dataset #9:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on validation dataset #0: 100%|██████████| 1/1 [00:00<00:00,  4.76ba/s]Running tokenizer on validation dataset #0: 100%|██████████| 1/1 [00:00<00:00,  4.75ba/s]

Running tokenizer on validation dataset #2: 100%|██████████| 1/1 [00:00<00:00,  4.57ba/s][A[A
Running tokenizer on validation dataset #1: 100%|██████████| 1/1 [00:00<00:00,  4.38ba/s][ARunning tokenizer on validation dataset #2: 100%|██████████| 1/1 [00:00<00:00,  4.56ba/s]Running tokenizer on validation dataset #1: 100%|██████████| 1/1 [00:00<00:00,  4.37ba/s]


Running tokenizer on validation dataset #3: 100%|██████████| 1/1 [00:00<00:00,  4.46ba/s][A[A[ARunning tokenizer on validation dataset #3: 100%|██████████| 1/1 [00:00<00:00,  4.45ba/s]



Running tokenizer on validation dataset #4: 100%|██████████| 1/1 [00:00<00:00,  4.61ba/s][A[A[A[ARunning tokenizer on validation dataset #4: 100%|██████████| 1/1 [00:00<00:00,  4.60ba/s]




Running tokenizer on validation dataset #5: 100%|██████████| 1/1 [00:00<00:00,  4.60ba/s][A[A[A[A[ARunning tokenizer on validation dataset #5: 100%|██████████| 1/1 [00:00<00:00,  4.59ba/s]





Running tokenizer on validation dataset #6: 100%|██████████| 1/1 [00:00<00:00,  4.53ba/s][A[A[A[A[A[ARunning tokenizer on validation dataset #6: 100%|██████████| 1/1 [00:00<00:00,  4.52ba/s]






Running tokenizer on validation dataset #7: 100%|██████████| 1/1 [00:00<00:00,  4.54ba/s][A[A[A[A[A[A[ARunning tokenizer on validation dataset #7: 100%|██████████| 1/1 [00:00<00:00,  4.53ba/s]







Running tokenizer on validation dataset #8: 100%|██████████| 1/1 [00:00<00:00,  4.53ba/s][A[A[A[A[A[A[A[ARunning tokenizer on validation dataset #8: 100%|██████████| 1/1 [00:00<00:00,  4.53ba/s]








Running tokenizer on validation dataset #9: 100%|██████████| 1/1 [00:00<00:00,  4.55ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on validation dataset #9: 100%|██████████| 1/1 [00:00<00:00,  4.54ba/s]








Running tokenizer on prediction dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]
Running tokenizer on prediction dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s][A

Running tokenizer on prediction dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s][A[A


Running tokenizer on prediction dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A



Running tokenizer on prediction dataset #4:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A




Running tokenizer on prediction dataset #5:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A





Running tokenizer on prediction dataset #6:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A






Running tokenizer on prediction dataset #7:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A[A







Running tokenizer on prediction dataset #8:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A








Running tokenizer on prediction dataset #9:   0%|          | 0/1 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on prediction dataset #0: 100%|██████████| 1/1 [00:00<00:00,  5.16ba/s]Running tokenizer on prediction dataset #0: 100%|██████████| 1/1 [00:00<00:00,  5.15ba/s]
Running tokenizer on prediction dataset #1: 100%|██████████| 1/1 [00:00<00:00,  5.22ba/s][ARunning tokenizer on prediction dataset #1: 100%|██████████| 1/1 [00:00<00:00,  5.21ba/s]

Running tokenizer on prediction dataset #2: 100%|██████████| 1/1 [00:00<00:00,  5.26ba/s][A[ARunning tokenizer on prediction dataset #2: 100%|██████████| 1/1 [00:00<00:00,  5.26ba/s]


Running tokenizer on prediction dataset #3: 100%|██████████| 1/1 [00:00<00:00,  5.03ba/s][A[A[ARunning tokenizer on prediction dataset #3: 100%|██████████| 1/1 [00:00<00:00,  5.03ba/s]



Running tokenizer on prediction dataset #4: 100%|██████████| 1/1 [00:00<00:00,  5.16ba/s][A[A[A[ARunning tokenizer on prediction dataset #4: 100%|██████████| 1/1 [00:00<00:00,  5.16ba/s]




Running tokenizer on prediction dataset #5: 100%|██████████| 1/1 [00:00<00:00,  5.11ba/s][A[A[A[A[ARunning tokenizer on prediction dataset #5: 100%|██████████| 1/1 [00:00<00:00,  5.11ba/s]





Running tokenizer on prediction dataset #6: 100%|██████████| 1/1 [00:00<00:00,  5.18ba/s][A[A[A[A[A[ARunning tokenizer on prediction dataset #6: 100%|██████████| 1/1 [00:00<00:00,  5.18ba/s]






Running tokenizer on prediction dataset #7: 100%|██████████| 1/1 [00:00<00:00,  5.27ba/s][A[A[A[A[A[A[ARunning tokenizer on prediction dataset #7: 100%|██████████| 1/1 [00:00<00:00,  5.26ba/s]







Running tokenizer on prediction dataset #8: 100%|██████████| 1/1 [00:00<00:00,  5.08ba/s][A[A[A[A[A[A[A[ARunning tokenizer on prediction dataset #8: 100%|██████████| 1/1 [00:00<00:00,  5.07ba/s]








Running tokenizer on prediction dataset #9: 100%|██████████| 1/1 [00:00<00:00,  4.99ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on prediction dataset #9: 100%|██████████| 1/1 [00:00<00:00,  4.98ba/s]








[INFO|trainer.py:571] 2022-12-20 02:43:01,390 >> The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text_e2, id, text_e1. If text_e2, id, text_e1 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
/afs/crc.nd.edu/user/m/myu2/anaconda2/envs/bert/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
[INFO|trainer.py:1279] 2022-12-20 02:43:01,402 >> ***** Running training *****
[INFO|trainer.py:1280] 2022-12-20 02:43:01,402 >>   Num examples = 123738
[INFO|trainer.py:1281] 2022-12-20 02:43:01,402 >>   Num Epochs = 4
[INFO|trainer.py:1282] 2022-12-20 02:43:01,402 >>   Instantaneous batch size per device = 384
[INFO|trainer.py:1283] 2022-12-20 02:43:01,402 >>   Total train batch size (w. parallel, distributed & accumulation) = 384
[INFO|trainer.py:1284] 2022-12-20 02:43:01,402 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1285] 2022-12-20 02:43:01,402 >>   Total optimization steps = 1292
  0%|          | 0/1292 [00:00<?, ?it/s]  0%|          | 1/1292 [00:02<54:49,  2.55s/it]  0%|          | 2/1292 [00:04<42:42,  1.99s/it]  0%|          | 3/1292 [00:05<38:47,  1.81s/it]  0%|          | 4/1292 [00:07<36:57,  1.72s/it]  0%|          | 5/1292 [00:08<35:57,  1.68s/it]  0%|          | 6/1292 [00:10<35:19,  1.65s/it]  1%|          | 7/1292 [00:12<34:57,  1.63s/it]  1%|          | 8/1292 [00:13<34:42,  1.62s/it]  1%|          | 9/1292 [00:15<34:32,  1.62s/it]  1%|          | 10/1292 [00:16<34:25,  1.61s/it]  1%|          | 11/1292 [00:18<34:20,  1.61s/it]  1%|          | 12/1292 [00:20<34:17,  1.61s/it]  1%|          | 13/1292 [00:21<34:14,  1.61s/it]  1%|          | 14/1292 [00:23<34:12,  1.61s/it]  1%|          | 15/1292 [00:24<34:11,  1.61s/it]  1%|          | 16/1292 [00:26<34:11,  1.61s/it]  1%|▏         | 17/1292 [00:28<34:09,  1.61s/it]  1%|▏         | 18/1292 [00:29<34:04,  1.60s/it]  1%|▏         | 19/1292 [00:31<34:00,  1.60s/it]  2%|▏         | 20/1292 [00:32<33:57,  1.60s/it]  2%|▏         | 21/1292 [00:34<33:54,  1.60s/it]  2%|▏         | 22/1292 [00:36<33:53,  1.60s/it]  2%|▏         | 23/1292 [00:37<33:52,  1.60s/it]  2%|▏         | 24/1292 [00:39<33:52,  1.60s/it]  2%|▏         | 25/1292 [00:40<33:56,  1.61s/it]  2%|▏         | 26/1292 [00:42<33:58,  1.61s/it]  2%|▏         | 27/1292 [00:44<34:00,  1.61s/it]  2%|▏         | 28/1292 [00:45<34:00,  1.61s/it]  2%|▏         | 29/1292 [00:47<34:00,  1.62s/it]  2%|▏         | 30/1292 [00:49<34:00,  1.62s/it]  2%|▏         | 31/1292 [00:50<34:00,  1.62s/it]  2%|▏         | 32/1292 [00:52<34:01,  1.62s/it]  3%|▎         | 33/1292 [00:53<34:00,  1.62s/it]  3%|▎         | 34/1292 [00:55<33:58,  1.62s/it]  3%|▎         | 35/1292 [00:57<33:56,  1.62s/it]  3%|▎         | 36/1292 [00:58<33:54,  1.62s/it]  3%|▎         | 37/1292 [01:00<33:53,  1.62s/it]  3%|▎         | 38/1292 [01:02<33:52,  1.62s/it]  3%|▎         | 39/1292 [01:03<33:51,  1.62s/it]  3%|▎         | 40/1292 [01:05<33:52,  1.62s/it]  3%|▎         | 41/1292 [01:06<33:52,  1.62s/it]  3%|▎         | 42/1292 [01:08<33:52,  1.63s/it]  3%|▎         | 43/1292 [01:10<33:53,  1.63s/it]  3%|▎         | 44/1292 [01:11<33:52,  1.63s/it]  3%|▎         | 45/1292 [01:13<33:51,  1.63s/it]  4%|▎         | 46/1292 [01:15<33:50,  1.63s/it]  4%|▎         | 47/1292 [01:16<33:50,  1.63s/it]  4%|▎         | 48/1292 [01:18<33:50,  1.63s/it]  4%|▍         | 49/1292 [01:19<33:50,  1.63s/it]  4%|▍         | 50/1292 [01:21<33:49,  1.63s/it]  4%|▍         | 51/1292 [01:23<33:49,  1.63s/it]  4%|▍         | 52/1292 [01:24<33:47,  1.64s/it]  4%|▍         | 53/1292 [01:26<33:48,  1.64s/it]  4%|▍         | 54/1292 [01:28<33:47,  1.64s/it]  4%|▍         | 55/1292 [01:29<33:46,  1.64s/it]  4%|▍         | 56/1292 [01:31<33:47,  1.64s/it]  4%|▍         | 57/1292 [01:33<33:46,  1.64s/it]  4%|▍         | 58/1292 [01:34<33:46,  1.64s/it]  5%|▍         | 59/1292 [01:36<33:45,  1.64s/it]  5%|▍         | 60/1292 [01:38<33:44,  1.64s/it]  5%|▍         | 61/1292 [01:39<33:44,  1.64s/it]  5%|▍         | 62/1292 [01:41<33:43,  1.65s/it]  5%|▍         | 63/1292 [01:42<33:42,  1.65s/it]  5%|▍         | 64/1292 [01:44<33:42,  1.65s/it]  5%|▌         | 65/1292 [01:46<33:42,  1.65s/it]  5%|▌         | 66/1292 [01:47<33:41,  1.65s/it]  5%|▌         | 67/1292 [01:49<33:39,  1.65s/it]  5%|▌         | 68/1292 [01:51<33:37,  1.65s/it]  5%|▌         | 69/1292 [01:52<33:36,  1.65s/it]  5%|▌         | 70/1292 [01:54<33:35,  1.65s/it]  5%|▌         | 71/1292 [01:56<33:34,  1.65s/it]  6%|▌         | 72/1292 [01:57<33:32,  1.65s/it]  6%|▌         | 73/1292 [01:59<33:31,  1.65s/it]  6%|▌         | 74/1292 [02:01<33:30,  1.65s/it]  6%|▌         | 75/1292 [02:02<33:30,  1.65s/it]  6%|▌         | 76/1292 [02:04<33:28,  1.65s/it]  6%|▌         | 77/1292 [02:06<33:28,  1.65s/it]  6%|▌         | 78/1292 [02:07<33:26,  1.65s/it]  6%|▌         | 79/1292 [02:09<33:25,  1.65s/it]  6%|▌         | 80/1292 [02:11<33:24,  1.65s/it]  6%|▋         | 81/1292 [02:12<33:22,  1.65s/it]  6%|▋         | 82/1292 [02:14<33:22,  1.65s/it]  6%|▋         | 83/1292 [02:16<33:21,  1.66s/it]  7%|▋         | 84/1292 [02:17<33:20,  1.66s/it]  7%|▋         | 85/1292 [02:19<33:19,  1.66s/it]  7%|▋         | 86/1292 [02:20<33:18,  1.66s/it]  7%|▋         | 87/1292 [02:22<33:17,  1.66s/it]  7%|▋         | 88/1292 [02:24<33:17,  1.66s/it]  7%|▋         | 89/1292 [02:25<33:16,  1.66s/it]  7%|▋         | 90/1292 [02:27<33:14,  1.66s/it]  7%|▋         | 91/1292 [02:29<33:14,  1.66s/it]  7%|▋         | 92/1292 [02:30<33:13,  1.66s/it]  7%|▋         | 93/1292 [02:32<33:12,  1.66s/it]  7%|▋         | 94/1292 [02:34<33:12,  1.66s/it]  7%|▋         | 95/1292 [02:35<33:13,  1.67s/it]  7%|▋         | 96/1292 [02:37<33:12,  1.67s/it]  8%|▊         | 97/1292 [02:39<33:12,  1.67s/it]  8%|▊         | 98/1292 [02:40<33:11,  1.67s/it]  8%|▊         | 99/1292 [02:42<33:11,  1.67s/it]  8%|▊         | 100/1292 [02:44<33:08,  1.67s/it]  8%|▊         | 101/1292 [02:45<33:07,  1.67s/it]  8%|▊         | 102/1292 [02:47<33:07,  1.67s/it]  8%|▊         | 103/1292 [02:49<33:06,  1.67s/it]  8%|▊         | 104/1292 [02:50<33:05,  1.67s/it]  8%|▊         | 105/1292 [02:52<33:04,  1.67s/it]  8%|▊         | 106/1292 [02:54<33:03,  1.67s/it]  8%|▊         | 107/1292 [02:56<33:02,  1.67s/it]  8%|▊         | 108/1292 [02:57<33:00,  1.67s/it]  8%|▊         | 109/1292 [02:59<32:59,  1.67s/it]  9%|▊         | 110/1292 [03:01<32:57,  1.67s/it]  9%|▊         | 111/1292 [03:02<32:55,  1.67s/it]  9%|▊         | 112/1292 [03:04<32:53,  1.67s/it]  9%|▊         | 113/1292 [03:06<32:52,  1.67s/it]  9%|▉         | 114/1292 [03:07<32:52,  1.67s/it]  9%|▉         | 115/1292 [03:09<32:49,  1.67s/it]  9%|▉         | 116/1292 [03:11<32:50,  1.68s/it]  9%|▉         | 117/1292 [03:12<32:48,  1.68s/it]  9%|▉         | 118/1292 [03:14<32:46,  1.67s/it]  9%|▉         | 119/1292 [03:16<32:44,  1.67s/it]  9%|▉         | 120/1292 [03:17<32:43,  1.67s/it]  9%|▉         | 121/1292 [03:19<32:42,  1.68s/it]  9%|▉         | 122/1292 [03:21<32:40,  1.68s/it] 10%|▉         | 123/1292 [03:22<32:37,  1.67s/it] 10%|▉         | 124/1292 [03:24<32:35,  1.67s/it] 10%|▉         | 125/1292 [03:26<32:34,  1.67s/it] 10%|▉         | 126/1292 [03:27<32:33,  1.68s/it] 10%|▉         | 127/1292 [03:29<32:32,  1.68s/it] 10%|▉         | 128/1292 [03:31<32:30,  1.68s/it] 10%|▉         | 129/1292 [03:32<32:27,  1.67s/it] 10%|█         | 130/1292 [03:34<32:26,  1.68s/it] 10%|█         | 131/1292 [03:36<32:26,  1.68s/it] 10%|█         | 132/1292 [03:37<32:24,  1.68s/it] 10%|█         | 133/1292 [03:39<32:23,  1.68s/it] 10%|█         | 134/1292 [03:41<32:22,  1.68s/it] 10%|█         | 135/1292 [03:42<32:21,  1.68s/it] 11%|█         | 136/1292 [03:44<32:18,  1.68s/it] 11%|█         | 137/1292 [03:46<32:17,  1.68s/it] 11%|█         | 138/1292 [03:47<32:16,  1.68s/it] 11%|█         | 139/1292 [03:49<32:14,  1.68s/it] 11%|█         | 140/1292 [03:51<32:12,  1.68s/it] 11%|█         | 141/1292 [03:52<32:10,  1.68s/it] 11%|█         | 142/1292 [03:54<32:09,  1.68s/it] 11%|█         | 143/1292 [03:56<32:08,  1.68s/it] 11%|█         | 144/1292 [03:58<32:07,  1.68s/it] 11%|█         | 145/1292 [03:59<32:06,  1.68s/it] 11%|█▏        | 146/1292 [04:01<32:03,  1.68s/it] 11%|█▏        | 147/1292 [04:03<32:02,  1.68s/it] 11%|█▏        | 148/1292 [04:04<32:01,  1.68s/it] 12%|█▏        | 149/1292 [04:06<31:59,  1.68s/it] 12%|█▏        | 150/1292 [04:08<31:57,  1.68s/it] 12%|█▏        | 151/1292 [04:09<31:56,  1.68s/it] 12%|█▏        | 152/1292 [04:11<31:54,  1.68s/it] 12%|█▏        | 153/1292 [04:13<31:52,  1.68s/it] 12%|█▏        | 154/1292 [04:14<31:51,  1.68s/it] 12%|█▏        | 155/1292 [04:16<31:49,  1.68s/it] 12%|█▏        | 156/1292 [04:18<31:47,  1.68s/it] 12%|█▏        | 157/1292 [04:19<31:45,  1.68s/it] 12%|█▏        | 158/1292 [04:21<31:43,  1.68s/it] 12%|█▏        | 159/1292 [04:23<31:43,  1.68s/it] 12%|█▏        | 160/1292 [04:24<31:41,  1.68s/it] 12%|█▏        | 161/1292 [04:26<31:39,  1.68s/it] 13%|█▎        | 162/1292 [04:28<31:38,  1.68s/it] 13%|█▎        | 163/1292 [04:29<31:36,  1.68s/it] 13%|█▎        | 164/1292 [04:31<31:34,  1.68s/it] 13%|█▎        | 165/1292 [04:33<31:32,  1.68s/it] 13%|█▎        | 166/1292 [04:34<31:31,  1.68s/it] 13%|█▎        | 167/1292 [04:36<31:29,  1.68s/it] 13%|█▎        | 168/1292 [04:38<31:58,  1.71s/it] 13%|█▎        | 169/1292 [04:40<31:47,  1.70s/it] 13%|█▎        | 170/1292 [04:41<31:39,  1.69s/it] 13%|█▎        | 171/1292 [04:43<31:32,  1.69s/it] 13%|█▎        | 172/1292 [04:45<31:28,  1.69s/it] 13%|█▎        | 173/1292 [04:46<31:24,  1.68s/it] 13%|█▎        | 174/1292 [04:48<31:21,  1.68s/it] 14%|█▎        | 175/1292 [04:50<31:18,  1.68s/it] 14%|█▎        | 176/1292 [04:51<31:15,  1.68s/it] 14%|█▎        | 177/1292 [04:53<31:14,  1.68s/it] 14%|█▍        | 178/1292 [04:55<31:12,  1.68s/it] 14%|█▍        | 179/1292 [04:56<31:09,  1.68s/it] 14%|█▍        | 180/1292 [04:58<31:07,  1.68s/it] 14%|█▍        | 181/1292 [05:00<31:05,  1.68s/it] 14%|█▍        | 182/1292 [05:01<31:04,  1.68s/it] 14%|█▍        | 183/1292 [05:03<31:02,  1.68s/it] 14%|█▍        | 184/1292 [05:05<31:01,  1.68s/it] 14%|█▍        | 185/1292 [05:06<30:59,  1.68s/it] 14%|█▍        | 186/1292 [05:08<30:57,  1.68s/it] 14%|█▍        | 187/1292 [05:10<30:55,  1.68s/it] 15%|█▍        | 188/1292 [05:12<30:55,  1.68s/it] 15%|█▍        | 189/1292 [05:13<30:53,  1.68s/it] 15%|█▍        | 190/1292 [05:15<30:51,  1.68s/it] 15%|█▍        | 191/1292 [05:17<30:49,  1.68s/it] 15%|█▍        | 192/1292 [05:18<30:47,  1.68s/it] 15%|█▍        | 193/1292 [05:20<30:46,  1.68s/it] 15%|█▌        | 194/1292 [05:22<30:44,  1.68s/it] 15%|█▌        | 195/1292 [05:23<30:42,  1.68s/it] 15%|█▌        | 196/1292 [05:25<30:41,  1.68s/it] 15%|█▌        | 197/1292 [05:27<30:40,  1.68s/it] 15%|█▌        | 198/1292 [05:28<30:41,  1.68s/it] 15%|█▌        | 199/1292 [05:30<30:39,  1.68s/it] 15%|█▌        | 200/1292 [05:32<30:36,  1.68s/it] 16%|█▌        | 201/1292 [05:33<30:33,  1.68s/it] 16%|█▌        | 202/1292 [05:35<30:31,  1.68s/it] 16%|█▌        | 203/1292 [05:37<30:29,  1.68s/it] 16%|█▌        | 204/1292 [05:38<30:27,  1.68s/it] 16%|█▌        | 205/1292 [05:40<30:26,  1.68s/it] 16%|█▌        | 206/1292 [05:42<30:25,  1.68s/it] 16%|█▌        | 207/1292 [05:43<30:23,  1.68s/it] 16%|█▌        | 208/1292 [05:45<30:21,  1.68s/it] 16%|█▌        | 209/1292 [05:47<30:20,  1.68s/it] 16%|█▋        | 210/1292 [05:48<30:21,  1.68s/it] 16%|█▋        | 211/1292 [05:50<30:19,  1.68s/it] 16%|█▋        | 212/1292 [05:52<30:16,  1.68s/it] 16%|█▋        | 213/1292 [05:54<30:14,  1.68s/it] 17%|█▋        | 214/1292 [05:55<30:12,  1.68s/it] 17%|█▋        | 215/1292 [05:57<30:11,  1.68s/it] 17%|█▋        | 216/1292 [05:59<30:09,  1.68s/it] 17%|█▋        | 217/1292 [06:00<30:08,  1.68s/it] 17%|█▋        | 218/1292 [06:02<30:06,  1.68s/it] 17%|█▋        | 219/1292 [06:04<30:04,  1.68s/it] 17%|█▋        | 220/1292 [06:05<30:03,  1.68s/it] 17%|█▋        | 221/1292 [06:07<30:01,  1.68s/it] 17%|█▋        | 222/1292 [06:09<29:59,  1.68s/it] 17%|█▋        | 223/1292 [06:10<29:57,  1.68s/it] 17%|█▋        | 224/1292 [06:12<29:56,  1.68s/it] 17%|█▋        | 225/1292 [06:14<29:54,  1.68s/it] 17%|█▋        | 226/1292 [06:15<29:54,  1.68s/it] 18%|█▊        | 227/1292 [06:17<29:52,  1.68s/it] 18%|█▊        | 228/1292 [06:19<29:50,  1.68s/it] 18%|█▊        | 229/1292 [06:20<29:49,  1.68s/it] 18%|█▊        | 230/1292 [06:22<29:48,  1.68s/it] 18%|█▊        | 231/1292 [06:24<29:46,  1.68s/it] 18%|█▊        | 232/1292 [06:26<29:44,  1.68s/it] 18%|█▊        | 233/1292 [06:27<29:42,  1.68s/it] 18%|█▊        | 234/1292 [06:29<29:40,  1.68s/it] 18%|█▊        | 235/1292 [06:31<29:38,  1.68s/it] 18%|█▊        | 236/1292 [06:32<29:37,  1.68s/it] 18%|█▊        | 237/1292 [06:34<29:35,  1.68s/it] 18%|█▊        | 238/1292 [06:36<29:34,  1.68s/it] 18%|█▊        | 239/1292 [06:37<29:32,  1.68s/it] 19%|█▊        | 240/1292 [06:39<29:30,  1.68s/it] 19%|█▊        | 241/1292 [06:41<29:29,  1.68s/it] 19%|█▊        | 242/1292 [06:42<29:27,  1.68s/it] 19%|█▉        | 243/1292 [06:44<29:24,  1.68s/it] 19%|█▉        | 244/1292 [06:46<29:23,  1.68s/it] 19%|█▉        | 245/1292 [06:47<29:26,  1.69s/it] 19%|█▉        | 246/1292 [06:49<29:26,  1.69s/it] 19%|█▉        | 247/1292 [06:51<29:24,  1.69s/it] 19%|█▉        | 248/1292 [06:52<29:22,  1.69s/it] 19%|█▉        | 249/1292 [06:54<29:21,  1.69s/it] 19%|█▉        | 250/1292 [06:56<29:18,  1.69s/it] 19%|█▉        | 251/1292 [06:58<29:15,  1.69s/it] 20%|█▉        | 252/1292 [06:59<29:12,  1.68s/it] 20%|█▉        | 253/1292 [07:01<29:10,  1.69s/it] 20%|█▉        | 254/1292 [07:03<29:10,  1.69s/it] 20%|█▉        | 255/1292 [07:04<29:08,  1.69s/it] 20%|█▉        | 256/1292 [07:06<29:06,  1.69s/it] 20%|█▉        | 257/1292 [07:08<29:05,  1.69s/it] 20%|█▉        | 258/1292 [07:09<29:03,  1.69s/it] 20%|██        | 259/1292 [07:11<29:00,  1.69s/it] 20%|██        | 260/1292 [07:13<28:58,  1.68s/it] 20%|██        | 261/1292 [07:14<28:57,  1.69s/it] 20%|██        | 262/1292 [07:16<28:55,  1.69s/it] 20%|██        | 263/1292 [07:18<28:54,  1.69s/it] 20%|██        | 264/1292 [07:19<28:53,  1.69s/it] 21%|██        | 265/1292 [07:21<28:50,  1.68s/it] 21%|██        | 266/1292 [07:23<28:48,  1.68s/it] 21%|██        | 267/1292 [07:24<28:46,  1.68s/it] 21%|██        | 268/1292 [07:26<28:45,  1.68s/it] 21%|██        | 269/1292 [07:28<28:44,  1.69s/it] 21%|██        | 270/1292 [07:30<28:42,  1.69s/it] 21%|██        | 271/1292 [07:31<28:42,  1.69s/it] 21%|██        | 272/1292 [07:33<28:40,  1.69s/it] 21%|██        | 273/1292 [07:35<28:37,  1.69s/it] 21%|██        | 274/1292 [07:36<28:35,  1.69s/it] 21%|██▏       | 275/1292 [07:38<28:34,  1.69s/it] 21%|██▏       | 276/1292 [07:40<28:33,  1.69s/it] 21%|██▏       | 277/1292 [07:41<28:30,  1.69s/it] 22%|██▏       | 278/1292 [07:43<28:28,  1.68s/it] 22%|██▏       | 279/1292 [07:45<28:26,  1.68s/it] 22%|██▏       | 280/1292 [07:46<28:23,  1.68s/it] 22%|██▏       | 281/1292 [07:48<28:21,  1.68s/it] 22%|██▏       | 282/1292 [07:50<28:19,  1.68s/it] 22%|██▏       | 283/1292 [07:51<28:18,  1.68s/it] 22%|██▏       | 284/1292 [07:53<28:18,  1.68s/it] 22%|██▏       | 285/1292 [07:55<28:15,  1.68s/it] 22%|██▏       | 286/1292 [07:56<28:12,  1.68s/it] 22%|██▏       | 287/1292 [07:58<28:12,  1.68s/it] 22%|██▏       | 288/1292 [08:00<28:10,  1.68s/it] 22%|██▏       | 289/1292 [08:02<28:09,  1.68s/it] 22%|██▏       | 290/1292 [08:03<28:07,  1.68s/it] 23%|██▎       | 291/1292 [08:05<28:04,  1.68s/it] 23%|██▎       | 292/1292 [08:07<28:02,  1.68s/it] 23%|██▎       | 293/1292 [08:08<28:01,  1.68s/it] 23%|██▎       | 294/1292 [08:10<28:00,  1.68s/it] 23%|██▎       | 295/1292 [08:12<27:59,  1.68s/it] 23%|██▎       | 296/1292 [08:13<27:57,  1.68s/it] 23%|██▎       | 297/1292 [08:15<27:55,  1.68s/it] 23%|██▎       | 298/1292 [08:17<27:53,  1.68s/it] 23%|██▎       | 299/1292 [08:18<27:50,  1.68s/it] 23%|██▎       | 300/1292 [08:20<27:49,  1.68s/it] 23%|██▎       | 301/1292 [08:22<27:47,  1.68s/it] 23%|██▎       | 302/1292 [08:23<27:45,  1.68s/it] 23%|██▎       | 303/1292 [08:25<27:45,  1.68s/it] 24%|██▎       | 304/1292 [08:27<27:43,  1.68s/it] 24%|██▎       | 305/1292 [08:28<27:41,  1.68s/it] 24%|██▎       | 306/1292 [08:30<27:39,  1.68s/it] 24%|██▍       | 307/1292 [08:32<27:38,  1.68s/it] 24%|██▍       | 308/1292 [08:34<27:37,  1.68s/it] 24%|██▍       | 309/1292 [08:35<27:35,  1.68s/it] 24%|██▍       | 310/1292 [08:37<27:33,  1.68s/it] 24%|██▍       | 311/1292 [08:39<27:31,  1.68s/it] 24%|██▍       | 312/1292 [08:40<27:29,  1.68s/it] 24%|██▍       | 313/1292 [08:42<27:29,  1.68s/it] 24%|██▍       | 314/1292 [08:44<27:27,  1.68s/it] 24%|██▍       | 315/1292 [08:45<27:24,  1.68s/it] 24%|██▍       | 316/1292 [08:47<27:22,  1.68s/it] 25%|██▍       | 317/1292 [08:49<27:19,  1.68s/it] 25%|██▍       | 318/1292 [08:50<27:18,  1.68s/it] 25%|██▍       | 319/1292 [08:52<27:17,  1.68s/it] 25%|██▍       | 320/1292 [08:54<27:16,  1.68s/it] 25%|██▍       | 321/1292 [08:55<27:14,  1.68s/it] 25%|██▍       | 322/1292 [08:57<27:12,  1.68s/it] 25%|██▌       | 323/1292 [08:58<21:10,  1.31s/it]                                                   25%|██▌       | 323/1292 [08:58<21:10,  1.31s/it][INFO|trainer.py:571] 2022-12-20 02:51:59,452 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text_e2, id, text_e1. If text_e2, id, text_e1 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:2389] 2022-12-20 02:51:59,457 >> ***** Running Evaluation *****
[INFO|trainer.py:2391] 2022-12-20 02:51:59,457 >>   Num examples = 8792
[INFO|trainer.py:2394] 2022-12-20 02:51:59,457 >>   Batch size = 384
{'loss': 0.1903, 'learning_rate': 2.25e-05, 'epoch': 1.0}

  0%|          | 0/23 [00:00<?, ?it/s][A
  9%|▊         | 2/23 [00:00<00:07,  2.98it/s][A
 13%|█▎        | 3/23 [00:01<00:09,  2.11it/s][A
 17%|█▋        | 4/23 [00:02<00:10,  1.83it/s][A
 22%|██▏       | 5/23 [00:02<00:10,  1.70it/s][A
 26%|██▌       | 6/23 [00:03<00:10,  1.62it/s][A
 30%|███       | 7/23 [00:04<00:10,  1.58it/s][A
 35%|███▍      | 8/23 [00:04<00:09,  1.55it/s][A
 39%|███▉      | 9/23 [00:05<00:09,  1.53it/s][A
 43%|████▎     | 10/23 [00:06<00:08,  1.52it/s][A
 48%|████▊     | 11/23 [00:06<00:07,  1.51it/s][A
 52%|█████▏    | 12/23 [00:07<00:07,  1.51it/s][A
 57%|█████▋    | 13/23 [00:08<00:06,  1.50it/s][A
 61%|██████    | 14/23 [00:08<00:06,  1.50it/s][A
 65%|██████▌   | 15/23 [00:09<00:05,  1.50it/s][A
 70%|██████▉   | 16/23 [00:10<00:04,  1.50it/s][A
 74%|███████▍  | 17/23 [00:10<00:04,  1.50it/s][A
 78%|███████▊  | 18/23 [00:11<00:03,  1.50it/s][A
 83%|████████▎ | 19/23 [00:12<00:02,  1.50it/s][A
 87%|████████▋ | 20/23 [00:12<00:02,  1.50it/s][A
 91%|█████████▏| 21/23 [00:13<00:01,  1.49it/s][A
 96%|█████████▌| 22/23 [00:14<00:00,  1.49it/s][A
100%|██████████| 23/23 [00:14<00:00,  1.54it/s][A                                                  
                                               [A 25%|██▌       | 323/1292 [09:13<21:10,  1.31s/it]
100%|██████████| 23/23 [00:14<00:00,  1.54it/s][A
                                               [A[INFO|trainer.py:2139] 2022-12-20 02:52:14,845 >> Saving model checkpoint to /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-323
[INFO|configuration_utils.py:439] 2022-12-20 02:52:14,847 >> Configuration saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-323/config.json
[INFO|modeling_utils.py:1084] 2022-12-20 02:52:17,538 >> Model weights saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-323/pytorch_model.bin
[INFO|tokenization_utils_base.py:2094] 2022-12-20 02:52:17,539 >> tokenizer config file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-323/tokenizer_config.json
[INFO|tokenization_utils_base.py:2100] 2022-12-20 02:52:17,540 >> Special tokens file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-323/special_tokens_map.json
 25%|██▌       | 324/1292 [09:23<2:16:48,  8.48s/it] 25%|██▌       | 325/1292 [09:24<1:43:42,  6.43s/it] 25%|██▌       | 326/1292 [09:26<1:20:35,  5.01s/it] 25%|██▌       | 327/1292 [09:28<1:04:23,  4.00s/it] 25%|██▌       | 328/1292 [09:29<53:05,  3.30s/it]   25%|██▌       | 329/1292 [09:31<45:10,  2.82s/it] 26%|██▌       | 330/1292 [09:33<39:37,  2.47s/it] 26%|██▌       | 331/1292 [09:34<35:43,  2.23s/it] 26%|██▌       | 332/1292 [09:36<32:59,  2.06s/it] 26%|██▌       | 333/1292 [09:38<31:04,  1.94s/it] 26%|██▌       | 334/1292 [09:39<29:44,  1.86s/it] 26%|██▌       | 335/1292 [09:41<28:49,  1.81s/it] 26%|██▌       | 336/1292 [09:43<28:11,  1.77s/it] 26%|██▌       | 337/1292 [09:44<27:43,  1.74s/it] 26%|██▌       | 338/1292 [09:46<27:21,  1.72s/it] 26%|██▌       | 339/1292 [09:48<27:06,  1.71s/it] 26%|██▋       | 340/1292 [09:50<26:55,  1.70s/it] 26%|██▋       | 341/1292 [09:51<26:47,  1.69s/it] 26%|██▋       | 342/1292 [09:53<26:41,  1.69s/it] 27%|██▋       | 343/1292 [09:55<26:36,  1.68s/it] 27%|██▋       | 344/1292 [09:56<26:33,  1.68s/it] 27%|██▋       | 345/1292 [09:58<26:31,  1.68s/it] 27%|██▋       | 346/1292 [10:00<26:28,  1.68s/it] 27%|██▋       | 347/1292 [10:01<26:26,  1.68s/it] 27%|██▋       | 348/1292 [10:03<26:23,  1.68s/it] 27%|██▋       | 349/1292 [10:05<26:22,  1.68s/it] 27%|██▋       | 350/1292 [10:06<26:20,  1.68s/it] 27%|██▋       | 351/1292 [10:08<26:18,  1.68s/it] 27%|██▋       | 352/1292 [10:10<26:16,  1.68s/it] 27%|██▋       | 353/1292 [10:11<26:14,  1.68s/it] 27%|██▋       | 354/1292 [10:13<26:13,  1.68s/it] 27%|██▋       | 355/1292 [10:15<26:12,  1.68s/it] 28%|██▊       | 356/1292 [10:16<26:10,  1.68s/it] 28%|██▊       | 357/1292 [10:18<26:08,  1.68s/it] 28%|██▊       | 358/1292 [10:20<26:06,  1.68s/it] 28%|██▊       | 359/1292 [10:21<26:04,  1.68s/it] 28%|██▊       | 360/1292 [10:23<26:02,  1.68s/it] 28%|██▊       | 361/1292 [10:25<26:01,  1.68s/it] 28%|██▊       | 362/1292 [10:26<26:00,  1.68s/it] 28%|██▊       | 363/1292 [10:28<25:59,  1.68s/it] 28%|██▊       | 364/1292 [10:30<25:57,  1.68s/it] 28%|██▊       | 365/1292 [10:31<25:56,  1.68s/it] 28%|██▊       | 366/1292 [10:33<25:54,  1.68s/it] 28%|██▊       | 367/1292 [10:35<25:53,  1.68s/it] 28%|██▊       | 368/1292 [10:36<25:52,  1.68s/it] 29%|██▊       | 369/1292 [10:38<25:50,  1.68s/it] 29%|██▊       | 370/1292 [10:40<25:48,  1.68s/it] 29%|██▊       | 371/1292 [10:42<25:47,  1.68s/it] 29%|██▉       | 372/1292 [10:43<25:45,  1.68s/it] 29%|██▉       | 373/1292 [10:45<25:43,  1.68s/it] 29%|██▉       | 374/1292 [10:47<25:41,  1.68s/it] 29%|██▉       | 375/1292 [10:48<25:39,  1.68s/it] 29%|██▉       | 376/1292 [10:50<25:38,  1.68s/it] 29%|██▉       | 377/1292 [10:52<25:37,  1.68s/it] 29%|██▉       | 378/1292 [10:53<25:36,  1.68s/it] 29%|██▉       | 379/1292 [10:55<25:33,  1.68s/it] 29%|██▉       | 380/1292 [10:57<25:32,  1.68s/it] 29%|██▉       | 381/1292 [10:58<25:30,  1.68s/it] 30%|██▉       | 382/1292 [11:00<25:30,  1.68s/it] 30%|██▉       | 383/1292 [11:02<25:28,  1.68s/it] 30%|██▉       | 384/1292 [11:03<25:26,  1.68s/it] 30%|██▉       | 385/1292 [11:05<25:23,  1.68s/it] 30%|██▉       | 386/1292 [11:07<25:22,  1.68s/it] 30%|██▉       | 387/1292 [11:08<25:20,  1.68s/it] 30%|███       | 388/1292 [11:10<25:18,  1.68s/it] 30%|███       | 389/1292 [11:12<25:16,  1.68s/it] 30%|███       | 390/1292 [11:13<25:15,  1.68s/it] 30%|███       | 391/1292 [11:15<25:14,  1.68s/it] 30%|███       | 392/1292 [11:17<25:14,  1.68s/it] 30%|███       | 393/1292 [11:18<25:12,  1.68s/it] 30%|███       | 394/1292 [11:20<25:10,  1.68s/it] 31%|███       | 395/1292 [11:22<25:08,  1.68s/it] 31%|███       | 396/1292 [11:24<25:06,  1.68s/it] 31%|███       | 397/1292 [11:25<25:04,  1.68s/it] 31%|███       | 398/1292 [11:27<25:02,  1.68s/it] 31%|███       | 399/1292 [11:29<25:00,  1.68s/it] 31%|███       | 400/1292 [11:30<24:59,  1.68s/it] 31%|███       | 401/1292 [11:32<24:58,  1.68s/it] 31%|███       | 402/1292 [11:34<24:56,  1.68s/it] 31%|███       | 403/1292 [11:35<24:55,  1.68s/it] 31%|███▏      | 404/1292 [11:37<24:53,  1.68s/it] 31%|███▏      | 405/1292 [11:39<24:51,  1.68s/it] 31%|███▏      | 406/1292 [11:40<24:49,  1.68s/it] 32%|███▏      | 407/1292 [11:42<24:47,  1.68s/it] 32%|███▏      | 408/1292 [11:44<24:45,  1.68s/it] 32%|███▏      | 409/1292 [11:45<24:43,  1.68s/it] 32%|███▏      | 410/1292 [11:47<24:41,  1.68s/it] 32%|███▏      | 411/1292 [11:49<24:39,  1.68s/it] 32%|███▏      | 412/1292 [11:50<24:38,  1.68s/it] 32%|███▏      | 413/1292 [11:52<24:37,  1.68s/it] 32%|███▏      | 414/1292 [11:54<24:35,  1.68s/it] 32%|███▏      | 415/1292 [11:55<24:33,  1.68s/it] 32%|███▏      | 416/1292 [11:57<24:33,  1.68s/it] 32%|███▏      | 417/1292 [11:59<24:31,  1.68s/it] 32%|███▏      | 418/1292 [12:01<24:29,  1.68s/it] 32%|███▏      | 419/1292 [12:02<24:28,  1.68s/it] 33%|███▎      | 420/1292 [12:04<24:27,  1.68s/it] 33%|███▎      | 421/1292 [12:06<24:24,  1.68s/it] 33%|███▎      | 422/1292 [12:07<24:22,  1.68s/it] 33%|███▎      | 423/1292 [12:09<24:20,  1.68s/it] 33%|███▎      | 424/1292 [12:11<24:18,  1.68s/it] 33%|███▎      | 425/1292 [12:12<24:16,  1.68s/it] 33%|███▎      | 426/1292 [12:14<24:15,  1.68s/it] 33%|███▎      | 427/1292 [12:16<24:13,  1.68s/it] 33%|███▎      | 428/1292 [12:17<24:11,  1.68s/it] 33%|███▎      | 429/1292 [12:19<24:10,  1.68s/it] 33%|███▎      | 430/1292 [12:21<24:09,  1.68s/it] 33%|███▎      | 431/1292 [12:22<24:07,  1.68s/it] 33%|███▎      | 432/1292 [12:24<24:06,  1.68s/it] 34%|███▎      | 433/1292 [12:26<24:05,  1.68s/it] 34%|███▎      | 434/1292 [12:27<24:02,  1.68s/it] 34%|███▎      | 435/1292 [12:29<24:00,  1.68s/it] 34%|███▎      | 436/1292 [12:31<23:59,  1.68s/it] 34%|███▍      | 437/1292 [12:32<23:57,  1.68s/it] 34%|███▍      | 438/1292 [12:34<23:56,  1.68s/it] 34%|███▍      | 439/1292 [12:36<23:55,  1.68s/it] 34%|███▍      | 440/1292 [12:38<23:54,  1.68s/it] 34%|███▍      | 441/1292 [12:39<23:52,  1.68s/it] 34%|███▍      | 442/1292 [12:41<23:50,  1.68s/it] 34%|███▍      | 443/1292 [12:43<23:49,  1.68s/it] 34%|███▍      | 444/1292 [12:44<23:48,  1.68s/it] 34%|███▍      | 445/1292 [12:46<23:45,  1.68s/it] 35%|███▍      | 446/1292 [12:48<23:43,  1.68s/it] 35%|███▍      | 447/1292 [12:49<23:40,  1.68s/it] 35%|███▍      | 448/1292 [12:51<23:38,  1.68s/it] 35%|███▍      | 449/1292 [12:53<23:37,  1.68s/it] 35%|███▍      | 450/1292 [12:54<23:35,  1.68s/it] 35%|███▍      | 451/1292 [12:56<23:33,  1.68s/it] 35%|███▍      | 452/1292 [12:58<23:32,  1.68s/it] 35%|███▌      | 453/1292 [12:59<23:31,  1.68s/it] 35%|███▌      | 454/1292 [13:01<23:29,  1.68s/it] 35%|███▌      | 455/1292 [13:03<23:28,  1.68s/it] 35%|███▌      | 456/1292 [13:04<23:26,  1.68s/it] 35%|███▌      | 457/1292 [13:06<23:24,  1.68s/it] 35%|███▌      | 458/1292 [13:08<23:22,  1.68s/it] 36%|███▌      | 459/1292 [13:09<23:21,  1.68s/it] 36%|███▌      | 460/1292 [13:11<23:20,  1.68s/it] 36%|███▌      | 461/1292 [13:13<23:19,  1.68s/it] 36%|███▌      | 462/1292 [13:15<23:17,  1.68s/it] 36%|███▌      | 463/1292 [13:16<23:14,  1.68s/it] 36%|███▌      | 464/1292 [13:18<23:12,  1.68s/it] 36%|███▌      | 465/1292 [13:20<23:11,  1.68s/it] 36%|███▌      | 466/1292 [13:21<23:10,  1.68s/it] 36%|███▌      | 467/1292 [13:23<23:08,  1.68s/it] 36%|███▌      | 468/1292 [13:25<23:06,  1.68s/it] 36%|███▋      | 469/1292 [13:26<23:04,  1.68s/it] 36%|███▋      | 470/1292 [13:28<23:02,  1.68s/it] 36%|███▋      | 471/1292 [13:30<23:00,  1.68s/it] 37%|███▋      | 472/1292 [13:31<22:59,  1.68s/it] 37%|███▋      | 473/1292 [13:33<22:58,  1.68s/it] 37%|███▋      | 474/1292 [13:35<22:57,  1.68s/it] 37%|███▋      | 475/1292 [13:36<22:54,  1.68s/it] 37%|███▋      | 476/1292 [13:38<22:52,  1.68s/it] 37%|███▋      | 477/1292 [13:40<22:50,  1.68s/it] 37%|███▋      | 478/1292 [13:41<22:48,  1.68s/it] 37%|███▋      | 479/1292 [13:43<22:46,  1.68s/it] 37%|███▋      | 480/1292 [13:45<22:44,  1.68s/it] 37%|███▋      | 481/1292 [13:46<22:42,  1.68s/it] 37%|███▋      | 482/1292 [13:48<22:42,  1.68s/it] 37%|███▋      | 483/1292 [13:50<22:41,  1.68s/it] 37%|███▋      | 484/1292 [13:52<22:40,  1.68s/it] 38%|███▊      | 485/1292 [13:53<22:37,  1.68s/it] 38%|███▊      | 486/1292 [13:55<22:36,  1.68s/it] 38%|███▊      | 487/1292 [13:57<22:35,  1.68s/it] 38%|███▊      | 488/1292 [13:58<22:33,  1.68s/it] 38%|███▊      | 489/1292 [14:00<22:31,  1.68s/it] 38%|███▊      | 490/1292 [14:02<22:28,  1.68s/it] 38%|███▊      | 491/1292 [14:03<22:26,  1.68s/it] 38%|███▊      | 492/1292 [14:05<22:24,  1.68s/it] 38%|███▊      | 493/1292 [14:07<22:23,  1.68s/it] 38%|███▊      | 494/1292 [14:08<22:21,  1.68s/it] 38%|███▊      | 495/1292 [14:10<22:19,  1.68s/it] 38%|███▊      | 496/1292 [14:12<22:18,  1.68s/it] 38%|███▊      | 497/1292 [14:13<22:16,  1.68s/it] 39%|███▊      | 498/1292 [14:15<22:15,  1.68s/it] 39%|███▊      | 499/1292 [14:17<22:13,  1.68s/it] 39%|███▊      | 500/1292 [14:18<22:12,  1.68s/it] 39%|███▉      | 501/1292 [14:20<22:11,  1.68s/it] 39%|███▉      | 502/1292 [14:22<22:09,  1.68s/it] 39%|███▉      | 503/1292 [14:23<22:08,  1.68s/it] 39%|███▉      | 504/1292 [14:25<22:06,  1.68s/it] 39%|███▉      | 505/1292 [14:27<22:04,  1.68s/it] 39%|███▉      | 506/1292 [14:29<22:02,  1.68s/it] 39%|███▉      | 507/1292 [14:30<22:00,  1.68s/it] 39%|███▉      | 508/1292 [14:32<21:57,  1.68s/it] 39%|███▉      | 509/1292 [14:34<21:56,  1.68s/it] 39%|███▉      | 510/1292 [14:35<21:55,  1.68s/it] 40%|███▉      | 511/1292 [14:37<21:53,  1.68s/it] 40%|███▉      | 512/1292 [14:39<21:52,  1.68s/it] 40%|███▉      | 513/1292 [14:40<21:50,  1.68s/it] 40%|███▉      | 514/1292 [14:42<21:48,  1.68s/it] 40%|███▉      | 515/1292 [14:44<21:46,  1.68s/it] 40%|███▉      | 516/1292 [14:45<21:44,  1.68s/it] 40%|████      | 517/1292 [14:47<21:43,  1.68s/it] 40%|████      | 518/1292 [14:49<21:41,  1.68s/it] 40%|████      | 519/1292 [14:50<21:41,  1.68s/it] 40%|████      | 520/1292 [14:52<21:39,  1.68s/it] 40%|████      | 521/1292 [14:54<21:36,  1.68s/it] 40%|████      | 522/1292 [14:55<21:34,  1.68s/it] 40%|████      | 523/1292 [14:57<21:33,  1.68s/it] 41%|████      | 524/1292 [14:59<21:31,  1.68s/it] 41%|████      | 525/1292 [15:00<21:30,  1.68s/it] 41%|████      | 526/1292 [15:02<21:28,  1.68s/it] 41%|████      | 527/1292 [15:04<21:45,  1.71s/it] 41%|████      | 528/1292 [15:06<21:38,  1.70s/it] 41%|████      | 529/1292 [15:07<21:33,  1.70s/it] 41%|████      | 530/1292 [15:09<21:29,  1.69s/it] 41%|████      | 531/1292 [15:11<21:25,  1.69s/it] 41%|████      | 532/1292 [15:12<21:21,  1.69s/it] 41%|████▏     | 533/1292 [15:14<21:19,  1.69s/it] 41%|████▏     | 534/1292 [15:16<21:16,  1.68s/it] 41%|████▏     | 535/1292 [15:17<21:14,  1.68s/it] 41%|████▏     | 536/1292 [15:19<21:11,  1.68s/it] 42%|████▏     | 537/1292 [15:21<21:09,  1.68s/it] 42%|████▏     | 538/1292 [15:22<21:07,  1.68s/it] 42%|████▏     | 539/1292 [15:24<21:05,  1.68s/it] 42%|████▏     | 540/1292 [15:26<21:03,  1.68s/it] 42%|████▏     | 541/1292 [15:27<21:01,  1.68s/it] 42%|████▏     | 542/1292 [15:29<20:59,  1.68s/it] 42%|████▏     | 543/1292 [15:31<20:58,  1.68s/it] 42%|████▏     | 544/1292 [15:33<20:56,  1.68s/it] 42%|████▏     | 545/1292 [15:34<20:55,  1.68s/it] 42%|████▏     | 546/1292 [15:36<20:53,  1.68s/it] 42%|████▏     | 547/1292 [15:38<20:51,  1.68s/it] 42%|████▏     | 548/1292 [15:39<20:50,  1.68s/it] 42%|████▏     | 549/1292 [15:41<20:49,  1.68s/it] 43%|████▎     | 550/1292 [15:43<20:48,  1.68s/it] 43%|████▎     | 551/1292 [15:44<20:46,  1.68s/it] 43%|████▎     | 552/1292 [15:46<20:43,  1.68s/it] 43%|████▎     | 553/1292 [15:48<20:42,  1.68s/it] 43%|████▎     | 554/1292 [15:49<20:40,  1.68s/it] 43%|████▎     | 555/1292 [15:51<20:38,  1.68s/it] 43%|████▎     | 556/1292 [15:53<20:36,  1.68s/it] 43%|████▎     | 557/1292 [15:54<20:34,  1.68s/it] 43%|████▎     | 558/1292 [15:56<20:33,  1.68s/it] 43%|████▎     | 559/1292 [15:58<20:31,  1.68s/it] 43%|████▎     | 560/1292 [15:59<20:31,  1.68s/it] 43%|████▎     | 561/1292 [16:01<20:29,  1.68s/it] 43%|████▎     | 562/1292 [16:03<20:33,  1.69s/it] 44%|████▎     | 563/1292 [16:04<20:30,  1.69s/it] 44%|████▎     | 564/1292 [16:06<20:27,  1.69s/it] 44%|████▎     | 565/1292 [16:08<20:24,  1.68s/it] 44%|████▍     | 566/1292 [16:10<20:28,  1.69s/it] 44%|████▍     | 567/1292 [16:11<20:24,  1.69s/it] 44%|████▍     | 568/1292 [16:13<20:21,  1.69s/it] 44%|████▍     | 569/1292 [16:15<20:19,  1.69s/it] 44%|████▍     | 570/1292 [16:16<20:16,  1.69s/it] 44%|████▍     | 571/1292 [16:18<20:14,  1.68s/it] 44%|████▍     | 572/1292 [16:20<20:12,  1.68s/it] 44%|████▍     | 573/1292 [16:21<20:10,  1.68s/it] 44%|████▍     | 574/1292 [16:23<20:08,  1.68s/it] 45%|████▍     | 575/1292 [16:25<20:07,  1.68s/it] 45%|████▍     | 576/1292 [16:26<20:05,  1.68s/it] 45%|████▍     | 577/1292 [16:28<20:03,  1.68s/it] 45%|████▍     | 578/1292 [16:30<20:01,  1.68s/it] 45%|████▍     | 579/1292 [16:31<20:00,  1.68s/it] 45%|████▍     | 580/1292 [16:33<19:59,  1.68s/it] 45%|████▍     | 581/1292 [16:35<19:57,  1.68s/it] 45%|████▌     | 582/1292 [16:36<19:55,  1.68s/it] 45%|████▌     | 583/1292 [16:38<19:53,  1.68s/it] 45%|████▌     | 584/1292 [16:40<19:53,  1.69s/it] 45%|████▌     | 585/1292 [16:42<19:50,  1.68s/it] 45%|████▌     | 586/1292 [16:43<19:48,  1.68s/it] 45%|████▌     | 587/1292 [16:45<19:46,  1.68s/it] 46%|████▌     | 588/1292 [16:47<19:45,  1.68s/it] 46%|████▌     | 589/1292 [16:48<19:43,  1.68s/it] 46%|████▌     | 590/1292 [16:50<19:42,  1.68s/it] 46%|████▌     | 591/1292 [16:52<19:39,  1.68s/it] 46%|████▌     | 592/1292 [16:53<19:37,  1.68s/it] 46%|████▌     | 593/1292 [16:55<19:36,  1.68s/it] 46%|████▌     | 594/1292 [16:57<19:34,  1.68s/it] 46%|████▌     | 595/1292 [16:58<19:32,  1.68s/it] 46%|████▌     | 596/1292 [17:00<19:30,  1.68s/it] 46%|████▌     | 597/1292 [17:02<19:29,  1.68s/it] 46%|████▋     | 598/1292 [17:03<19:27,  1.68s/it] 46%|████▋     | 599/1292 [17:05<19:25,  1.68s/it] 46%|████▋     | 600/1292 [17:07<19:23,  1.68s/it] 47%|████▋     | 601/1292 [17:08<19:21,  1.68s/it] 47%|████▋     | 602/1292 [17:10<19:20,  1.68s/it] 47%|████▋     | 603/1292 [17:12<19:19,  1.68s/it] 47%|████▋     | 604/1292 [17:14<19:18,  1.68s/it] 47%|████▋     | 605/1292 [17:15<19:15,  1.68s/it] 47%|████▋     | 606/1292 [17:17<19:14,  1.68s/it] 47%|████▋     | 607/1292 [17:19<19:12,  1.68s/it] 47%|████▋     | 608/1292 [17:20<19:10,  1.68s/it] 47%|████▋     | 609/1292 [17:22<19:08,  1.68s/it] 47%|████▋     | 610/1292 [17:24<19:07,  1.68s/it] 47%|████▋     | 611/1292 [17:25<19:06,  1.68s/it] 47%|████▋     | 612/1292 [17:27<19:04,  1.68s/it] 47%|████▋     | 613/1292 [17:29<19:02,  1.68s/it] 48%|████▊     | 614/1292 [17:30<19:00,  1.68s/it] 48%|████▊     | 615/1292 [17:32<18:58,  1.68s/it] 48%|████▊     | 616/1292 [17:34<18:58,  1.68s/it] 48%|████▊     | 617/1292 [17:35<18:57,  1.69s/it] 48%|████▊     | 618/1292 [17:37<18:56,  1.69s/it] 48%|████▊     | 619/1292 [17:39<18:53,  1.68s/it] 48%|████▊     | 620/1292 [17:40<18:51,  1.68s/it] 48%|████▊     | 621/1292 [17:42<18:49,  1.68s/it] 48%|████▊     | 622/1292 [17:44<18:47,  1.68s/it] 48%|████▊     | 623/1292 [17:45<18:45,  1.68s/it] 48%|████▊     | 624/1292 [17:47<18:43,  1.68s/it] 48%|████▊     | 625/1292 [17:49<18:41,  1.68s/it] 48%|████▊     | 626/1292 [17:51<18:40,  1.68s/it] 49%|████▊     | 627/1292 [17:52<18:38,  1.68s/it] 49%|████▊     | 628/1292 [17:54<18:36,  1.68s/it] 49%|████▊     | 629/1292 [17:56<18:35,  1.68s/it] 49%|████▉     | 630/1292 [17:57<18:34,  1.68s/it] 49%|████▉     | 631/1292 [17:59<18:31,  1.68s/it] 49%|████▉     | 632/1292 [18:01<18:29,  1.68s/it] 49%|████▉     | 633/1292 [18:02<18:27,  1.68s/it] 49%|████▉     | 634/1292 [18:04<18:25,  1.68s/it] 49%|████▉     | 635/1292 [18:06<18:24,  1.68s/it] 49%|████▉     | 636/1292 [18:07<18:22,  1.68s/it] 49%|████▉     | 637/1292 [18:09<18:21,  1.68s/it] 49%|████▉     | 638/1292 [18:11<18:19,  1.68s/it] 49%|████▉     | 639/1292 [18:12<18:18,  1.68s/it] 50%|████▉     | 640/1292 [18:14<18:16,  1.68s/it] 50%|████▉     | 641/1292 [18:16<18:14,  1.68s/it] 50%|████▉     | 642/1292 [18:17<18:13,  1.68s/it] 50%|████▉     | 643/1292 [18:19<18:10,  1.68s/it] 50%|████▉     | 644/1292 [18:21<18:09,  1.68s/it] 50%|████▉     | 645/1292 [18:22<18:07,  1.68s/it] 50%|█████     | 646/1292 [18:23<14:05,  1.31s/it]                                                   50%|█████     | 646/1292 [18:23<14:05,  1.31s/it][INFO|trainer.py:571] 2022-12-20 03:01:24,829 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text_e2, id, text_e1. If text_e2, id, text_e1 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:2389] 2022-12-20 03:01:24,834 >> ***** Running Evaluation *****
[INFO|trainer.py:2391] 2022-12-20 03:01:24,834 >>   Num examples = 8792
[INFO|trainer.py:2394] 2022-12-20 03:01:24,834 >>   Batch size = 384
{'eval_loss': 0.17752547562122345, 'eval_accuracy': 0.9434713375796179, 'eval_runtime': 15.3866, 'eval_samples_per_second': 571.406, 'eval_steps_per_second': 1.495, 'epoch': 1.0}
{'loss': 0.0899, 'learning_rate': 1.5e-05, 'epoch': 2.0}

  0%|          | 0/23 [00:00<?, ?it/s][A
  9%|▊         | 2/23 [00:00<00:07,  2.99it/s][A
 13%|█▎        | 3/23 [00:01<00:09,  2.11it/s][A
 17%|█▋        | 4/23 [00:02<00:10,  1.83it/s][A
 22%|██▏       | 5/23 [00:02<00:10,  1.70it/s][A
 26%|██▌       | 6/23 [00:03<00:10,  1.63it/s][A
 30%|███       | 7/23 [00:04<00:10,  1.58it/s][A
 35%|███▍      | 8/23 [00:04<00:09,  1.55it/s][A
 39%|███▉      | 9/23 [00:05<00:09,  1.53it/s][A
 43%|████▎     | 10/23 [00:06<00:08,  1.52it/s][A
 48%|████▊     | 11/23 [00:06<00:07,  1.51it/s][A
 52%|█████▏    | 12/23 [00:07<00:07,  1.51it/s][A
 57%|█████▋    | 13/23 [00:08<00:06,  1.50it/s][A
 61%|██████    | 14/23 [00:08<00:05,  1.50it/s][A
 65%|██████▌   | 15/23 [00:09<00:05,  1.50it/s][A
 70%|██████▉   | 16/23 [00:10<00:04,  1.50it/s][A
 74%|███████▍  | 17/23 [00:10<00:04,  1.50it/s][A
 78%|███████▊  | 18/23 [00:11<00:03,  1.50it/s][A
 83%|████████▎ | 19/23 [00:12<00:02,  1.50it/s][A
 87%|████████▋ | 20/23 [00:12<00:02,  1.49it/s][A
 91%|█████████▏| 21/23 [00:13<00:01,  1.49it/s][A
 96%|█████████▌| 22/23 [00:14<00:00,  1.49it/s][A
100%|██████████| 23/23 [00:14<00:00,  1.54it/s][A                                                  
                                               [A 50%|█████     | 646/1292 [18:38<14:05,  1.31s/it]
100%|██████████| 23/23 [00:14<00:00,  1.54it/s][A
                                               [A[INFO|trainer.py:2139] 2022-12-20 03:01:40,212 >> Saving model checkpoint to /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-646
[INFO|configuration_utils.py:439] 2022-12-20 03:01:40,213 >> Configuration saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-646/config.json
[INFO|modeling_utils.py:1084] 2022-12-20 03:01:42,934 >> Model weights saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-646/pytorch_model.bin
[INFO|tokenization_utils_base.py:2094] 2022-12-20 03:01:42,936 >> tokenizer config file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-646/tokenizer_config.json
[INFO|tokenization_utils_base.py:2100] 2022-12-20 03:01:42,937 >> Special tokens file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-646/special_tokens_map.json
 50%|█████     | 647/1292 [18:48<1:31:42,  8.53s/it] 50%|█████     | 648/1292 [18:50<1:09:26,  6.47s/it] 50%|█████     | 649/1292 [18:52<53:52,  5.03s/it]   50%|█████     | 650/1292 [18:53<42:59,  4.02s/it] 50%|█████     | 651/1292 [18:55<35:22,  3.31s/it] 50%|█████     | 652/1292 [18:57<30:05,  2.82s/it] 51%|█████     | 653/1292 [18:58<26:21,  2.48s/it] 51%|█████     | 654/1292 [19:00<23:45,  2.23s/it] 51%|█████     | 655/1292 [19:02<21:55,  2.07s/it] 51%|█████     | 656/1292 [19:03<20:39,  1.95s/it] 51%|█████     | 657/1292 [19:05<19:45,  1.87s/it] 51%|█████     | 658/1292 [19:07<19:06,  1.81s/it] 51%|█████     | 659/1292 [19:08<18:39,  1.77s/it] 51%|█████     | 660/1292 [19:10<18:19,  1.74s/it] 51%|█████     | 661/1292 [19:12<18:04,  1.72s/it] 51%|█████     | 662/1292 [19:13<17:54,  1.71s/it] 51%|█████▏    | 663/1292 [19:15<17:46,  1.70s/it] 51%|█████▏    | 664/1292 [19:17<17:40,  1.69s/it] 51%|█████▏    | 665/1292 [19:18<17:36,  1.68s/it] 52%|█████▏    | 666/1292 [19:20<17:32,  1.68s/it] 52%|█████▏    | 667/1292 [19:22<17:30,  1.68s/it] 52%|█████▏    | 668/1292 [19:23<17:27,  1.68s/it] 52%|█████▏    | 669/1292 [19:25<17:25,  1.68s/it] 52%|█████▏    | 670/1292 [19:27<17:22,  1.68s/it] 52%|█████▏    | 671/1292 [19:28<17:20,  1.68s/it] 52%|█████▏    | 672/1292 [19:30<17:18,  1.68s/it] 52%|█████▏    | 673/1292 [19:32<17:17,  1.68s/it] 52%|█████▏    | 674/1292 [19:33<17:15,  1.68s/it] 52%|█████▏    | 675/1292 [19:35<17:14,  1.68s/it] 52%|█████▏    | 676/1292 [19:37<17:12,  1.68s/it] 52%|█████▏    | 677/1292 [19:38<17:10,  1.68s/it] 52%|█████▏    | 678/1292 [19:40<17:09,  1.68s/it] 53%|█████▎    | 679/1292 [19:42<17:08,  1.68s/it] 53%|█████▎    | 680/1292 [19:44<17:07,  1.68s/it] 53%|█████▎    | 681/1292 [19:45<17:05,  1.68s/it] 53%|█████▎    | 682/1292 [19:47<17:03,  1.68s/it] 53%|█████▎    | 683/1292 [19:49<17:01,  1.68s/it] 53%|█████▎    | 684/1292 [19:50<16:59,  1.68s/it] 53%|█████▎    | 685/1292 [19:52<16:57,  1.68s/it] 53%|█████▎    | 686/1292 [19:54<16:56,  1.68s/it] 53%|█████▎    | 687/1292 [19:55<16:55,  1.68s/it] 53%|█████▎    | 688/1292 [19:57<16:53,  1.68s/it] 53%|█████▎    | 689/1292 [19:59<16:51,  1.68s/it] 53%|█████▎    | 690/1292 [20:00<16:50,  1.68s/it] 53%|█████▎    | 691/1292 [20:02<16:48,  1.68s/it] 54%|█████▎    | 692/1292 [20:04<16:46,  1.68s/it] 54%|█████▎    | 693/1292 [20:05<16:45,  1.68s/it] 54%|█████▎    | 694/1292 [20:07<16:44,  1.68s/it] 54%|█████▍    | 695/1292 [20:09<16:42,  1.68s/it] 54%|█████▍    | 696/1292 [20:10<16:40,  1.68s/it] 54%|█████▍    | 697/1292 [20:12<16:39,  1.68s/it] 54%|█████▍    | 698/1292 [20:14<16:37,  1.68s/it] 54%|█████▍    | 699/1292 [20:15<16:36,  1.68s/it] 54%|█████▍    | 700/1292 [20:17<16:34,  1.68s/it] 54%|█████▍    | 701/1292 [20:19<16:32,  1.68s/it] 54%|█████▍    | 702/1292 [20:20<16:30,  1.68s/it] 54%|█████▍    | 703/1292 [20:22<16:28,  1.68s/it] 54%|█████▍    | 704/1292 [20:24<16:27,  1.68s/it] 55%|█████▍    | 705/1292 [20:25<16:25,  1.68s/it] 55%|█████▍    | 706/1292 [20:27<16:24,  1.68s/it] 55%|█████▍    | 707/1292 [20:29<16:22,  1.68s/it] 55%|█████▍    | 708/1292 [20:31<16:20,  1.68s/it] 55%|█████▍    | 709/1292 [20:32<16:19,  1.68s/it] 55%|█████▍    | 710/1292 [20:34<16:17,  1.68s/it] 55%|█████▌    | 711/1292 [20:36<16:15,  1.68s/it] 55%|█████▌    | 712/1292 [20:37<16:14,  1.68s/it] 55%|█████▌    | 713/1292 [20:39<16:26,  1.70s/it] 55%|█████▌    | 714/1292 [20:41<16:20,  1.70s/it] 55%|█████▌    | 715/1292 [20:42<16:15,  1.69s/it] 55%|█████▌    | 716/1292 [20:44<16:12,  1.69s/it] 55%|█████▌    | 717/1292 [20:46<16:08,  1.69s/it] 56%|█████▌    | 718/1292 [20:47<16:06,  1.68s/it] 56%|█████▌    | 719/1292 [20:49<16:04,  1.68s/it] 56%|█████▌    | 720/1292 [20:51<16:02,  1.68s/it] 56%|█████▌    | 721/1292 [20:52<16:00,  1.68s/it] 56%|█████▌    | 722/1292 [20:54<15:58,  1.68s/it] 56%|█████▌    | 723/1292 [20:56<15:56,  1.68s/it] 56%|█████▌    | 724/1292 [20:57<15:55,  1.68s/it] 56%|█████▌    | 725/1292 [20:59<15:53,  1.68s/it] 56%|█████▌    | 726/1292 [21:01<15:51,  1.68s/it] 56%|█████▋    | 727/1292 [21:03<15:49,  1.68s/it] 56%|█████▋    | 728/1292 [21:04<15:47,  1.68s/it] 56%|█████▋    | 729/1292 [21:06<15:45,  1.68s/it] 57%|█████▋    | 730/1292 [21:08<15:44,  1.68s/it] 57%|█████▋    | 731/1292 [21:09<15:42,  1.68s/it] 57%|█████▋    | 732/1292 [21:11<15:41,  1.68s/it] 57%|█████▋    | 733/1292 [21:13<15:39,  1.68s/it] 57%|█████▋    | 734/1292 [21:14<15:37,  1.68s/it] 57%|█████▋    | 735/1292 [21:16<15:36,  1.68s/it] 57%|█████▋    | 736/1292 [21:18<15:35,  1.68s/it] 57%|█████▋    | 737/1292 [21:19<15:33,  1.68s/it] 57%|█████▋    | 738/1292 [21:21<15:32,  1.68s/it] 57%|█████▋    | 739/1292 [21:23<15:30,  1.68s/it] 57%|█████▋    | 740/1292 [21:24<15:28,  1.68s/it] 57%|█████▋    | 741/1292 [21:26<15:26,  1.68s/it] 57%|█████▋    | 742/1292 [21:28<15:24,  1.68s/it] 58%|█████▊    | 743/1292 [21:29<15:22,  1.68s/it] 58%|█████▊    | 744/1292 [21:31<15:20,  1.68s/it] 58%|█████▊    | 745/1292 [21:33<15:19,  1.68s/it] 58%|█████▊    | 746/1292 [21:34<15:18,  1.68s/it] 58%|█████▊    | 747/1292 [21:36<15:16,  1.68s/it] 58%|█████▊    | 748/1292 [21:38<15:14,  1.68s/it] 58%|█████▊    | 749/1292 [21:40<15:12,  1.68s/it] 58%|█████▊    | 750/1292 [21:41<15:11,  1.68s/it] 58%|█████▊    | 751/1292 [21:43<15:10,  1.68s/it] 58%|█████▊    | 752/1292 [21:45<15:08,  1.68s/it] 58%|█████▊    | 753/1292 [21:46<15:06,  1.68s/it] 58%|█████▊    | 754/1292 [21:48<15:04,  1.68s/it] 58%|█████▊    | 755/1292 [21:50<15:02,  1.68s/it] 59%|█████▊    | 756/1292 [21:51<15:01,  1.68s/it] 59%|█████▊    | 757/1292 [21:53<14:59,  1.68s/it] 59%|█████▊    | 758/1292 [21:55<14:57,  1.68s/it] 59%|█████▊    | 759/1292 [21:56<14:55,  1.68s/it] 59%|█████▉    | 760/1292 [21:58<14:54,  1.68s/it] 59%|█████▉    | 761/1292 [22:00<14:53,  1.68s/it] 59%|█████▉    | 762/1292 [22:01<14:51,  1.68s/it] 59%|█████▉    | 763/1292 [22:03<14:49,  1.68s/it] 59%|█████▉    | 764/1292 [22:05<14:47,  1.68s/it] 59%|█████▉    | 765/1292 [22:06<14:45,  1.68s/it] 59%|█████▉    | 766/1292 [22:08<14:44,  1.68s/it] 59%|█████▉    | 767/1292 [22:10<14:43,  1.68s/it] 59%|█████▉    | 768/1292 [22:11<14:41,  1.68s/it] 60%|█████▉    | 769/1292 [22:13<14:39,  1.68s/it] 60%|█████▉    | 770/1292 [22:15<14:37,  1.68s/it] 60%|█████▉    | 771/1292 [22:17<14:35,  1.68s/it] 60%|█████▉    | 772/1292 [22:18<14:35,  1.68s/it] 60%|█████▉    | 773/1292 [22:20<14:33,  1.68s/it] 60%|█████▉    | 774/1292 [22:22<14:31,  1.68s/it] 60%|█████▉    | 775/1292 [22:23<14:29,  1.68s/it] 60%|██████    | 776/1292 [22:25<14:27,  1.68s/it] 60%|██████    | 777/1292 [22:27<14:26,  1.68s/it] 60%|██████    | 778/1292 [22:28<14:24,  1.68s/it] 60%|██████    | 779/1292 [22:30<14:22,  1.68s/it] 60%|██████    | 780/1292 [22:32<14:21,  1.68s/it] 60%|██████    | 781/1292 [22:33<14:19,  1.68s/it] 61%|██████    | 782/1292 [22:35<14:17,  1.68s/it] 61%|██████    | 783/1292 [22:37<14:16,  1.68s/it] 61%|██████    | 784/1292 [22:38<14:14,  1.68s/it] 61%|██████    | 785/1292 [22:40<14:12,  1.68s/it] 61%|██████    | 786/1292 [22:42<14:11,  1.68s/it] 61%|██████    | 787/1292 [22:43<14:09,  1.68s/it] 61%|██████    | 788/1292 [22:45<14:07,  1.68s/it] 61%|██████    | 789/1292 [22:47<14:05,  1.68s/it] 61%|██████    | 790/1292 [22:48<14:03,  1.68s/it] 61%|██████    | 791/1292 [22:50<14:02,  1.68s/it] 61%|██████▏   | 792/1292 [22:52<14:00,  1.68s/it] 61%|██████▏   | 793/1292 [22:54<13:58,  1.68s/it] 61%|██████▏   | 794/1292 [22:55<13:57,  1.68s/it] 62%|██████▏   | 795/1292 [22:57<13:55,  1.68s/it] 62%|██████▏   | 796/1292 [22:59<13:54,  1.68s/it] 62%|██████▏   | 797/1292 [23:00<13:53,  1.68s/it] 62%|██████▏   | 798/1292 [23:02<13:50,  1.68s/it] 62%|██████▏   | 799/1292 [23:04<13:49,  1.68s/it] 62%|██████▏   | 800/1292 [23:05<13:47,  1.68s/it] 62%|██████▏   | 801/1292 [23:07<13:45,  1.68s/it] 62%|██████▏   | 802/1292 [23:09<13:43,  1.68s/it] 62%|██████▏   | 803/1292 [23:10<13:41,  1.68s/it] 62%|██████▏   | 804/1292 [23:12<13:39,  1.68s/it] 62%|██████▏   | 805/1292 [23:14<13:38,  1.68s/it] 62%|██████▏   | 806/1292 [23:15<13:37,  1.68s/it] 62%|██████▏   | 807/1292 [23:17<13:35,  1.68s/it] 63%|██████▎   | 808/1292 [23:19<13:34,  1.68s/it] 63%|██████▎   | 809/1292 [23:20<13:33,  1.68s/it] 63%|██████▎   | 810/1292 [23:22<13:30,  1.68s/it] 63%|██████▎   | 811/1292 [23:24<13:28,  1.68s/it] 63%|██████▎   | 812/1292 [23:25<13:27,  1.68s/it] 63%|██████▎   | 813/1292 [23:27<13:25,  1.68s/it] 63%|██████▎   | 814/1292 [23:29<13:24,  1.68s/it] 63%|██████▎   | 815/1292 [23:31<13:22,  1.68s/it] 63%|██████▎   | 816/1292 [23:32<13:20,  1.68s/it] 63%|██████▎   | 817/1292 [23:34<13:18,  1.68s/it] 63%|██████▎   | 818/1292 [23:36<13:16,  1.68s/it] 63%|██████▎   | 819/1292 [23:37<13:15,  1.68s/it] 63%|██████▎   | 820/1292 [23:39<13:13,  1.68s/it] 64%|██████▎   | 821/1292 [23:41<13:11,  1.68s/it] 64%|██████▎   | 822/1292 [23:42<13:10,  1.68s/it] 64%|██████▎   | 823/1292 [23:44<13:09,  1.68s/it] 64%|██████▍   | 824/1292 [23:46<13:07,  1.68s/it] 64%|██████▍   | 825/1292 [23:47<13:05,  1.68s/it] 64%|██████▍   | 826/1292 [23:49<13:03,  1.68s/it] 64%|██████▍   | 827/1292 [23:51<13:01,  1.68s/it] 64%|██████▍   | 828/1292 [23:52<12:59,  1.68s/it] 64%|██████▍   | 829/1292 [23:54<12:58,  1.68s/it] 64%|██████▍   | 830/1292 [23:56<12:56,  1.68s/it] 64%|██████▍   | 831/1292 [23:57<12:54,  1.68s/it] 64%|██████▍   | 832/1292 [23:59<12:52,  1.68s/it] 64%|██████▍   | 833/1292 [24:01<12:51,  1.68s/it] 65%|██████▍   | 834/1292 [24:02<12:49,  1.68s/it] 65%|██████▍   | 835/1292 [24:04<12:48,  1.68s/it] 65%|██████▍   | 836/1292 [24:06<12:46,  1.68s/it] 65%|██████▍   | 837/1292 [24:08<12:45,  1.68s/it] 65%|██████▍   | 838/1292 [24:09<12:43,  1.68s/it] 65%|██████▍   | 839/1292 [24:11<12:41,  1.68s/it] 65%|██████▌   | 840/1292 [24:13<12:39,  1.68s/it] 65%|██████▌   | 841/1292 [24:14<12:37,  1.68s/it] 65%|██████▌   | 842/1292 [24:16<12:36,  1.68s/it] 65%|██████▌   | 843/1292 [24:18<12:35,  1.68s/it] 65%|██████▌   | 844/1292 [24:19<12:33,  1.68s/it] 65%|██████▌   | 845/1292 [24:21<12:31,  1.68s/it] 65%|██████▌   | 846/1292 [24:23<12:29,  1.68s/it] 66%|██████▌   | 847/1292 [24:24<12:32,  1.69s/it] 66%|██████▌   | 848/1292 [24:26<12:31,  1.69s/it] 66%|██████▌   | 849/1292 [24:28<12:28,  1.69s/it] 66%|██████▌   | 850/1292 [24:29<12:25,  1.69s/it] 66%|██████▌   | 851/1292 [24:31<12:23,  1.69s/it] 66%|██████▌   | 852/1292 [24:33<12:21,  1.69s/it] 66%|██████▌   | 853/1292 [24:34<12:19,  1.68s/it] 66%|██████▌   | 854/1292 [24:36<12:17,  1.68s/it] 66%|██████▌   | 855/1292 [24:38<12:16,  1.68s/it] 66%|██████▋   | 856/1292 [24:40<12:14,  1.68s/it] 66%|██████▋   | 857/1292 [24:41<12:12,  1.68s/it] 66%|██████▋   | 858/1292 [24:43<12:10,  1.68s/it] 66%|██████▋   | 859/1292 [24:45<12:09,  1.69s/it] 67%|██████▋   | 860/1292 [24:46<12:07,  1.68s/it] 67%|██████▋   | 861/1292 [24:48<12:05,  1.68s/it] 67%|██████▋   | 862/1292 [24:50<12:04,  1.68s/it] 67%|██████▋   | 863/1292 [24:51<12:02,  1.68s/it] 67%|██████▋   | 864/1292 [24:53<12:00,  1.68s/it] 67%|██████▋   | 865/1292 [24:55<11:58,  1.68s/it] 67%|██████▋   | 866/1292 [24:56<11:56,  1.68s/it] 67%|██████▋   | 867/1292 [24:58<11:54,  1.68s/it] 67%|██████▋   | 868/1292 [25:00<11:53,  1.68s/it] 67%|██████▋   | 869/1292 [25:01<11:51,  1.68s/it] 67%|██████▋   | 870/1292 [25:03<11:49,  1.68s/it] 67%|██████▋   | 871/1292 [25:05<11:48,  1.68s/it] 67%|██████▋   | 872/1292 [25:06<11:46,  1.68s/it] 68%|██████▊   | 873/1292 [25:08<11:45,  1.68s/it] 68%|██████▊   | 874/1292 [25:10<11:43,  1.68s/it] 68%|██████▊   | 875/1292 [25:11<11:41,  1.68s/it] 68%|██████▊   | 876/1292 [25:13<11:39,  1.68s/it] 68%|██████▊   | 877/1292 [25:15<11:38,  1.68s/it] 68%|██████▊   | 878/1292 [25:17<11:36,  1.68s/it] 68%|██████▊   | 879/1292 [25:18<11:34,  1.68s/it] 68%|██████▊   | 880/1292 [25:20<11:32,  1.68s/it] 68%|██████▊   | 881/1292 [25:22<11:30,  1.68s/it] 68%|██████▊   | 882/1292 [25:23<11:29,  1.68s/it] 68%|██████▊   | 883/1292 [25:25<11:28,  1.68s/it] 68%|██████▊   | 884/1292 [25:27<11:26,  1.68s/it] 68%|██████▊   | 885/1292 [25:28<11:25,  1.68s/it] 69%|██████▊   | 886/1292 [25:30<11:23,  1.68s/it] 69%|██████▊   | 887/1292 [25:32<11:21,  1.68s/it] 69%|██████▊   | 888/1292 [25:33<11:19,  1.68s/it] 69%|██████▉   | 889/1292 [25:35<11:17,  1.68s/it] 69%|██████▉   | 890/1292 [25:37<11:16,  1.68s/it] 69%|██████▉   | 891/1292 [25:38<11:15,  1.68s/it] 69%|██████▉   | 892/1292 [25:40<11:13,  1.68s/it] 69%|██████▉   | 893/1292 [25:42<11:11,  1.68s/it] 69%|██████▉   | 894/1292 [25:43<11:10,  1.68s/it] 69%|██████▉   | 895/1292 [25:45<11:08,  1.68s/it] 69%|██████▉   | 896/1292 [25:47<11:06,  1.68s/it] 69%|██████▉   | 897/1292 [25:48<11:04,  1.68s/it] 70%|██████▉   | 898/1292 [25:50<11:02,  1.68s/it] 70%|██████▉   | 899/1292 [25:52<11:00,  1.68s/it] 70%|██████▉   | 900/1292 [25:54<10:58,  1.68s/it] 70%|██████▉   | 901/1292 [25:55<10:56,  1.68s/it] 70%|██████▉   | 902/1292 [25:57<10:55,  1.68s/it] 70%|██████▉   | 903/1292 [25:59<10:53,  1.68s/it] 70%|██████▉   | 904/1292 [26:00<10:51,  1.68s/it] 70%|███████   | 905/1292 [26:02<10:50,  1.68s/it] 70%|███████   | 906/1292 [26:04<10:49,  1.68s/it] 70%|███████   | 907/1292 [26:05<10:47,  1.68s/it] 70%|███████   | 908/1292 [26:07<10:46,  1.68s/it] 70%|███████   | 909/1292 [26:09<10:44,  1.68s/it] 70%|███████   | 910/1292 [26:10<10:42,  1.68s/it] 71%|███████   | 911/1292 [26:12<10:40,  1.68s/it] 71%|███████   | 912/1292 [26:14<10:38,  1.68s/it] 71%|███████   | 913/1292 [26:15<10:37,  1.68s/it] 71%|███████   | 914/1292 [26:17<10:35,  1.68s/it] 71%|███████   | 915/1292 [26:19<10:33,  1.68s/it] 71%|███████   | 916/1292 [26:20<10:31,  1.68s/it] 71%|███████   | 917/1292 [26:22<10:30,  1.68s/it] 71%|███████   | 918/1292 [26:24<10:28,  1.68s/it] 71%|███████   | 919/1292 [26:25<10:26,  1.68s/it] 71%|███████   | 920/1292 [26:27<10:25,  1.68s/it] 71%|███████▏  | 921/1292 [26:29<10:23,  1.68s/it] 71%|███████▏  | 922/1292 [26:31<10:22,  1.68s/it] 71%|███████▏  | 923/1292 [26:32<10:20,  1.68s/it] 72%|███████▏  | 924/1292 [26:34<10:18,  1.68s/it] 72%|███████▏  | 925/1292 [26:36<10:16,  1.68s/it] 72%|███████▏  | 926/1292 [26:37<10:14,  1.68s/it] 72%|███████▏  | 927/1292 [26:39<10:13,  1.68s/it] 72%|███████▏  | 928/1292 [26:41<10:11,  1.68s/it] 72%|███████▏  | 929/1292 [26:42<10:09,  1.68s/it] 72%|███████▏  | 930/1292 [26:44<10:08,  1.68s/it] 72%|███████▏  | 931/1292 [26:46<10:06,  1.68s/it] 72%|███████▏  | 932/1292 [26:47<10:05,  1.68s/it] 72%|███████▏  | 933/1292 [26:49<10:03,  1.68s/it] 72%|███████▏  | 934/1292 [26:51<10:02,  1.68s/it] 72%|███████▏  | 935/1292 [26:52<10:00,  1.68s/it] 72%|███████▏  | 936/1292 [26:54<09:59,  1.68s/it] 73%|███████▎  | 937/1292 [26:56<09:56,  1.68s/it] 73%|███████▎  | 938/1292 [26:57<09:55,  1.68s/it] 73%|███████▎  | 939/1292 [26:59<09:53,  1.68s/it] 73%|███████▎  | 940/1292 [27:01<09:51,  1.68s/it] 73%|███████▎  | 941/1292 [27:02<09:49,  1.68s/it] 73%|███████▎  | 942/1292 [27:04<09:48,  1.68s/it] 73%|███████▎  | 943/1292 [27:06<09:46,  1.68s/it] 73%|███████▎  | 944/1292 [27:07<09:44,  1.68s/it] 73%|███████▎  | 945/1292 [27:09<09:43,  1.68s/it] 73%|███████▎  | 946/1292 [27:11<09:41,  1.68s/it] 73%|███████▎  | 947/1292 [27:13<09:39,  1.68s/it] 73%|███████▎  | 948/1292 [27:14<09:38,  1.68s/it] 73%|███████▎  | 949/1292 [27:16<09:36,  1.68s/it] 74%|███████▎  | 950/1292 [27:18<09:35,  1.68s/it] 74%|███████▎  | 951/1292 [27:19<09:33,  1.68s/it] 74%|███████▎  | 952/1292 [27:21<09:31,  1.68s/it] 74%|███████▍  | 953/1292 [27:23<09:29,  1.68s/it] 74%|███████▍  | 954/1292 [27:24<09:27,  1.68s/it] 74%|███████▍  | 955/1292 [27:26<09:26,  1.68s/it] 74%|███████▍  | 956/1292 [27:28<09:24,  1.68s/it] 74%|███████▍  | 957/1292 [27:29<09:22,  1.68s/it] 74%|███████▍  | 958/1292 [27:31<09:21,  1.68s/it] 74%|███████▍  | 959/1292 [27:33<09:19,  1.68s/it] 74%|███████▍  | 960/1292 [27:34<09:17,  1.68s/it] 74%|███████▍  | 961/1292 [27:36<09:16,  1.68s/it] 74%|███████▍  | 962/1292 [27:38<09:14,  1.68s/it] 75%|███████▍  | 963/1292 [27:39<09:13,  1.68s/it] 75%|███████▍  | 964/1292 [27:41<09:11,  1.68s/it] 75%|███████▍  | 965/1292 [27:43<09:09,  1.68s/it] 75%|███████▍  | 966/1292 [27:44<09:08,  1.68s/it] 75%|███████▍  | 967/1292 [27:46<09:06,  1.68s/it] 75%|███████▍  | 968/1292 [27:48<09:04,  1.68s/it] 75%|███████▌  | 969/1292 [27:48<07:02,  1.31s/it]                                                   75%|███████▌  | 969/1292 [27:48<07:02,  1.31s/it][INFO|trainer.py:571] 2022-12-20 03:10:50,181 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text_e2, id, text_e1. If text_e2, id, text_e1 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:2389] 2022-12-20 03:10:50,185 >> ***** Running Evaluation *****
[INFO|trainer.py:2391] 2022-12-20 03:10:50,185 >>   Num examples = 8792
[INFO|trainer.py:2394] 2022-12-20 03:10:50,186 >>   Batch size = 384
{'eval_loss': 0.2169426530599594, 'eval_accuracy': 0.9393767060964513, 'eval_runtime': 15.3758, 'eval_samples_per_second': 571.808, 'eval_steps_per_second': 1.496, 'epoch': 2.0}
{'loss': 0.0546, 'learning_rate': 7.5e-06, 'epoch': 3.0}

  0%|          | 0/23 [00:00<?, ?it/s][A
  9%|▊         | 2/23 [00:00<00:07,  3.00it/s][A
 13%|█▎        | 3/23 [00:01<00:09,  2.11it/s][A
 17%|█▋        | 4/23 [00:02<00:10,  1.83it/s][A
 22%|██▏       | 5/23 [00:02<00:10,  1.70it/s][A
 26%|██▌       | 6/23 [00:03<00:10,  1.63it/s][A
 30%|███       | 7/23 [00:04<00:10,  1.58it/s][A
 35%|███▍      | 8/23 [00:04<00:09,  1.55it/s][A
 39%|███▉      | 9/23 [00:05<00:09,  1.54it/s][A
 43%|████▎     | 10/23 [00:06<00:08,  1.52it/s][A
 48%|████▊     | 11/23 [00:06<00:07,  1.51it/s][A
 52%|█████▏    | 12/23 [00:07<00:07,  1.51it/s][A
 57%|█████▋    | 13/23 [00:08<00:06,  1.50it/s][A
 61%|██████    | 14/23 [00:08<00:05,  1.50it/s][A
 65%|██████▌   | 15/23 [00:09<00:05,  1.50it/s][A
 70%|██████▉   | 16/23 [00:10<00:04,  1.50it/s][A
 74%|███████▍  | 17/23 [00:10<00:04,  1.50it/s][A
 78%|███████▊  | 18/23 [00:11<00:03,  1.50it/s][A
 83%|████████▎ | 19/23 [00:12<00:02,  1.50it/s][A
 87%|████████▋ | 20/23 [00:12<00:02,  1.50it/s][A
 91%|█████████▏| 21/23 [00:13<00:01,  1.50it/s][A
 96%|█████████▌| 22/23 [00:14<00:00,  1.50it/s][A
100%|██████████| 23/23 [00:14<00:00,  1.55it/s][A                                                  
                                               [A 75%|███████▌  | 969/1292 [28:04<07:02,  1.31s/it]
100%|██████████| 23/23 [00:14<00:00,  1.55it/s][A
                                               [A[INFO|trainer.py:2139] 2022-12-20 03:11:05,538 >> Saving model checkpoint to /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-969
[INFO|configuration_utils.py:439] 2022-12-20 03:11:05,540 >> Configuration saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-969/config.json
[INFO|modeling_utils.py:1084] 2022-12-20 03:11:08,210 >> Model weights saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-969/pytorch_model.bin
[INFO|tokenization_utils_base.py:2094] 2022-12-20 03:11:08,211 >> tokenizer config file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-969/tokenizer_config.json
[INFO|tokenization_utils_base.py:2100] 2022-12-20 03:11:08,212 >> Special tokens file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-969/special_tokens_map.json
[INFO|trainer.py:2217] 2022-12-20 03:11:13,668 >> Deleting older checkpoint [/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-323] due to args.save_total_limit
 75%|███████▌  | 970/1292 [28:14<45:44,  8.52s/it] 75%|███████▌  | 971/1292 [28:15<34:35,  6.46s/it] 75%|███████▌  | 972/1292 [28:17<26:47,  5.02s/it] 75%|███████▌  | 973/1292 [28:19<21:21,  4.02s/it] 75%|███████▌  | 974/1292 [28:20<17:33,  3.31s/it] 75%|███████▌  | 975/1292 [28:22<14:53,  2.82s/it] 76%|███████▌  | 976/1292 [28:24<13:01,  2.47s/it] 76%|███████▌  | 977/1292 [28:25<11:43,  2.23s/it] 76%|███████▌  | 978/1292 [28:27<10:48,  2.06s/it] 76%|███████▌  | 979/1292 [28:29<10:09,  1.95s/it] 76%|███████▌  | 980/1292 [28:30<09:41,  1.86s/it] 76%|███████▌  | 981/1292 [28:32<09:21,  1.81s/it] 76%|███████▌  | 982/1292 [28:34<09:07,  1.77s/it] 76%|███████▌  | 983/1292 [28:35<08:56,  1.74s/it] 76%|███████▌  | 984/1292 [28:37<08:49,  1.72s/it] 76%|███████▌  | 985/1292 [28:39<08:43,  1.71s/it] 76%|███████▋  | 986/1292 [28:40<08:39,  1.70s/it] 76%|███████▋  | 987/1292 [28:42<08:35,  1.69s/it] 76%|███████▋  | 988/1292 [28:44<08:32,  1.69s/it] 77%|███████▋  | 989/1292 [28:45<08:29,  1.68s/it] 77%|███████▋  | 990/1292 [28:47<08:27,  1.68s/it] 77%|███████▋  | 991/1292 [28:49<08:25,  1.68s/it] 77%|███████▋  | 992/1292 [28:50<08:23,  1.68s/it] 77%|███████▋  | 993/1292 [28:52<08:21,  1.68s/it] 77%|███████▋  | 994/1292 [28:54<08:19,  1.68s/it] 77%|███████▋  | 995/1292 [28:55<08:17,  1.68s/it] 77%|███████▋  | 996/1292 [28:57<08:16,  1.68s/it] 77%|███████▋  | 997/1292 [28:59<08:14,  1.68s/it] 77%|███████▋  | 998/1292 [29:00<08:12,  1.68s/it] 77%|███████▋  | 999/1292 [29:02<08:11,  1.68s/it] 77%|███████▋  | 1000/1292 [29:04<08:09,  1.68s/it] 77%|███████▋  | 1001/1292 [29:05<08:07,  1.68s/it] 78%|███████▊  | 1002/1292 [29:07<08:06,  1.68s/it] 78%|███████▊  | 1003/1292 [29:09<08:04,  1.68s/it] 78%|███████▊  | 1004/1292 [29:11<08:02,  1.68s/it] 78%|███████▊  | 1005/1292 [29:12<08:01,  1.68s/it] 78%|███████▊  | 1006/1292 [29:14<07:59,  1.68s/it] 78%|███████▊  | 1007/1292 [29:16<07:57,  1.68s/it] 78%|███████▊  | 1008/1292 [29:17<07:56,  1.68s/it] 78%|███████▊  | 1009/1292 [29:19<07:54,  1.68s/it] 78%|███████▊  | 1010/1292 [29:21<07:52,  1.68s/it] 78%|███████▊  | 1011/1292 [29:22<07:51,  1.68s/it] 78%|███████▊  | 1012/1292 [29:24<07:49,  1.68s/it] 78%|███████▊  | 1013/1292 [29:26<07:48,  1.68s/it] 78%|███████▊  | 1014/1292 [29:27<07:46,  1.68s/it] 79%|███████▊  | 1015/1292 [29:29<07:44,  1.68s/it] 79%|███████▊  | 1016/1292 [29:31<07:43,  1.68s/it] 79%|███████▊  | 1017/1292 [29:32<07:41,  1.68s/it] 79%|███████▉  | 1018/1292 [29:34<07:40,  1.68s/it] 79%|███████▉  | 1019/1292 [29:36<07:38,  1.68s/it] 79%|███████▉  | 1020/1292 [29:37<07:36,  1.68s/it] 79%|███████▉  | 1021/1292 [29:39<07:35,  1.68s/it] 79%|███████▉  | 1022/1292 [29:41<07:33,  1.68s/it] 79%|███████▉  | 1023/1292 [29:42<07:32,  1.68s/it] 79%|███████▉  | 1024/1292 [29:44<07:30,  1.68s/it] 79%|███████▉  | 1025/1292 [29:46<07:28,  1.68s/it] 79%|███████▉  | 1026/1292 [29:47<07:26,  1.68s/it] 79%|███████▉  | 1027/1292 [29:49<07:25,  1.68s/it] 80%|███████▉  | 1028/1292 [29:51<07:23,  1.68s/it] 80%|███████▉  | 1029/1292 [29:52<07:21,  1.68s/it] 80%|███████▉  | 1030/1292 [29:54<07:20,  1.68s/it] 80%|███████▉  | 1031/1292 [29:56<07:18,  1.68s/it] 80%|███████▉  | 1032/1292 [29:58<07:16,  1.68s/it] 80%|███████▉  | 1033/1292 [29:59<07:15,  1.68s/it] 80%|████████  | 1034/1292 [30:01<07:13,  1.68s/it] 80%|████████  | 1035/1292 [30:03<07:11,  1.68s/it] 80%|████████  | 1036/1292 [30:04<07:10,  1.68s/it] 80%|████████  | 1037/1292 [30:06<07:08,  1.68s/it] 80%|████████  | 1038/1292 [30:08<07:06,  1.68s/it] 80%|████████  | 1039/1292 [30:09<07:04,  1.68s/it] 80%|████████  | 1040/1292 [30:11<07:03,  1.68s/it] 81%|████████  | 1041/1292 [30:13<07:01,  1.68s/it] 81%|████████  | 1042/1292 [30:14<07:00,  1.68s/it] 81%|████████  | 1043/1292 [30:16<06:58,  1.68s/it] 81%|████████  | 1044/1292 [30:18<06:56,  1.68s/it] 81%|████████  | 1045/1292 [30:19<06:54,  1.68s/it] 81%|████████  | 1046/1292 [30:21<06:53,  1.68s/it] 81%|████████  | 1047/1292 [30:23<06:51,  1.68s/it] 81%|████████  | 1048/1292 [30:24<06:49,  1.68s/it] 81%|████████  | 1049/1292 [30:26<06:48,  1.68s/it] 81%|████████▏ | 1050/1292 [30:28<06:46,  1.68s/it] 81%|████████▏ | 1051/1292 [30:29<06:45,  1.68s/it] 81%|████████▏ | 1052/1292 [30:31<06:43,  1.68s/it] 82%|████████▏ | 1053/1292 [30:33<06:41,  1.68s/it] 82%|████████▏ | 1054/1292 [30:35<06:40,  1.68s/it] 82%|████████▏ | 1055/1292 [30:36<06:38,  1.68s/it] 82%|████████▏ | 1056/1292 [30:38<06:36,  1.68s/it] 82%|████████▏ | 1057/1292 [30:40<06:34,  1.68s/it] 82%|████████▏ | 1058/1292 [30:41<06:33,  1.68s/it] 82%|████████▏ | 1059/1292 [30:43<06:31,  1.68s/it] 82%|████████▏ | 1060/1292 [30:45<06:29,  1.68s/it] 82%|████████▏ | 1061/1292 [30:46<06:28,  1.68s/it] 82%|████████▏ | 1062/1292 [30:48<06:26,  1.68s/it] 82%|████████▏ | 1063/1292 [30:50<06:24,  1.68s/it] 82%|████████▏ | 1064/1292 [30:51<06:23,  1.68s/it] 82%|████████▏ | 1065/1292 [30:53<06:21,  1.68s/it] 83%|████████▎ | 1066/1292 [30:55<06:20,  1.68s/it] 83%|████████▎ | 1067/1292 [30:56<06:18,  1.68s/it] 83%|████████▎ | 1068/1292 [30:58<06:16,  1.68s/it] 83%|████████▎ | 1069/1292 [31:00<06:14,  1.68s/it] 83%|████████▎ | 1070/1292 [31:01<06:13,  1.68s/it] 83%|████████▎ | 1071/1292 [31:03<06:11,  1.68s/it] 83%|████████▎ | 1072/1292 [31:05<06:09,  1.68s/it] 83%|████████▎ | 1073/1292 [31:06<06:08,  1.68s/it] 83%|████████▎ | 1074/1292 [31:08<06:06,  1.68s/it] 83%|████████▎ | 1075/1292 [31:10<06:05,  1.68s/it] 83%|████████▎ | 1076/1292 [31:11<06:03,  1.68s/it] 83%|████████▎ | 1077/1292 [31:13<06:01,  1.68s/it] 83%|████████▎ | 1078/1292 [31:15<06:00,  1.68s/it] 84%|████████▎ | 1079/1292 [31:17<05:58,  1.68s/it] 84%|████████▎ | 1080/1292 [31:18<05:56,  1.68s/it] 84%|████████▎ | 1081/1292 [31:20<05:55,  1.68s/it] 84%|████████▎ | 1082/1292 [31:22<05:53,  1.68s/it] 84%|████████▍ | 1083/1292 [31:23<05:51,  1.68s/it] 84%|████████▍ | 1084/1292 [31:25<05:54,  1.71s/it] 84%|████████▍ | 1085/1292 [31:27<05:51,  1.70s/it] 84%|████████▍ | 1086/1292 [31:28<05:48,  1.69s/it] 84%|████████▍ | 1087/1292 [31:30<05:46,  1.69s/it] 84%|████████▍ | 1088/1292 [31:32<05:44,  1.69s/it] 84%|████████▍ | 1089/1292 [31:33<05:42,  1.69s/it] 84%|████████▍ | 1090/1292 [31:35<05:40,  1.68s/it] 84%|████████▍ | 1091/1292 [31:37<05:38,  1.68s/it] 85%|████████▍ | 1092/1292 [31:38<05:36,  1.68s/it] 85%|████████▍ | 1093/1292 [31:40<05:34,  1.68s/it] 85%|████████▍ | 1094/1292 [31:42<05:32,  1.68s/it] 85%|████████▍ | 1095/1292 [31:44<05:31,  1.68s/it] 85%|████████▍ | 1096/1292 [31:45<05:29,  1.68s/it] 85%|████████▍ | 1097/1292 [31:47<05:27,  1.68s/it] 85%|████████▍ | 1098/1292 [31:49<05:26,  1.68s/it] 85%|████████▌ | 1099/1292 [31:50<05:24,  1.68s/it] 85%|████████▌ | 1100/1292 [31:52<05:23,  1.68s/it] 85%|████████▌ | 1101/1292 [31:54<05:21,  1.68s/it] 85%|████████▌ | 1102/1292 [31:55<05:19,  1.68s/it] 85%|████████▌ | 1103/1292 [31:57<05:17,  1.68s/it] 85%|████████▌ | 1104/1292 [31:59<05:16,  1.68s/it] 86%|████████▌ | 1105/1292 [32:00<05:14,  1.68s/it] 86%|████████▌ | 1106/1292 [32:02<05:13,  1.68s/it] 86%|████████▌ | 1107/1292 [32:04<05:11,  1.68s/it] 86%|████████▌ | 1108/1292 [32:05<05:09,  1.68s/it] 86%|████████▌ | 1109/1292 [32:07<05:07,  1.68s/it] 86%|████████▌ | 1110/1292 [32:09<05:06,  1.68s/it] 86%|████████▌ | 1111/1292 [32:10<05:04,  1.68s/it] 86%|████████▌ | 1112/1292 [32:12<05:03,  1.68s/it] 86%|████████▌ | 1113/1292 [32:14<05:01,  1.68s/it] 86%|████████▌ | 1114/1292 [32:15<04:59,  1.68s/it] 86%|████████▋ | 1115/1292 [32:17<04:57,  1.68s/it] 86%|████████▋ | 1116/1292 [32:19<04:56,  1.68s/it] 86%|████████▋ | 1117/1292 [32:21<04:54,  1.68s/it] 87%|████████▋ | 1118/1292 [32:22<04:52,  1.68s/it] 87%|████████▋ | 1119/1292 [32:24<04:51,  1.68s/it] 87%|████████▋ | 1120/1292 [32:26<04:49,  1.68s/it] 87%|████████▋ | 1121/1292 [32:27<04:47,  1.68s/it] 87%|████████▋ | 1122/1292 [32:29<04:46,  1.68s/it] 87%|████████▋ | 1123/1292 [32:31<04:44,  1.68s/it] 87%|████████▋ | 1124/1292 [32:32<04:42,  1.68s/it] 87%|████████▋ | 1125/1292 [32:34<04:40,  1.68s/it] 87%|████████▋ | 1126/1292 [32:36<04:39,  1.68s/it] 87%|████████▋ | 1127/1292 [32:37<04:37,  1.68s/it] 87%|████████▋ | 1128/1292 [32:39<04:35,  1.68s/it] 87%|████████▋ | 1129/1292 [32:41<04:34,  1.68s/it] 87%|████████▋ | 1130/1292 [32:42<04:32,  1.68s/it] 88%|████████▊ | 1131/1292 [32:44<04:30,  1.68s/it] 88%|████████▊ | 1132/1292 [32:46<04:29,  1.68s/it] 88%|████████▊ | 1133/1292 [32:47<04:27,  1.68s/it] 88%|████████▊ | 1134/1292 [32:49<04:26,  1.68s/it] 88%|████████▊ | 1135/1292 [32:51<04:24,  1.68s/it] 88%|████████▊ | 1136/1292 [32:53<04:22,  1.68s/it] 88%|████████▊ | 1137/1292 [32:54<04:20,  1.68s/it] 88%|████████▊ | 1138/1292 [32:56<04:19,  1.68s/it] 88%|████████▊ | 1139/1292 [32:58<04:17,  1.68s/it] 88%|████████▊ | 1140/1292 [32:59<04:16,  1.68s/it] 88%|████████▊ | 1141/1292 [33:01<04:14,  1.68s/it] 88%|████████▊ | 1142/1292 [33:03<04:12,  1.68s/it] 88%|████████▊ | 1143/1292 [33:04<04:10,  1.68s/it] 89%|████████▊ | 1144/1292 [33:06<04:09,  1.68s/it] 89%|████████▊ | 1145/1292 [33:08<04:07,  1.68s/it] 89%|████████▊ | 1146/1292 [33:09<04:05,  1.68s/it] 89%|████████▉ | 1147/1292 [33:11<04:04,  1.68s/it] 89%|████████▉ | 1148/1292 [33:13<04:02,  1.68s/it] 89%|████████▉ | 1149/1292 [33:14<04:00,  1.68s/it] 89%|████████▉ | 1150/1292 [33:16<03:58,  1.68s/it] 89%|████████▉ | 1151/1292 [33:18<03:57,  1.68s/it] 89%|████████▉ | 1152/1292 [33:19<03:55,  1.68s/it] 89%|████████▉ | 1153/1292 [33:21<03:53,  1.68s/it] 89%|████████▉ | 1154/1292 [33:23<03:52,  1.68s/it] 89%|████████▉ | 1155/1292 [33:25<03:50,  1.68s/it] 89%|████████▉ | 1156/1292 [33:26<03:48,  1.68s/it] 90%|████████▉ | 1157/1292 [33:28<03:47,  1.68s/it] 90%|████████▉ | 1158/1292 [33:30<03:45,  1.68s/it] 90%|████████▉ | 1159/1292 [33:31<03:43,  1.68s/it] 90%|████████▉ | 1160/1292 [33:33<03:42,  1.68s/it] 90%|████████▉ | 1161/1292 [33:35<03:40,  1.68s/it] 90%|████████▉ | 1162/1292 [33:36<03:38,  1.68s/it] 90%|█████████ | 1163/1292 [33:38<03:37,  1.68s/it] 90%|█████████ | 1164/1292 [33:40<03:35,  1.68s/it] 90%|█████████ | 1165/1292 [33:41<03:33,  1.68s/it] 90%|█████████ | 1166/1292 [33:43<03:32,  1.68s/it] 90%|█████████ | 1167/1292 [33:45<03:30,  1.68s/it] 90%|█████████ | 1168/1292 [33:46<03:28,  1.68s/it] 90%|█████████ | 1169/1292 [33:48<03:26,  1.68s/it] 91%|█████████ | 1170/1292 [33:50<03:25,  1.68s/it] 91%|█████████ | 1171/1292 [33:51<03:23,  1.68s/it] 91%|█████████ | 1172/1292 [33:53<03:21,  1.68s/it] 91%|█████████ | 1173/1292 [33:55<03:20,  1.68s/it] 91%|█████████ | 1174/1292 [33:56<03:18,  1.68s/it] 91%|█████████ | 1175/1292 [33:58<03:16,  1.68s/it] 91%|█████████ | 1176/1292 [34:00<03:15,  1.68s/it] 91%|█████████ | 1177/1292 [34:02<03:13,  1.68s/it] 91%|█████████ | 1178/1292 [34:03<03:11,  1.68s/it] 91%|█████████▏| 1179/1292 [34:05<03:10,  1.68s/it] 91%|█████████▏| 1180/1292 [34:07<03:08,  1.68s/it] 91%|█████████▏| 1181/1292 [34:08<03:06,  1.68s/it] 91%|█████████▏| 1182/1292 [34:10<03:05,  1.68s/it] 92%|█████████▏| 1183/1292 [34:12<03:03,  1.68s/it] 92%|█████████▏| 1184/1292 [34:13<03:01,  1.68s/it] 92%|█████████▏| 1185/1292 [34:15<03:00,  1.68s/it] 92%|█████████▏| 1186/1292 [34:17<02:58,  1.68s/it] 92%|█████████▏| 1187/1292 [34:18<02:56,  1.68s/it] 92%|█████████▏| 1188/1292 [34:20<02:55,  1.68s/it] 92%|█████████▏| 1189/1292 [34:22<02:53,  1.68s/it] 92%|█████████▏| 1190/1292 [34:23<02:51,  1.68s/it] 92%|█████████▏| 1191/1292 [34:25<02:50,  1.68s/it] 92%|█████████▏| 1192/1292 [34:27<02:48,  1.68s/it] 92%|█████████▏| 1193/1292 [34:28<02:46,  1.68s/it] 92%|█████████▏| 1194/1292 [34:30<02:44,  1.68s/it] 92%|█████████▏| 1195/1292 [34:32<02:43,  1.68s/it] 93%|█████████▎| 1196/1292 [34:34<02:41,  1.68s/it] 93%|█████████▎| 1197/1292 [34:35<02:39,  1.68s/it] 93%|█████████▎| 1198/1292 [34:37<02:38,  1.68s/it] 93%|█████████▎| 1199/1292 [34:39<02:36,  1.68s/it] 93%|█████████▎| 1200/1292 [34:40<02:34,  1.68s/it] 93%|█████████▎| 1201/1292 [34:42<02:33,  1.68s/it] 93%|█████████▎| 1202/1292 [34:44<02:31,  1.68s/it] 93%|█████████▎| 1203/1292 [34:45<02:29,  1.68s/it] 93%|█████████▎| 1204/1292 [34:47<02:28,  1.68s/it] 93%|█████████▎| 1205/1292 [34:49<02:26,  1.68s/it] 93%|█████████▎| 1206/1292 [34:50<02:24,  1.68s/it] 93%|█████████▎| 1207/1292 [34:52<02:23,  1.68s/it] 93%|█████████▎| 1208/1292 [34:54<02:21,  1.68s/it] 94%|█████████▎| 1209/1292 [34:55<02:19,  1.68s/it] 94%|█████████▎| 1210/1292 [34:57<02:17,  1.68s/it] 94%|█████████▎| 1211/1292 [34:59<02:16,  1.68s/it] 94%|█████████▍| 1212/1292 [35:00<02:14,  1.68s/it] 94%|█████████▍| 1213/1292 [35:02<02:12,  1.68s/it] 94%|█████████▍| 1214/1292 [35:04<02:11,  1.68s/it] 94%|█████████▍| 1215/1292 [35:05<02:09,  1.68s/it] 94%|█████████▍| 1216/1292 [35:07<02:07,  1.68s/it] 94%|█████████▍| 1217/1292 [35:09<02:06,  1.68s/it] 94%|█████████▍| 1218/1292 [35:11<02:04,  1.68s/it] 94%|█████████▍| 1219/1292 [35:12<02:02,  1.68s/it] 94%|█████████▍| 1220/1292 [35:14<02:01,  1.68s/it] 95%|█████████▍| 1221/1292 [35:16<01:59,  1.68s/it] 95%|█████████▍| 1222/1292 [35:17<01:57,  1.68s/it] 95%|█████████▍| 1223/1292 [35:19<01:56,  1.68s/it] 95%|█████████▍| 1224/1292 [35:21<01:54,  1.68s/it] 95%|█████████▍| 1225/1292 [35:22<01:52,  1.68s/it] 95%|█████████▍| 1226/1292 [35:24<01:51,  1.68s/it] 95%|█████████▍| 1227/1292 [35:26<01:49,  1.68s/it] 95%|█████████▌| 1228/1292 [35:27<01:47,  1.68s/it] 95%|█████████▌| 1229/1292 [35:29<01:45,  1.68s/it] 95%|█████████▌| 1230/1292 [35:31<01:44,  1.68s/it] 95%|█████████▌| 1231/1292 [35:32<01:42,  1.68s/it] 95%|█████████▌| 1232/1292 [35:34<01:40,  1.68s/it] 95%|█████████▌| 1233/1292 [35:36<01:39,  1.68s/it] 96%|█████████▌| 1234/1292 [35:37<01:37,  1.68s/it] 96%|█████████▌| 1235/1292 [35:39<01:35,  1.68s/it] 96%|█████████▌| 1236/1292 [35:41<01:34,  1.68s/it] 96%|█████████▌| 1237/1292 [35:42<01:32,  1.68s/it] 96%|█████████▌| 1238/1292 [35:44<01:30,  1.68s/it] 96%|█████████▌| 1239/1292 [35:46<01:29,  1.68s/it] 96%|█████████▌| 1240/1292 [35:48<01:27,  1.68s/it] 96%|█████████▌| 1241/1292 [35:49<01:25,  1.68s/it] 96%|█████████▌| 1242/1292 [35:51<01:24,  1.68s/it] 96%|█████████▌| 1243/1292 [35:53<01:22,  1.68s/it] 96%|█████████▋| 1244/1292 [35:54<01:20,  1.68s/it] 96%|█████████▋| 1245/1292 [35:56<01:19,  1.68s/it] 96%|█████████▋| 1246/1292 [35:58<01:17,  1.68s/it] 97%|█████████▋| 1247/1292 [35:59<01:15,  1.68s/it] 97%|█████████▋| 1248/1292 [36:01<01:14,  1.68s/it] 97%|█████████▋| 1249/1292 [36:03<01:12,  1.68s/it] 97%|█████████▋| 1250/1292 [36:04<01:10,  1.68s/it] 97%|█████████▋| 1251/1292 [36:06<01:09,  1.68s/it] 97%|█████████▋| 1252/1292 [36:08<01:07,  1.68s/it] 97%|█████████▋| 1253/1292 [36:09<01:05,  1.68s/it] 97%|█████████▋| 1254/1292 [36:11<01:03,  1.68s/it] 97%|█████████▋| 1255/1292 [36:13<01:02,  1.68s/it] 97%|█████████▋| 1256/1292 [36:14<01:00,  1.68s/it] 97%|█████████▋| 1257/1292 [36:16<00:58,  1.68s/it] 97%|█████████▋| 1258/1292 [36:18<00:57,  1.68s/it] 97%|█████████▋| 1259/1292 [36:20<00:55,  1.68s/it] 98%|█████████▊| 1260/1292 [36:21<00:53,  1.68s/it] 98%|█████████▊| 1261/1292 [36:23<00:52,  1.68s/it] 98%|█████████▊| 1262/1292 [36:25<00:50,  1.68s/it] 98%|█████████▊| 1263/1292 [36:26<00:48,  1.68s/it] 98%|█████████▊| 1264/1292 [36:28<00:47,  1.68s/it] 98%|█████████▊| 1265/1292 [36:30<00:45,  1.68s/it] 98%|█████████▊| 1266/1292 [36:31<00:43,  1.68s/it] 98%|█████████▊| 1267/1292 [36:33<00:42,  1.68s/it] 98%|█████████▊| 1268/1292 [36:35<00:40,  1.68s/it] 98%|█████████▊| 1269/1292 [36:36<00:38,  1.68s/it] 98%|█████████▊| 1270/1292 [36:38<00:37,  1.68s/it] 98%|█████████▊| 1271/1292 [36:40<00:35,  1.68s/it] 98%|█████████▊| 1272/1292 [36:41<00:33,  1.68s/it] 99%|█████████▊| 1273/1292 [36:43<00:31,  1.68s/it] 99%|█████████▊| 1274/1292 [36:45<00:30,  1.68s/it] 99%|█████████▊| 1275/1292 [36:46<00:28,  1.68s/it] 99%|█████████▉| 1276/1292 [36:48<00:26,  1.68s/it] 99%|█████████▉| 1277/1292 [36:50<00:25,  1.68s/it] 99%|█████████▉| 1278/1292 [36:51<00:23,  1.68s/it] 99%|█████████▉| 1279/1292 [36:53<00:21,  1.68s/it] 99%|█████████▉| 1280/1292 [36:55<00:20,  1.68s/it] 99%|█████████▉| 1281/1292 [36:57<00:18,  1.68s/it] 99%|█████████▉| 1282/1292 [36:58<00:16,  1.68s/it] 99%|█████████▉| 1283/1292 [37:00<00:15,  1.68s/it] 99%|█████████▉| 1284/1292 [37:02<00:13,  1.68s/it] 99%|█████████▉| 1285/1292 [37:03<00:11,  1.68s/it]100%|█████████▉| 1286/1292 [37:05<00:10,  1.68s/it]100%|█████████▉| 1287/1292 [37:07<00:08,  1.68s/it]100%|█████████▉| 1288/1292 [37:08<00:06,  1.68s/it]100%|█████████▉| 1289/1292 [37:10<00:05,  1.68s/it]100%|█████████▉| 1290/1292 [37:12<00:03,  1.68s/it]100%|█████████▉| 1291/1292 [37:13<00:01,  1.68s/it]100%|██████████| 1292/1292 [37:14<00:00,  1.31s/it]                                                   100%|██████████| 1292/1292 [37:14<00:00,  1.31s/it][INFO|trainer.py:571] 2022-12-20 03:20:15,718 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text_e2, id, text_e1. If text_e2, id, text_e1 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:2389] 2022-12-20 03:20:15,723 >> ***** Running Evaluation *****
[INFO|trainer.py:2391] 2022-12-20 03:20:15,723 >>   Num examples = 8792
[INFO|trainer.py:2394] 2022-12-20 03:20:15,723 >>   Batch size = 384
{'eval_loss': 0.1959153562784195, 'eval_accuracy': 0.945859872611465, 'eval_runtime': 15.351, 'eval_samples_per_second': 572.732, 'eval_steps_per_second': 1.498, 'epoch': 3.0}
{'loss': 0.0359, 'learning_rate': 0.0, 'epoch': 4.0}

  0%|          | 0/23 [00:00<?, ?it/s][A
  9%|▊         | 2/23 [00:00<00:07,  2.98it/s][A
 13%|█▎        | 3/23 [00:01<00:10,  1.98it/s][A
 17%|█▋        | 4/23 [00:02<00:10,  1.76it/s][A
 22%|██▏       | 5/23 [00:02<00:10,  1.66it/s][A
 26%|██▌       | 6/23 [00:03<00:10,  1.60it/s][A
 30%|███       | 7/23 [00:04<00:10,  1.57it/s][A
 35%|███▍      | 8/23 [00:04<00:09,  1.54it/s][A
 39%|███▉      | 9/23 [00:05<00:09,  1.52it/s][A
 43%|████▎     | 10/23 [00:06<00:08,  1.51it/s][A
 48%|████▊     | 11/23 [00:06<00:07,  1.51it/s][A
 52%|█████▏    | 12/23 [00:07<00:07,  1.50it/s][A
 57%|█████▋    | 13/23 [00:08<00:06,  1.50it/s][A
 61%|██████    | 14/23 [00:08<00:06,  1.50it/s][A
 65%|██████▌   | 15/23 [00:09<00:05,  1.50it/s][A
 70%|██████▉   | 16/23 [00:10<00:04,  1.50it/s][A
 74%|███████▍  | 17/23 [00:10<00:04,  1.50it/s][A
 78%|███████▊  | 18/23 [00:11<00:03,  1.50it/s][A
 83%|████████▎ | 19/23 [00:12<00:02,  1.50it/s][A
 87%|████████▋ | 20/23 [00:12<00:02,  1.49it/s][A
 91%|█████████▏| 21/23 [00:13<00:01,  1.49it/s][A
 96%|█████████▌| 22/23 [00:14<00:00,  1.49it/s][A
100%|██████████| 23/23 [00:14<00:00,  1.54it/s][A                                                   
                                               [A100%|██████████| 1292/1292 [37:29<00:00,  1.31s/it]
100%|██████████| 23/23 [00:14<00:00,  1.54it/s][A
                                               [A[INFO|trainer.py:2139] 2022-12-20 03:20:31,185 >> Saving model checkpoint to /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-1292
[INFO|configuration_utils.py:439] 2022-12-20 03:20:31,187 >> Configuration saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-1292/config.json
[INFO|modeling_utils.py:1084] 2022-12-20 03:20:33,845 >> Model weights saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-1292/pytorch_model.bin
[INFO|tokenization_utils_base.py:2094] 2022-12-20 03:20:33,846 >> tokenizer config file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-1292/tokenizer_config.json
[INFO|tokenization_utils_base.py:2100] 2022-12-20 03:20:33,847 >> Special tokens file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-1292/special_tokens_map.json
[INFO|trainer.py:2217] 2022-12-20 03:20:39,202 >> Deleting older checkpoint [/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-646] due to args.save_total_limit
[INFO|trainer.py:1508] 2022-12-20 03:20:39,401 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:1517] 2022-12-20 03:20:39,402 >> Loading best model from /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/checkpoint-969 (score: 0.945859872611465).
                                                   100%|██████████| 1292/1292 [37:38<00:00,  1.31s/it]100%|██████████| 1292/1292 [37:38<00:00,  1.75s/it]
[INFO|trainer.py:2139] 2022-12-20 03:20:39,703 >> Saving model checkpoint to /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased
[INFO|configuration_utils.py:439] 2022-12-20 03:20:39,705 >> Configuration saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/config.json
[INFO|modeling_utils.py:1084] 2022-12-20 03:20:43,723 >> Model weights saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/pytorch_model.bin
[INFO|tokenization_utils_base.py:2094] 2022-12-20 03:20:43,725 >> tokenizer config file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/tokenizer_config.json
[INFO|tokenization_utils_base.py:2100] 2022-12-20 03:20:43,726 >> Special tokens file saved in /afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_combined_cross0_uncased/special_tokens_map.json
{'eval_loss': 0.22359918057918549, 'eval_accuracy': 0.945859872611465, 'eval_runtime': 15.4604, 'eval_samples_per_second': 568.679, 'eval_steps_per_second': 1.488, 'epoch': 4.0}
{'train_runtime': 2258.2927, 'train_samples_per_second': 219.171, 'train_steps_per_second': 0.572, 'train_loss': 0.09267343825231027, 'epoch': 4.0}
***** train metrics *****
  epoch                    =        4.0
  train_loss               =     0.0927
  train_runtime            = 0:37:38.29
  train_samples            =     123738
  train_samples_per_second =    219.171
  train_steps_per_second   =      0.572
12/20/2022 03:20:43 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:571] 2022-12-20 03:20:43,772 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text_e2, id, text_e1. If text_e2, id, text_e1 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:2389] 2022-12-20 03:20:43,777 >> ***** Running Evaluation *****
[INFO|trainer.py:2391] 2022-12-20 03:20:43,777 >>   Num examples = 8792
[INFO|trainer.py:2394] 2022-12-20 03:20:43,777 >>   Batch size = 384
  0%|          | 0/23 [00:00<?, ?it/s]  9%|▊         | 2/23 [00:00<00:06,  3.02it/s] 13%|█▎        | 3/23 [00:01<00:09,  2.13it/s] 17%|█▋        | 4/23 [00:01<00:10,  1.85it/s] 22%|██▏       | 5/23 [00:02<00:10,  1.71it/s] 26%|██▌       | 6/23 [00:03<00:10,  1.64it/s] 30%|███       | 7/23 [00:03<00:10,  1.59it/s] 35%|███▍      | 8/23 [00:04<00:09,  1.56it/s] 39%|███▉      | 9/23 [00:05<00:09,  1.55it/s] 43%|████▎     | 10/23 [00:05<00:08,  1.53it/s] 48%|████▊     | 11/23 [00:06<00:07,  1.52it/s] 52%|█████▏    | 12/23 [00:07<00:07,  1.52it/s] 57%|█████▋    | 13/23 [00:07<00:06,  1.51it/s] 61%|██████    | 14/23 [00:08<00:05,  1.51it/s] 65%|██████▌   | 15/23 [00:09<00:05,  1.51it/s] 70%|██████▉   | 16/23 [00:09<00:04,  1.51it/s] 74%|███████▍  | 17/23 [00:10<00:03,  1.51it/s] 78%|███████▊  | 18/23 [00:11<00:03,  1.51it/s] 83%|████████▎ | 19/23 [00:11<00:02,  1.50it/s] 87%|████████▋ | 20/23 [00:12<00:01,  1.50it/s] 91%|█████████▏| 21/23 [00:13<00:01,  1.51it/s] 96%|█████████▌| 22/23 [00:13<00:00,  1.50it/s]100%|██████████| 23/23 [00:14<00:00,  1.55it/s]100%|██████████| 23/23 [00:14<00:00,  1.58it/s]***** eval metrics *****
  epoch                   =        4.0
  eval_accuracy           =     0.9459
  eval_loss               =     0.1959
  eval_runtime            = 0:00:15.25
  eval_samples            =       8792
  eval_samples_per_second =     576.24
  eval_steps_per_second   =      1.507
12/20/2022 03:20:59 - INFO - __main__ - *** Predict ***

[INFO|trainer.py:571] 2022-12-20 03:20:59,046 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text_e2, id, text_e1. If text_e2, id, text_e1 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:2389] 2022-12-20 03:20:59,051 >> ***** Running Prediction *****
[INFO|trainer.py:2391] 2022-12-20 03:20:59,051 >>   Num examples = 7812
[INFO|trainer.py:2394] 2022-12-20 03:20:59,051 >>   Batch size = 384
  0%|          | 0/21 [00:00<?, ?it/s] 10%|▉         | 2/21 [00:00<00:06,  3.01it/s] 14%|█▍        | 3/21 [00:01<00:08,  2.13it/s] 19%|█▉        | 4/21 [00:01<00:09,  1.84it/s] 24%|██▍       | 5/21 [00:02<00:09,  1.71it/s] 29%|██▊       | 6/21 [00:03<00:09,  1.63it/s] 33%|███▎      | 7/21 [00:03<00:08,  1.59it/s] 38%|███▊      | 8/21 [00:04<00:08,  1.56it/s] 43%|████▎     | 9/21 [00:05<00:07,  1.54it/s] 48%|████▊     | 10/21 [00:05<00:07,  1.53it/s] 52%|█████▏    | 11/21 [00:06<00:06,  1.52it/s] 57%|█████▋    | 12/21 [00:07<00:05,  1.52it/s] 62%|██████▏   | 13/21 [00:07<00:05,  1.51it/s] 67%|██████▋   | 14/21 [00:08<00:04,  1.50it/s] 71%|███████▏  | 15/21 [00:09<00:03,  1.50it/s] 76%|███████▌  | 16/21 [00:09<00:03,  1.50it/s] 81%|████████  | 17/21 [00:10<00:02,  1.50it/s] 86%|████████▌ | 18/21 [00:11<00:01,  1.50it/s] 90%|█████████ | 19/21 [00:11<00:01,  1.50it/s] 95%|█████████▌| 20/21 [00:12<00:00,  1.50it/s]100%|██████████| 21/21 [00:12<00:00,  1.87it/s]100%|██████████| 21/21 [00:14<00:00,  1.43it/s]
***** predict metrics *****
  predict_accuracy           =     0.9415
  predict_loss               =     0.2339
  predict_runtime            = 0:00:13.58
  predict_samples            =       7812
  predict_samples_per_second =    574.852
  predict_steps_per_second   =      1.545
