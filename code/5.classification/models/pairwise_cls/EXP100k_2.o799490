11/17/2022 16:45:50 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
11/17/2022 16:45:50 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_train100k_split1_1117/runs/Nov17_16-45-50_qa-2080ti-006.crc.nd.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.EPOCH,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
no_cuda=False,
num_train_epochs=4.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_train100k_split1_1117,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/afs/crc.nd.edu/group/dmsquare/vol2/myu2/ComparisonSentences/experiments/pairwise_cls/cross_enc_train100k_split1_1117,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=2,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/17/2022 16:45:50 - WARNING - datasets.builder - Using custom data configuration default-253918d4491734cc
11/17/2022 16:45:50 - INFO - datasets.builder - Generating dataset json (/afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-253918d4491734cc/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)
Downloading and preparing dataset json/default to /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-253918d4491734cc/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]11/17/2022 16:45:50 - INFO - datasets.download.download_manager - Downloading took 0.0 min
11/17/2022 16:45:52 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min

Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 946.15it/s]11/17/2022 16:45:52 - INFO - datasets.utils.info_utils - Unable to verify checksums.
11/17/2022 16:45:52 - INFO - datasets.builder - Generating train split

0 tables [00:00, ? tables/s]1 tables [00:00,  8.41 tables/s]2 tables [00:00,  9.01 tables/s]4 tables [00:00, 10.35 tables/s]6 tables [00:00, 10.83 tables/s]8 tables [00:00, 11.05 tables/s]10 tables [00:00, 11.41 tables/s]                                 11/17/2022 16:45:53 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.
Dataset json downloaded and prepared to /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-253918d4491734cc/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.
11/17/2022 16:45:53 - WARNING - datasets.builder - Using custom data configuration default-c1526b4ffd149b02
11/17/2022 16:45:53 - INFO - datasets.builder - Generating dataset json (/afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-c1526b4ffd149b02/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)
Downloading and preparing dataset json/default to /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-c1526b4ffd149b02/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 7423.55it/s]11/17/2022 16:45:53 - INFO - datasets.download.download_manager - Downloading took 0.0 min
11/17/2022 16:45:53 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min

Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1255.03it/s]11/17/2022 16:45:53 - INFO - datasets.utils.info_utils - Unable to verify checksums.
11/17/2022 16:45:53 - INFO - datasets.builder - Generating validation split

0 tables [00:00, ? tables/s]                            11/17/2022 16:45:53 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.
Dataset json downloaded and prepared to /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-c1526b4ffd149b02/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.
11/17/2022 16:45:54 - WARNING - datasets.builder - Using custom data configuration default-a02130bb15c674e4
11/17/2022 16:45:54 - INFO - datasets.builder - Generating dataset json (/afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-a02130bb15c674e4/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)
Downloading and preparing dataset json/default to /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-a02130bb15c674e4/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 7530.17it/s]11/17/2022 16:45:54 - INFO - datasets.download.download_manager - Downloading took 0.0 min
11/17/2022 16:45:54 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min

Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1271.77it/s]11/17/2022 16:45:54 - INFO - datasets.utils.info_utils - Unable to verify checksums.
11/17/2022 16:45:54 - INFO - datasets.builder - Generating test split

0 tables [00:00, ? tables/s]                            11/17/2022 16:45:54 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.
[INFO|configuration_utils.py:648] 2022-11-17 16:45:54,366 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:684] 2022-11-17 16:45:54,367 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "xnli",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:648] 2022-11-17 16:45:54,646 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:684] 2022-11-17 16:45:54,647 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1786] 2022-11-17 16:45:55,435 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1786] 2022-11-17 16:45:55,435 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1786] 2022-11-17 16:45:55,435 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1786] 2022-11-17 16:45:55,435 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1786] 2022-11-17 16:45:55,436 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:648] 2022-11-17 16:45:55,584 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:684] 2022-11-17 16:45:55,585 >> Model config BertConfig {
  "_name_or_path": "bert-base-cased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1431] 2022-11-17 16:45:55,834 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1694] 2022-11-17 16:46:00,899 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1705] 2022-11-17 16:46:00,899 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Dataset json downloaded and prepared to /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-a02130bb15c674e4/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.
11/17/2022 16:46:00 - INFO - datasets.arrow_dataset - Caching indices mapping at /afs/crc.nd.edu/user/m/myu2/.cache/huggingface/datasets/json/default-253918d4491734cc/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-624f5305135fcda6.arrow
Running tokenizer on train dataset #0:   0%|          | 0/10 [00:00<?, ?ba/s]
Running tokenizer on train dataset #1:   0%|          | 0/10 [00:00<?, ?ba/s][A

Running tokenizer on train dataset #2:   0%|          | 0/10 [00:00<?, ?ba/s][A[A


Running tokenizer on train dataset #3:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A



Running tokenizer on train dataset #4:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A[A




Running tokenizer on train dataset #5:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A








Running tokenizer on train dataset #9:   0%|          | 0/10 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  10%|█         | 1/10 [00:00<00:02,  3.25ba/s]
Running tokenizer on train dataset #1:  10%|█         | 1/10 [00:00<00:02,  3.15ba/s][A

Running tokenizer on train dataset #2:  10%|█         | 1/10 [00:00<00:02,  3.16ba/s][A[A


Running tokenizer on train dataset #3:  10%|█         | 1/10 [00:00<00:02,  3.18ba/s][A[A[A



Running tokenizer on train dataset #4:  10%|█         | 1/10 [00:00<00:02,  3.24ba/s][A[A[A[A




Running tokenizer on train dataset #5:  10%|█         | 1/10 [00:00<00:02,  3.16ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  10%|█         | 1/10 [00:00<00:02,  3.22ba/s][A[A[A[A[A[A






Running tokenizer on train dataset #7:  10%|█         | 1/10 [00:00<00:02,  3.15ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  10%|█         | 1/10 [00:00<00:02,  3.22ba/s][A[A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  10%|█         | 1/10 [00:00<00:02,  3.12ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  20%|██        | 2/10 [00:00<00:02,  3.31ba/s]
Running tokenizer on train dataset #1:  20%|██        | 2/10 [00:00<00:02,  3.23ba/s][A

Running tokenizer on train dataset #2:  20%|██        | 2/10 [00:00<00:02,  3.27ba/s][A[A


Running tokenizer on train dataset #3:  20%|██        | 2/10 [00:00<00:02,  3.28ba/s][A[A[A



Running tokenizer on train dataset #4:  20%|██        | 2/10 [00:00<00:02,  3.31ba/s][A[A[A[A




Running tokenizer on train dataset #5:  20%|██        | 2/10 [00:00<00:02,  3.30ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  20%|██        | 2/10 [00:00<00:02,  3.33ba/s][A[A[A[A[A[A







Running tokenizer on train dataset #8:  20%|██        | 2/10 [00:00<00:02,  3.23ba/s][A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  20%|██        | 2/10 [00:00<00:02,  3.14ba/s][A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  20%|██        | 2/10 [00:00<00:02,  3.19ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  30%|███       | 3/10 [00:00<00:02,  3.33ba/s]
Running tokenizer on train dataset #1:  30%|███       | 3/10 [00:00<00:02,  3.30ba/s][A

Running tokenizer on train dataset #2:  30%|███       | 3/10 [00:00<00:02,  3.29ba/s][A[A


Running tokenizer on train dataset #3:  30%|███       | 3/10 [00:00<00:02,  3.30ba/s][A[A[A



Running tokenizer on train dataset #4:  30%|███       | 3/10 [00:00<00:02,  3.30ba/s][A[A[A[A




Running tokenizer on train dataset #5:  30%|███       | 3/10 [00:00<00:02,  3.30ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  30%|███       | 3/10 [00:00<00:02,  3.32ba/s][A[A[A[A[A[A







Running tokenizer on train dataset #8:  30%|███       | 3/10 [00:00<00:02,  3.30ba/s][A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  30%|███       | 3/10 [00:00<00:02,  3.24ba/s][A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  30%|███       | 3/10 [00:00<00:02,  3.26ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  40%|████      | 4/10 [00:01<00:01,  3.36ba/s]
Running tokenizer on train dataset #1:  40%|████      | 4/10 [00:01<00:01,  3.32ba/s][A

Running tokenizer on train dataset #2:  40%|████      | 4/10 [00:01<00:01,  3.32ba/s][A[A


Running tokenizer on train dataset #3:  40%|████      | 4/10 [00:01<00:01,  3.35ba/s][A[A[A



Running tokenizer on train dataset #4:  40%|████      | 4/10 [00:01<00:01,  3.34ba/s][A[A[A[A




Running tokenizer on train dataset #5:  40%|████      | 4/10 [00:01<00:01,  3.33ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  40%|████      | 4/10 [00:01<00:01,  3.36ba/s][A[A[A[A[A[A







Running tokenizer on train dataset #8:  40%|████      | 4/10 [00:01<00:01,  3.33ba/s][A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  40%|████      | 4/10 [00:01<00:01,  3.26ba/s][A[A[A[A[A[A[A








Running tokenizer on train dataset #9:  40%|████      | 4/10 [00:01<00:01,  3.28ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  50%|█████     | 5/10 [00:01<00:01,  3.34ba/s]
Running tokenizer on train dataset #1:  50%|█████     | 5/10 [00:01<00:01,  3.35ba/s][A


Running tokenizer on train dataset #3:  50%|█████     | 5/10 [00:01<00:01,  3.33ba/s][A[A[A

Running tokenizer on train dataset #2:  50%|█████     | 5/10 [00:01<00:01,  3.29ba/s][A[A



Running tokenizer on train dataset #4:  50%|█████     | 5/10 [00:01<00:01,  3.33ba/s][A[A[A[A




Running tokenizer on train dataset #5:  50%|█████     | 5/10 [00:01<00:01,  3.33ba/s][A[A[A[A[A





Running tokenizer on train dataset #6:  50%|█████     | 5/10 [00:01<00:01,  3.34ba/s][A[A[A[A[A[A








Running tokenizer on train dataset #9:  50%|█████     | 5/10 [00:01<00:01,  3.32ba/s][A[A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  50%|█████     | 5/10 [00:01<00:01,  3.21ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  50%|█████     | 5/10 [00:01<00:01,  3.18ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  60%|██████    | 6/10 [00:01<00:01,  3.36ba/s]

Running tokenizer on train dataset #2:  60%|██████    | 6/10 [00:01<00:01,  3.34ba/s][A[A


Running tokenizer on train dataset #3:  60%|██████    | 6/10 [00:01<00:01,  3.36ba/s][A[A[A



Running tokenizer on train dataset #4:  60%|██████    | 6/10 [00:01<00:01,  3.36ba/s][A[A[A[A
Running tokenizer on train dataset #1:  60%|██████    | 6/10 [00:01<00:01,  3.21ba/s][A





Running tokenizer on train dataset #6:  60%|██████    | 6/10 [00:01<00:01,  3.36ba/s][A[A[A[A[A[A




Running tokenizer on train dataset #5:  60%|██████    | 6/10 [00:01<00:01,  3.34ba/s][A[A[A[A[A








Running tokenizer on train dataset #9:  60%|██████    | 6/10 [00:01<00:01,  3.35ba/s][A[A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  60%|██████    | 6/10 [00:01<00:01,  3.24ba/s][A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  60%|██████    | 6/10 [00:01<00:01,  3.23ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #0:  70%|███████   | 7/10 [00:02<00:00,  3.22ba/s]

Running tokenizer on train dataset #2:  70%|███████   | 7/10 [00:02<00:00,  3.32ba/s][A[A


Running tokenizer on train dataset #3:  70%|███████   | 7/10 [00:02<00:00,  3.33ba/s][A[A[A



Running tokenizer on train dataset #4:  70%|███████   | 7/10 [00:02<00:00,  3.34ba/s][A[A[A[A
Running tokenizer on train dataset #1:  70%|███████   | 7/10 [00:02<00:00,  3.26ba/s][A





Running tokenizer on train dataset #6:  70%|███████   | 7/10 [00:02<00:00,  3.37ba/s][A[A[A[A[A[A




Running tokenizer on train dataset #5:  70%|███████   | 7/10 [00:02<00:00,  3.33ba/s][A[A[A[A[A








Running tokenizer on train dataset #9:  70%|███████   | 7/10 [00:02<00:00,  3.37ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  70%|███████   | 7/10 [00:02<00:00,  3.26ba/s][A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  70%|███████   | 7/10 [00:02<00:00,  3.24ba/s][A[A[A[A[A[A[A


Running tokenizer on train dataset #3:  80%|████████  | 8/10 [00:02<00:00,  2.97ba/s][A[A[ARunning tokenizer on train dataset #0:  80%|████████  | 8/10 [00:02<00:00,  2.85ba/s]



Running tokenizer on train dataset #4:  80%|████████  | 8/10 [00:02<00:00,  2.95ba/s][A[A[A[A

Running tokenizer on train dataset #2:  80%|████████  | 8/10 [00:02<00:00,  2.91ba/s][A[A
Running tokenizer on train dataset #1:  80%|████████  | 8/10 [00:02<00:00,  2.89ba/s][A





Running tokenizer on train dataset #6:  80%|████████  | 8/10 [00:02<00:00,  2.95ba/s][A[A[A[A[A[A




Running tokenizer on train dataset #5:  80%|████████  | 8/10 [00:02<00:00,  2.94ba/s][A[A[A[A[A








Running tokenizer on train dataset #9:  80%|████████  | 8/10 [00:02<00:00,  2.98ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  80%|████████  | 8/10 [00:02<00:00,  2.86ba/s][A[A[A[A[A[A[A[A


Running tokenizer on train dataset #3:  90%|█████████ | 9/10 [00:02<00:00,  3.02ba/s][A[A[ARunning tokenizer on train dataset #0:  90%|█████████ | 9/10 [00:02<00:00,  2.95ba/s]
Running tokenizer on train dataset #1:  90%|█████████ | 9/10 [00:02<00:00,  2.99ba/s][A



Running tokenizer on train dataset #4:  90%|█████████ | 9/10 [00:02<00:00,  3.01ba/s][A[A[A[A

Running tokenizer on train dataset #2:  90%|█████████ | 9/10 [00:02<00:00,  2.98ba/s][A[A





Running tokenizer on train dataset #6:  90%|█████████ | 9/10 [00:02<00:00,  3.00ba/s][A[A[A[A[A[A




Running tokenizer on train dataset #5:  90%|█████████ | 9/10 [00:02<00:00,  3.00ba/s][A[A[A[A[A








Running tokenizer on train dataset #9:  90%|█████████ | 9/10 [00:02<00:00,  3.04ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on train dataset #8:  90%|█████████ | 9/10 [00:02<00:00,  2.97ba/s][A[A[A[A[A[A[A[A






Running tokenizer on train dataset #7:  80%|████████  | 8/10 [00:02<00:00,  2.16ba/s][A[A[A[A[A[A[A


Running tokenizer on train dataset #3: 100%|██████████| 10/10 [00:03<00:00,  3.12ba/s][A[A[ARunning tokenizer on train dataset #3: 100%|██████████| 10/10 [00:03<00:00,  3.19ba/s]Running tokenizer on train dataset #0: 100%|██████████| 10/10 [00:03<00:00,  3.04ba/s]Running tokenizer on train dataset #0: 100%|██████████| 10/10 [00:03<00:00,  3.14ba/s]



Running tokenizer on train dataset #4: 100%|██████████| 10/10 [00:03<00:00,  3.11ba/s][A[A[A[ARunning tokenizer on train dataset #4: 100%|██████████| 10/10 [00:03<00:00,  3.18ba/s]
Running tokenizer on train dataset #1: 100%|██████████| 10/10 [00:03<00:00,  3.09ba/s][A

Running tokenizer on train dataset #2: 100%|██████████| 10/10 [00:03<00:00,  3.09ba/s][A[ARunning tokenizer on train dataset #1: 100%|██████████| 10/10 [00:03<00:00,  3.14ba/s]Running tokenizer on train dataset #2: 100%|██████████| 10/10 [00:03<00:00,  3.15ba/s]





Running tokenizer on train dataset #6: 100%|██████████| 10/10 [00:03<00:00,  3.08ba/s][A[A[A[A[A[ARunning tokenizer on train dataset #6: 100%|██████████| 10/10 [00:03<00:00,  3.18ba/s]




Running tokenizer on train dataset #5: 100%|██████████| 10/10 [00:03<00:00,  3.08ba/s][A[A[A[A[ARunning tokenizer on train dataset #5: 100%|██████████| 10/10 [00:03<00:00,  3.17ba/s]








Running tokenizer on train dataset #9: 100%|██████████| 10/10 [00:03<00:00,  3.15ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on train dataset #9: 100%|██████████| 10/10 [00:03<00:00,  3.19ba/s]







Running tokenizer on train dataset #8: 100%|██████████| 10/10 [00:03<00:00,  3.08ba/s][A[A[A[A[A[A[A[ARunning tokenizer on train dataset #8: 100%|██████████| 10/10 [00:03<00:00,  3.13ba/s]






Running tokenizer on train dataset #7:  90%|█████████ | 9/10 [00:03<00:00,  2.42ba/s][A[A[A[A[A[A[A






Running tokenizer on train dataset #7: 100%|██████████| 10/10 [00:03<00:00,  2.65ba/s][A[A[A[A[A[A[ARunning tokenizer on train dataset #7: 100%|██████████| 10/10 [00:03<00:00,  2.81ba/s]







11/17/2022 16:46:05 - INFO - __main__ - Sample 83810 of the training set: {'id': 'neg_14372_74_259', 'text_e1': 'Vettori is the first cousin of David Hill, a rugby union player who played in one Test for the All Blacks.', 'text_e2': 'In January 2008, Warne signed a two-year agreement with 888poker to represent them at poker events around the world including the Aussie Millions, World Series of Poker and the 888 UK Poker Open.', 'label': 0, 'input_ids': [101, 159, 27394, 2047, 1110, 1103, 1148, 5009, 1104, 1681, 2404, 117, 170, 4896, 3779, 1591, 1150, 1307, 1107, 1141, 5960, 1111, 1103, 1398, 21861, 119, 102, 1130, 1356, 1369, 117, 1414, 1673, 1878, 170, 1160, 118, 1214, 3311, 1114, 5385, 1604, 5674, 4188, 1106, 4248, 1172, 1120, 15772, 1958, 1213, 1103, 1362, 1259, 1103, 27758, 16869, 16660, 1116, 117, 1291, 2768, 1104, 25268, 1105, 1103, 5385, 1604, 1993, 25268, 3353, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/17/2022 16:46:05 - INFO - __main__ - Sample 14592 of the training set: {'id': 'neg_64200_7_13', 'text_e1': 'He scored 24 goals for the club, making him their all-time leading Premier League goalscorer.', 'text_e2': 'Napoli where he played for the next four seasons.', 'label': 0, 'input_ids': [101, 1124, 2297, 1572, 2513, 1111, 1103, 1526, 117, 1543, 1140, 1147, 1155, 118, 1159, 2020, 3863, 1453, 2513, 9475, 1197, 119, 102, 11896, 23311, 1187, 1119, 1307, 1111, 1103, 1397, 1300, 2955, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/17/2022 16:46:05 - INFO - __main__ - Sample 3278 of the training set: {'id': 'neg_63825_70_10', 'text_e1': 'In 2011, the Giants finished 86–76 and missed the playoffs.', 'text_e2': 'Wood attended MacArthur High School in Irving, Texas, for his first three seasons of high school baseball.', 'label': 0, 'input_ids': [101, 1130, 1349, 117, 1103, 7783, 1845, 5942, 782, 5465, 1105, 4007, 1103, 7736, 119, 102, 5296, 2323, 21045, 1693, 1323, 1107, 12581, 117, 2245, 117, 1111, 1117, 1148, 1210, 2955, 1104, 1344, 1278, 3866, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
Running tokenizer on validation dataset #0:   0%|          | 0/3 [00:00<?, ?ba/s]
Running tokenizer on validation dataset #1:   0%|          | 0/3 [00:00<?, ?ba/s][A

Running tokenizer on validation dataset #2:   0%|          | 0/3 [00:00<?, ?ba/s][A[A


Running tokenizer on validation dataset #3:   0%|          | 0/3 [00:00<?, ?ba/s][A[A[A



Running tokenizer on validation dataset #4:   0%|          | 0/3 [00:00<?, ?ba/s][A[A[A[A




Running tokenizer on validation dataset #5:   0%|          | 0/3 [00:00<?, ?ba/s][A[A[A[A[A





Running tokenizer on validation dataset #6:   0%|          | 0/3 [00:00<?, ?ba/s][A[A[A[A[A[A






Running tokenizer on validation dataset #7:   0%|          | 0/3 [00:00<?, ?ba/s][A[A[A[A[A[A[A







Running tokenizer on validation dataset #8:   0%|          | 0/3 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A








Running tokenizer on validation dataset #9:   0%|          | 0/3 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A
Running tokenizer on validation dataset #1:  33%|███▎      | 1/3 [00:00<00:00,  3.68ba/s][ARunning tokenizer on validation dataset #0:  33%|███▎      | 1/3 [00:00<00:00,  3.26ba/s]

Running tokenizer on validation dataset #2:  33%|███▎      | 1/3 [00:00<00:00,  3.28ba/s][A[A


Running tokenizer on validation dataset #3:  33%|███▎      | 1/3 [00:00<00:00,  3.17ba/s][A[A[A



Running tokenizer on validation dataset #4:  33%|███▎      | 1/3 [00:00<00:00,  3.25ba/s][A[A[A[A




Running tokenizer on validation dataset #5:  33%|███▎      | 1/3 [00:00<00:00,  3.37ba/s][A[A[A[A[A





Running tokenizer on validation dataset #6:  33%|███▎      | 1/3 [00:00<00:00,  3.52ba/s][A[A[A[A[A[A






Running tokenizer on validation dataset #7:  33%|███▎      | 1/3 [00:00<00:00,  3.40ba/s][A[A[A[A[A[A[A








Running tokenizer on validation dataset #9:  33%|███▎      | 1/3 [00:00<00:00,  3.33ba/s][A[A[A[A[A[A[A[A[A







Running tokenizer on validation dataset #8:  33%|███▎      | 1/3 [00:00<00:00,  3.20ba/s][A[A[A[A[A[A[A[A
Running tokenizer on validation dataset #1:  67%|██████▋   | 2/3 [00:00<00:00,  3.56ba/s][ARunning tokenizer on validation dataset #0:  67%|██████▋   | 2/3 [00:00<00:00,  3.22ba/s]


Running tokenizer on validation dataset #3:  67%|██████▋   | 2/3 [00:00<00:00,  3.45ba/s][A[A[ARunning tokenizer on validation dataset #1: 100%|██████████| 3/3 [00:00<00:00,  4.72ba/s]





Running tokenizer on validation dataset #6:  67%|██████▋   | 2/3 [00:00<00:00,  3.46ba/s][A[A[A[A[A[A

Running tokenizer on validation dataset #2:  67%|██████▋   | 2/3 [00:00<00:00,  3.13ba/s][A[A




Running tokenizer on validation dataset #5:  67%|██████▋   | 2/3 [00:00<00:00,  3.31ba/s][A[A[A[A[A



Running tokenizer on validation dataset #4:  67%|██████▋   | 2/3 [00:00<00:00,  3.21ba/s][A[A[A[A






Running tokenizer on validation dataset #7:  67%|██████▋   | 2/3 [00:00<00:00,  3.42ba/s][A[A[A[A[A[A[A







Running tokenizer on validation dataset #8:  67%|██████▋   | 2/3 [00:00<00:00,  3.46ba/s][A[A[A[A[A[A[A[ARunning tokenizer on validation dataset #0: 100%|██████████| 3/3 [00:00<00:00,  4.35ba/s]Running tokenizer on validation dataset #3: 100%|██████████| 3/3 [00:00<00:00,  4.55ba/s]Running tokenizer on validation dataset #5: 100%|██████████| 3/3 [00:00<00:00,  4.54ba/s]Running tokenizer on validation dataset #6: 100%|██████████| 3/3 [00:00<00:00,  4.62ba/s]Running tokenizer on validation dataset #4: 100%|██████████| 3/3 [00:00<00:00,  4.42ba/s]








Running tokenizer on validation dataset #9:  67%|██████▋   | 2/3 [00:00<00:00,  3.20ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on validation dataset #2: 100%|██████████| 3/3 [00:00<00:00,  4.20ba/s]Running tokenizer on validation dataset #7: 100%|██████████| 3/3 [00:00<00:00,  4.55ba/s]Running tokenizer on validation dataset #8: 100%|██████████| 3/3 [00:00<00:00,  4.55ba/s]Running tokenizer on validation dataset #9: 100%|██████████| 3/3 [00:00<00:00,  4.32ba/s]








Running tokenizer on prediction dataset #0:   0%|          | 0/2 [00:00<?, ?ba/s]
Running tokenizer on prediction dataset #1:   0%|          | 0/2 [00:00<?, ?ba/s][A

Running tokenizer on prediction dataset #2:   0%|          | 0/2 [00:00<?, ?ba/s][A[A


Running tokenizer on prediction dataset #3:   0%|          | 0/2 [00:00<?, ?ba/s][A[A[A



Running tokenizer on prediction dataset #4:   0%|          | 0/2 [00:00<?, ?ba/s][A[A[A[A




Running tokenizer on prediction dataset #5:   0%|          | 0/2 [00:00<?, ?ba/s][A[A[A[A[A





Running tokenizer on prediction dataset #6:   0%|          | 0/2 [00:00<?, ?ba/s][A[A[A[A[A[A






Running tokenizer on prediction dataset #7:   0%|          | 0/2 [00:00<?, ?ba/s][A[A[A[A[A[A[A







Running tokenizer on prediction dataset #8:   0%|          | 0/2 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A








Running tokenizer on prediction dataset #9:   0%|          | 0/2 [00:00<?, ?ba/s][A[A[A[A[A[A[A[A[A

Running tokenizer on prediction dataset #2:  50%|█████     | 1/2 [00:00<00:00,  3.66ba/s][A[A


Running tokenizer on prediction dataset #3:  50%|█████     | 1/2 [00:00<00:00,  3.64ba/s][A[A[A
Running tokenizer on prediction dataset #1:  50%|█████     | 1/2 [00:00<00:00,  3.26ba/s][ARunning tokenizer on prediction dataset #0:  50%|█████     | 1/2 [00:00<00:00,  3.14ba/s]




Running tokenizer on prediction dataset #5:  50%|█████     | 1/2 [00:00<00:00,  3.86ba/s][A[A[A[A[A



Running tokenizer on prediction dataset #4:  50%|█████     | 1/2 [00:00<00:00,  3.39ba/s][A[A[A[A






Running tokenizer on prediction dataset #7:  50%|█████     | 1/2 [00:00<00:00,  3.46ba/s][A[A[A[A[A[A[A





Running tokenizer on prediction dataset #6:  50%|█████     | 1/2 [00:00<00:00,  3.31ba/s][A[A[A[A[A[A







Running tokenizer on prediction dataset #8:  50%|█████     | 1/2 [00:00<00:00,  3.48ba/s][A[A[A[A[A[A[A[A








Running tokenizer on prediction dataset #9:  50%|█████     | 1/2 [00:00<00:00,  3.15ba/s][A[A[A[A[A[A[A[A[A

Running tokenizer on prediction dataset #2: 100%|██████████| 2/2 [00:00<00:00,  4.04ba/s][A[ARunning tokenizer on prediction dataset #2: 100%|██████████| 2/2 [00:00<00:00,  3.98ba/s]




Running tokenizer on prediction dataset #5: 100%|██████████| 2/2 [00:00<00:00,  4.38ba/s][A[A[A[A[ARunning tokenizer on prediction dataset #5: 100%|██████████| 2/2 [00:00<00:00,  4.29ba/s]Running tokenizer on prediction dataset #0: 100%|██████████| 2/2 [00:00<00:00,  3.75ba/s]Running tokenizer on prediction dataset #0: 100%|██████████| 2/2 [00:00<00:00,  3.64ba/s]


Running tokenizer on prediction dataset #3: 100%|██████████| 2/2 [00:00<00:00,  3.75ba/s][A[A[ARunning tokenizer on prediction dataset #3: 100%|██████████| 2/2 [00:00<00:00,  3.72ba/s]
Running tokenizer on prediction dataset #1: 100%|██████████| 2/2 [00:00<00:00,  3.58ba/s][ARunning tokenizer on prediction dataset #1: 100%|██████████| 2/2 [00:00<00:00,  3.52ba/s]



Running tokenizer on prediction dataset #4: 100%|██████████| 2/2 [00:00<00:00,  3.82ba/s][A[A[A[ARunning tokenizer on prediction dataset #4: 100%|██████████| 2/2 [00:00<00:00,  3.74ba/s]






Running tokenizer on prediction dataset #7: 100%|██████████| 2/2 [00:00<00:00,  4.14ba/s][A[A[A[A[A[A[ARunning tokenizer on prediction dataset #7: 100%|██████████| 2/2 [00:00<00:00,  4.02ba/s]





Running tokenizer on prediction dataset #6: 100%|██████████| 2/2 [00:00<00:00,  4.01ba/s][A[A[A[A[A[ARunning tokenizer on prediction dataset #6: 100%|██████████| 2/2 [00:00<00:00,  3.89ba/s]







Running tokenizer on prediction dataset #8: 100%|██████████| 2/2 [00:00<00:00,  4.10ba/s][A[A[A[A[A[A[A[ARunning tokenizer on prediction dataset #8: 100%|██████████| 2/2 [00:00<00:00,  3.99ba/s]








Running tokenizer on prediction dataset #9: 100%|██████████| 2/2 [00:00<00:00,  3.90ba/s][A[A[A[A[A[A[A[A[ARunning tokenizer on prediction dataset #9: 100%|██████████| 2/2 [00:00<00:00,  3.76ba/s]






[INFO|trainer.py:571] 2022-11-17 16:46:15,989 >> The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, text_e1, text_e2. If id, text_e1, text_e2 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.
/afs/crc.nd.edu/user/m/myu2/anaconda2/envs/bert/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
[INFO|trainer.py:1279] 2022-11-17 16:46:16,019 >> ***** Running training *****
[INFO|trainer.py:1280] 2022-11-17 16:46:16,019 >>   Num examples = 100000
[INFO|trainer.py:1281] 2022-11-17 16:46:16,019 >>   Num Epochs = 4
[INFO|trainer.py:1282] 2022-11-17 16:46:16,019 >>   Instantaneous batch size per device = 64
[INFO|trainer.py:1283] 2022-11-17 16:46:16,019 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1284] 2022-11-17 16:46:16,019 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1285] 2022-11-17 16:46:16,019 >>   Total optimization steps = 6252
  0%|          | 0/6252 [00:00<?, ?it/s]  0%|          | 1/6252 [00:00<1:18:08,  1.33it/s]  0%|          | 2/6252 [00:01<1:02:31,  1.67it/s]  0%|          | 3/6252 [00:01<57:26,  1.81it/s]    0%|          | 4/6252 [00:02<55:07,  1.89it/s]  0%|          | 5/6252 [00:02<53:47,  1.94it/s]  0%|          | 6/6252 [00:03<53:00,  1.96it/s]  0%|          | 7/6252 [00:03<52:28,  1.98it/s]  0%|          | 8/6252 [00:04<52:06,  2.00it/s]  0%|          | 9/6252 [00:04<51:50,  2.01it/s]  0%|          | 10/6252 [00:05<51:39,  2.01it/s]  0%|          | 11/6252 [00:05<51:39,  2.01it/s]  0%|          | 12/6252 [00:06<1:01:02,  1.70it/s]  0%|          | 13/6252 [00:06<58:06,  1.79it/s]    0%|          | 14/6252 [00:07<56:03,  1.85it/s]  0%|          | 15/6252 [00:07<54:37,  1.90it/s]  0%|          | 16/6252 [00:08<53:37,  1.94it/s]  0%|          | 17/6252 [00:08<52:53,  1.96it/s]  0%|          | 18/6252 [00:09<52:25,  1.98it/s]  0%|          | 19/6252 [00:09<52:07,  1.99it/s]  0%|          | 20/6252 [00:10<51:53,  2.00it/s]  0%|          | 21/6252 [00:10<51:44,  2.01it/s]  0%|          | 22/6252 [00:11<51:37,  2.01it/s]  0%|          | 23/6252 [00:11<51:33,  2.01it/s]  0%|          | 24/6252 [00:12<51:31,  2.01it/s]  0%|          | 25/6252 [00:12<51:29,  2.02it/s]  0%|          | 26/6252 [00:13<51:34,  2.01it/s]  0%|          | 27/6252 [00:13<51:35,  2.01it/s]  0%|          | 28/6252 [00:14<51:35,  2.01it/s]  0%|          | 29/6252 [00:14<51:33,  2.01it/s]  0%|          | 30/6252 [00:15<51:32,  2.01it/s]  0%|          | 31/6252 [00:15<51:30,  2.01it/s]  1%|          | 32/6252 [00:16<51:29,  2.01it/s]  1%|          | 33/6252 [00:16<51:32,  2.01it/s]  1%|          | 34/6252 [00:17<51:33,  2.01it/s]  1%|          | 35/6252 [00:17<51:36,  2.01it/s]  1%|          | 36/6252 [00:18<51:33,  2.01it/s]  1%|          | 37/6252 [00:18<51:32,  2.01it/s]  1%|          | 38/6252 [00:19<51:34,  2.01it/s]  1%|          | 39/6252 [00:19<51:35,  2.01it/s]  1%|          | 40/6252 [00:20<51:40,  2.00it/s]  1%|          | 41/6252 [00:20<51:39,  2.00it/s]  1%|          | 42/6252 [00:21<51:37,  2.00it/s]  1%|          | 43/6252 [00:21<51:39,  2.00it/s]  1%|          | 44/6252 [00:22<51:39,  2.00it/s]  1%|          | 45/6252 [00:22<51:38,  2.00it/s]  1%|          | 46/6252 [00:23<51:38,  2.00it/s]  1%|          | 47/6252 [00:23<51:38,  2.00it/s]  1%|          | 48/6252 [00:24<51:36,  2.00it/s]  1%|          | 49/6252 [00:24<51:39,  2.00it/s]  1%|          | 50/6252 [00:25<51:41,  2.00it/s]  1%|          | 51/6252 [00:25<51:40,  2.00it/s]  1%|          | 52/6252 [00:26<51:41,  2.00it/s]  1%|          | 53/6252 [00:26<51:43,  2.00it/s]  1%|          | 54/6252 [00:27<51:42,  2.00it/s]  1%|          | 55/6252 [00:27<51:47,  1.99it/s]  1%|          | 56/6252 [00:28<51:50,  1.99it/s]  1%|          | 57/6252 [00:28<51:51,  1.99it/s]  1%|          | 58/6252 [00:29<51:49,  1.99it/s]  1%|          | 59/6252 [00:29<51:49,  1.99it/s]  1%|          | 60/6252 [00:30<51:50,  1.99it/s]  1%|          | 61/6252 [00:30<51:49,  1.99it/s]  1%|          | 62/6252 [00:31<51:48,  1.99it/s]  1%|          | 63/6252 [00:31<51:47,  1.99it/s]  1%|          | 64/6252 [00:32<51:47,  1.99it/s]  1%|          | 65/6252 [00:32<51:46,  1.99it/s]  1%|          | 66/6252 [00:33<51:51,  1.99it/s]  1%|          | 67/6252 [00:33<51:51,  1.99it/s]  1%|          | 68/6252 [00:34<51:51,  1.99it/s]  1%|          | 69/6252 [00:34<51:50,  1.99it/s]  1%|          | 70/6252 [00:35<51:49,  1.99it/s]  1%|          | 71/6252 [00:35<51:49,  1.99it/s]  1%|          | 72/6252 [00:36<51:52,  1.99it/s]  1%|          | 73/6252 [00:36<51:51,  1.99it/s]  1%|          | 74/6252 [00:37<51:52,  1.98it/s]  1%|          | 75/6252 [00:37<51:51,  1.98it/s]  1%|          | 76/6252 [00:38<51:48,  1.99it/s]  1%|          | 77/6252 [00:38<51:48,  1.99it/s]  1%|          | 78/6252 [00:39<51:50,  1.98it/s]  1%|▏         | 79/6252 [00:39<51:53,  1.98it/s]  1%|▏         | 80/6252 [00:40<51:56,  1.98it/s]  1%|▏         | 81/6252 [00:40<51:57,  1.98it/s]  1%|▏         | 82/6252 [00:41<51:57,  1.98it/s]  1%|▏         | 83/6252 [00:41<51:57,  1.98it/s]  1%|▏         | 84/6252 [00:42<51:56,  1.98it/s]  1%|▏         | 85/6252 [00:42<51:55,  1.98it/s]  1%|▏         | 86/6252 [00:43<51:56,  1.98it/s]  1%|▏         | 87/6252 [00:44<51:56,  1.98it/s]  1%|▏         | 88/6252 [00:44<51:59,  1.98it/s]  1%|▏         | 89/6252 [00:45<51:59,  1.98it/s]  1%|▏         | 90/6252 [00:45<51:58,  1.98it/s]  1%|▏         | 91/6252 [00:46<51:59,  1.97it/s]  1%|▏         | 92/6252 [00:46<52:00,  1.97it/s]  1%|▏         | 93/6252 [00:47<52:02,  1.97it/s]  2%|▏         | 94/6252 [00:47<52:03,  1.97it/s]  2%|▏         | 95/6252 [00:48<52:03,  1.97it/s]  2%|▏         | 96/6252 [00:48<52:01,  1.97it/s]  2%|▏         | 97/6252 [00:49<52:01,  1.97it/s]  2%|▏         | 98/6252 [00:49<52:00,  1.97it/s]  2%|▏         | 99/6252 [00:50<52:02,  1.97it/s]  2%|▏         | 100/6252 [00:50<52:01,  1.97it/s]  2%|▏         | 101/6252 [00:51<52:02,  1.97it/s]  2%|▏         | 102/6252 [00:51<51:59,  1.97it/s]  2%|▏         | 103/6252 [00:52<52:00,  1.97it/s]  2%|▏         | 104/6252 [00:52<52:06,  1.97it/s]  2%|▏         | 105/6252 [00:53<52:08,  1.97it/s]  2%|▏         | 106/6252 [00:53<52:04,  1.97it/s]  2%|▏         | 107/6252 [00:54<52:06,  1.97it/s]  2%|▏         | 108/6252 [00:54<52:05,  1.97it/s]  2%|▏         | 109/6252 [00:55<52:02,  1.97it/s]  2%|▏         | 110/6252 [00:55<52:02,  1.97it/s]  2%|▏         | 111/6252 [00:56<52:01,  1.97it/s]  2%|▏         | 112/6252 [00:56<52:00,  1.97it/s]  2%|▏         | 113/6252 [00:57<52:02,  1.97it/s]  2%|▏         | 114/6252 [00:57<52:05,  1.96it/s]  2%|▏         | 115/6252 [00:58<52:06,  1.96it/s]  2%|▏         | 116/6252 [00:58<52:07,  1.96it/s]  2%|▏         | 117/6252 [00:59<52:09,  1.96it/s]  2%|▏         | 118/6252 [00:59<52:08,  1.96it/s]  2%|▏         | 119/6252 [01:00<52:08,  1.96it/s]  2%|▏         | 120/6252 [01:00<52:09,  1.96it/s]  2%|▏         | 121/6252 [01:01<52:09,  1.96it/s]  2%|▏         | 122/6252 [01:01<52:09,  1.96it/s]  2%|▏         | 123/6252 [01:02<52:10,  1.96it/s]  2%|▏         | 124/6252 [01:02<52:10,  1.96it/s]  2%|▏         | 125/6252 [01:03<52:11,  1.96it/s]  2%|▏         | 126/6252 [01:03<52:11,  1.96it/s]  2%|▏         | 127/6252 [01:04<52:11,  1.96it/s]  2%|▏         | 128/6252 [01:04<52:12,  1.96it/s]  2%|▏         | 129/6252 [01:05<52:10,  1.96it/s]  2%|▏         | 130/6252 [01:05<52:10,  1.96it/s]  2%|▏         | 131/6252 [01:06<52:10,  1.96it/s]  2%|▏         | 132/6252 [01:06<52:09,  1.96it/s]  2%|▏         | 133/6252 [01:07<52:12,  1.95it/s]  2%|▏         | 134/6252 [01:07<52:11,  1.95it/s]  2%|▏         | 135/6252 [01:08<52:12,  1.95it/s]  2%|▏         | 136/6252 [01:08<52:11,  1.95it/s]  2%|▏         | 137/6252 [01:09<52:10,  1.95it/s]  2%|▏         | 138/6252 [01:09<52:08,  1.95it/s]  2%|▏         | 139/6252 [01:10<52:08,  1.95it/s]  2%|▏         | 140/6252 [01:11<52:07,  1.95it/s]  2%|▏         | 141/6252 [01:11<52:09,  1.95it/s]  2%|▏         | 142/6252 [01:12<52:09,  1.95it/s]  2%|▏         | 143/6252 [01:12<52:09,  1.95it/s]  2%|▏         | 144/6252 [01:13<52:07,  1.95it/s]  2%|▏         | 145/6252 [01:13<52:06,  1.95it/s]  2%|▏         | 146/6252 [01:14<52:07,  1.95it/s]  2%|▏         | 147/6252 [01:14<52:08,  1.95it/s]  2%|▏         | 148/6252 [01:15<52:07,  1.95it/s]  2%|▏         | 149/6252 [01:15<52:08,  1.95it/s]  2%|▏         | 150/6252 [01:16<52:09,  1.95it/s]  2%|▏         | 151/6252 [01:16<52:07,  1.95it/s]  2%|▏         | 152/6252 [01:17<52:03,  1.95it/s]  2%|▏         | 153/6252 [01:17<52:10,  1.95it/s]  2%|▏         | 154/6252 [01:18<52:11,  1.95it/s]  2%|▏         | 155/6252 [01:18<52:10,  1.95it/s]  2%|▏         | 156/6252 [01:19<52:13,  1.95it/s]  3%|▎         | 157/6252 [01:19<52:12,  1.95it/s]  3%|▎         | 158/6252 [01:20<52:12,  1.95it/s]  3%|▎         | 159/6252 [01:20<52:23,  1.94it/s]  3%|▎         | 160/6252 [01:21<52:20,  1.94it/s]  3%|▎         | 161/6252 [01:21<52:20,  1.94it/s]  3%|▎         | 162/6252 [01:22<52:18,  1.94it/s]  3%|▎         | 163/6252 [01:22<52:17,  1.94it/s]  3%|▎         | 164/6252 [01:23<52:14,  1.94it/s]  3%|▎         | 165/6252 [01:23<52:13,  1.94it/s]  3%|▎         | 166/6252 [01:24<52:15,  1.94it/s]  3%|▎         | 167/6252 [01:24<52:14,  1.94it/s]  3%|▎         | 168/6252 [01:25<52:14,  1.94it/s]  3%|▎         | 169/6252 [01:25<52:11,  1.94it/s]  3%|▎         | 170/6252 [01:26<52:12,  1.94it/s]  3%|▎         | 171/6252 [01:26<52:10,  1.94it/s]  3%|▎         | 172/6252 [01:27<52:11,  1.94it/s]  3%|▎         | 173/6252 [01:27<52:10,  1.94it/s]  3%|▎         | 174/6252 [01:28<52:11,  1.94it/s]  3%|▎         | 175/6252 [01:29<52:09,  1.94it/s]  3%|▎         | 176/6252 [01:29<52:07,  1.94it/s]  3%|▎         | 177/6252 [01:30<52:07,  1.94it/s]  3%|▎         | 178/6252 [01:30<52:08,  1.94it/s]  3%|▎         | 179/6252 [01:31<52:08,  1.94it/s]  3%|▎         | 180/6252 [01:31<52:06,  1.94it/s]  3%|▎         | 181/6252 [01:32<52:12,  1.94it/s]  3%|▎         | 182/6252 [01:32<52:13,  1.94it/s]  3%|▎         | 183/6252 [01:33<52:10,  1.94it/s]  3%|▎         | 184/6252 [01:33<52:10,  1.94it/s]  3%|▎         | 185/6252 [01:34<52:08,  1.94it/s]  3%|▎         | 186/6252 [01:34<52:08,  1.94it/s]  3%|▎         | 187/6252 [01:35<52:06,  1.94it/s]  3%|▎         | 188/6252 [01:35<52:06,  1.94it/s]  3%|▎         | 189/6252 [01:36<52:06,  1.94it/s]  3%|▎         | 190/6252 [01:36<52:06,  1.94it/s]  3%|▎         | 191/6252 [01:37<52:07,  1.94it/s]  3%|▎         | 192/6252 [01:37<52:07,  1.94it/s]  3%|▎         | 193/6252 [01:38<52:06,  1.94it/s]  3%|▎         | 194/6252 [01:38<52:07,  1.94it/s]  3%|▎         | 195/6252 [01:39<52:05,  1.94it/s]  3%|▎         | 196/6252 [01:39<52:05,  1.94it/s]  3%|▎         | 197/6252 [01:40<52:04,  1.94it/s]  3%|▎         | 198/6252 [01:40<52:03,  1.94it/s]  3%|▎         | 199/6252 [01:41<52:03,  1.94it/s]  3%|▎         | 200/6252 [01:41<52:02,  1.94it/s]  3%|▎         | 201/6252 [01:42<52:05,  1.94it/s]  3%|▎         | 202/6252 [01:42<52:05,  1.94it/s]  3%|▎         | 203/6252 [01:43<52:03,  1.94it/s]  3%|▎         | 204/6252 [01:43<52:03,  1.94it/s]  3%|▎         | 205/6252 [01:44<52:02,  1.94it/s]  3%|▎         | 206/6252 [01:45<52:01,  1.94it/s]  3%|▎         | 207/6252 [01:45<52:02,  1.94it/s]  3%|▎         | 208/6252 [01:46<52:02,  1.94it/s]  3%|▎         | 209/6252 [01:46<52:00,  1.94it/s]  3%|▎         | 210/6252 [01:47<51:58,  1.94it/s]  3%|▎         | 211/6252 [01:47<51:59,  1.94it/s]  3%|▎         | 212/6252 [01:48<51:58,  1.94it/s]  3%|▎         | 213/6252 [01:48<51:58,  1.94it/s]  3%|▎         | 214/6252 [01:49<51:56,  1.94it/s]  3%|▎         | 215/6252 [01:49<51:56,  1.94it/s]  3%|▎         | 216/6252 [01:50<51:55,  1.94it/s]  3%|▎         | 217/6252 [01:50<51:54,  1.94it/s]  3%|▎         | 218/6252 [01:51<51:45,  1.94it/s]  4%|▎         | 219/6252 [01:51<51:47,  1.94it/s]  4%|▎         | 220/6252 [01:52<51:52,  1.94it/s]  4%|▎         | 221/6252 [01:52<51:53,  1.94it/s]  4%|▎         | 222/6252 [01:53<51:52,  1.94it/s]  4%|▎         | 223/6252 [01:53<51:53,  1.94it/s]  4%|▎         | 224/6252 [01:54<51:53,  1.94it/s]  4%|▎         | 225/6252 [01:54<51:53,  1.94it/s]  4%|▎         | 226/6252 [01:55<51:53,  1.94it/s]  4%|▎         | 227/6252 [01:55<51:52,  1.94it/s]  4%|▎         | 228/6252 [01:56<51:54,  1.93it/s]  4%|▎         | 229/6252 [01:56<51:56,  1.93it/s]  4%|▎         | 230/6252 [01:57<51:55,  1.93it/s]  4%|▎         | 231/6252 [01:57<51:56,  1.93it/s]  4%|▎         | 232/6252 [01:58<51:55,  1.93it/s]  4%|▎         | 233/6252 [01:58<51:57,  1.93it/s]  4%|▎         | 234/6252 [01:59<51:58,  1.93it/s]  4%|▍         | 235/6252 [01:59<51:57,  1.93it/s]  4%|▍         | 236/6252 [02:00<51:57,  1.93it/s]  4%|▍         | 237/6252 [02:01<51:54,  1.93it/s]  4%|▍         | 238/6252 [02:01<51:56,  1.93it/s]  4%|▍         | 239/6252 [02:02<51:54,  1.93it/s]  4%|▍         | 240/6252 [02:02<51:55,  1.93it/s]  4%|▍         | 241/6252 [02:03<51:56,  1.93it/s]  4%|▍         | 242/6252 [02:03<51:55,  1.93it/s]  4%|▍         | 243/6252 [02:04<51:55,  1.93it/s]  4%|▍         | 244/6252 [02:04<51:56,  1.93it/s]  4%|▍         | 245/6252 [02:05<51:57,  1.93it/s]  4%|▍         | 246/6252 [02:05<51:57,  1.93it/s]  4%|▍         | 247/6252 [02:06<51:55,  1.93it/s]  4%|▍         | 248/6252 [02:06<51:54,  1.93it/s]  4%|▍         | 249/6252 [02:07<51:53,  1.93it/s]  4%|▍         | 250/6252 [02:07<51:52,  1.93it/s]  4%|▍         | 251/6252 [02:08<51:52,  1.93it/s]  4%|▍         | 252/6252 [02:08<51:51,  1.93it/s]  4%|▍         | 253/6252 [02:09<51:53,  1.93it/s]  4%|▍         | 254/6252 [02:09<51:54,  1.93it/s]  4%|▍         | 255/6252 [02:10<51:51,  1.93it/s]  4%|▍         | 256/6252 [02:10<51:51,  1.93it/s]  4%|▍         | 257/6252 [02:11<51:49,  1.93it/s]  4%|▍         | 258/6252 [02:11<51:50,  1.93it/s]  4%|▍         | 259/6252 [02:12<51:51,  1.93it/s]  4%|▍         | 260/6252 [02:12<51:53,  1.92it/s]  4%|▍         | 261/6252 [02:13<51:55,  1.92it/s]  4%|▍         | 262/6252 [02:14<51:53,  1.92it/s]  4%|▍         | 263/6252 [02:14<51:52,  1.92it/s]  4%|▍         | 264/6252 [02:15<51:50,  1.93it/s]  4%|▍         | 265/6252 [02:15<51:49,  1.93it/s]  4%|▍         | 266/6252 [02:16<51:50,  1.92it/s]  4%|▍         | 267/6252 [02:16<51:49,  1.92it/s]  4%|▍         | 268/6252 [02:17<51:49,  1.92it/s]  4%|▍         | 269/6252 [02:17<51:49,  1.92it/s]  4%|▍         | 270/6252 [02:18<51:48,  1.92it/s]  4%|▍         | 271/6252 [02:18<51:49,  1.92it/s]  4%|▍         | 272/6252 [02:19<51:51,  1.92it/s]  4%|▍         | 273/6252 [02:19<51:48,  1.92it/s]  4%|▍         | 274/6252 [02:20<51:47,  1.92it/s]  4%|▍         | 275/6252 [02:20<51:47,  1.92it/s]  4%|▍         | 276/6252 [02:21<51:45,  1.92it/s]  4%|▍         | 277/6252 [02:21<51:44,  1.92it/s]  4%|▍         | 278/6252 [02:22<51:46,  1.92it/s]  4%|▍         | 279/6252 [02:22<51:43,  1.92it/s]  4%|▍         | 280/6252 [02:23<51:45,  1.92it/s]  4%|▍         | 281/6252 [02:23<51:45,  1.92it/s]  5%|▍         | 282/6252 [02:24<51:43,  1.92it/s]  5%|▍         | 283/6252 [02:24<51:42,  1.92it/s]  5%|▍         | 284/6252 [02:25<51:41,  1.92it/s]  5%|▍         | 285/6252 [02:25<51:40,  1.92it/s]  5%|▍         | 286/6252 [02:26<51:43,  1.92it/s]  5%|▍         | 287/6252 [02:27<51:44,  1.92it/s]